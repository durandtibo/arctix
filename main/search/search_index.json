{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p>The <code>arctix</code> package consists of functionalities to prepare dataset of asynchronous time series. It is design to make dataset preparation reusable and reproducible. For each dataset, <code>arctix</code> provides 3 main functions:</p> <ul> <li><code>fetch_data</code> to load the raw data are loaded in   a <code>polars.DataFrame</code>. When   possible, it downloads automatically the data.</li> <li><code>prepare_data</code> to prepare the data. It outputs the prepared data   in <code>polars.DataFrame</code>, and   the metadata.</li> <li><code>to_array</code> to convert the prepared data to a dictionary of numpy arrays.</li> </ul> <p>For example, it is possible to use the following lines to download and prepare the MultiTHUMOS data.</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.multithumos import fetch_data, prepare_data, to_array\n&gt;&gt;&gt; dataset_path = Path(\"/path/to/dataset/multithumos\")\n&gt;&gt;&gt; data_raw = fetch_data(dataset_path)  # doctest: +SKIP\n&gt;&gt;&gt; data, metadata = prepare_data(data_raw)  # doctest: +SKIP\n&gt;&gt;&gt; arrays = to_array(data)  # doctest: +SKIP\n</code></pre>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>arctix</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>arctix</code> to a new version will possibly break any code that was using the old version of <code>arctix</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>arctix</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install arctix\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>arctix</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'arctix[all]'\n</code></pre> <p>This command also installed NumPy and PyTorch. It is also possible to install the optional packages manually or to select the packages to install. In the following example, only NumPy is installed:</p> <pre><code>pip install arctix numpy\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>arctix</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/arctix.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate arctix\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>arctix</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"datasets/breakfast/","title":"Breakfast","text":"<p>This page contains information about the Breakfast dataset, which was published with the following paper:</p> <pre><code>The Language of Actions: Recovering the Syntax and Semantics of Goal-\nDirected Human Activities. Kuehne, Arslan, and Serre. CVPR 2014.\n</code></pre> <p>The data can be downloaded from the official project page.</p>"},{"location":"datasets/breakfast/#get-the-raw-data","title":"Get the raw data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.breakfast.fetch_data</code> to easily load the raw data in a <code>polars.DataFrame</code> format.</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.breakfast import fetch_data\n&gt;&gt;&gt; dataset_path = Path(\"/path/to/dataset/breakfast\")\n&gt;&gt;&gt; data_raw = fetch_data(dataset_path, name=\"segmentation_coarse\")  # doctest: +SKIP\nshape: (3_585, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action       \u2506 start_time \u2506 end_time \u2506 person \u2506 cooking_activity \u2502\n\u2502 ---          \u2506 ---        \u2506 ---      \u2506 ---    \u2506 ---              \u2502\n\u2502 str          \u2506 f64        \u2506 f64      \u2506 str    \u2506 str              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SIL          \u2506 1.0        \u2506 30.0     \u2506 P03    \u2506 cereals          \u2502\n\u2502 take_bowl    \u2506 31.0       \u2506 150.0    \u2506 P03    \u2506 cereals          \u2502\n\u2502 pour_cereals \u2506 151.0      \u2506 428.0    \u2506 P03    \u2506 cereals          \u2502\n\u2502 pour_milk    \u2506 429.0      \u2506 575.0    \u2506 P03    \u2506 cereals          \u2502\n\u2502 stir_cereals \u2506 576.0      \u2506 705.0    \u2506 P03    \u2506 cereals          \u2502\n\u2502 \u2026            \u2506 \u2026          \u2506 \u2026        \u2506 \u2026      \u2506 \u2026                \u2502\n\u2502 take_cup     \u2506 38.0       \u2506 92.0     \u2506 P54    \u2506 tea              \u2502\n\u2502 pour_water   \u2506 93.0       \u2506 229.0    \u2506 P54    \u2506 tea              \u2502\n\u2502 add_teabag   \u2506 230.0      \u2506 744.0    \u2506 P54    \u2506 tea              \u2502\n\u2502 pour_sugar   \u2506 745.0      \u2506 884.0    \u2506 P54    \u2506 tea              \u2502\n\u2502 SIL          \u2506 885.0      \u2506 973.0    \u2506 P54    \u2506 tea              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>There are two versions of the dataset: <code>\"segmentation_coarse\"</code> and <code>\"segmentation_fine\"</code>. If the data is not downloaded in the dataset path, <code>fetch_data</code> automatically downloads the data. You can set <code>force_download=True</code> to force to re-download the data if the data is already downloaded.</p>"},{"location":"datasets/breakfast/#prepare-the-data","title":"Prepare the data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.breakfast.prepare_data</code> to preprocess the raw data. It returns two outputs: the prepared data and the generate metadata.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.breakfast import prepare_data\n&gt;&gt;&gt; data, metadata = prepare_data(data_raw)  # doctest: +SKIP\n</code></pre> <p><code>data</code> is a <code>polars.DataFrame</code> which contains the prepared data:</p> <pre><code>shape: (3_585, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action      \u2506 start_time \u2506 end_time \u2506 person \u2506 cooking_act \u2506 action_id \u2506 person_id \u2506 cooking_act \u2502\n\u2502 ---         \u2506 ---        \u2506 ---      \u2506 ---    \u2506 ivity       \u2506 ---       \u2506 ---       \u2506 ivity_id    \u2502\n\u2502 str         \u2506 f64        \u2506 f64      \u2506 str    \u2506 ---         \u2506 i64       \u2506 i64       \u2506 ---         \u2502\n\u2502             \u2506            \u2506          \u2506        \u2506 str         \u2506           \u2506           \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SIL         \u2506 1.0        \u2506 30.0     \u2506 P03    \u2506 cereals     \u2506 0         \u2506 50        \u2506 7           \u2502\n\u2502 take_bowl   \u2506 31.0       \u2506 150.0    \u2506 P03    \u2506 cereals     \u2506 16        \u2506 50        \u2506 7           \u2502\n\u2502 pour_cereal \u2506 151.0      \u2506 428.0    \u2506 P03    \u2506 cereals     \u2506 21        \u2506 50        \u2506 7           \u2502\n\u2502 s           \u2506            \u2506          \u2506        \u2506             \u2506           \u2506           \u2506             \u2502\n\u2502 pour_milk   \u2506 429.0      \u2506 575.0    \u2506 P03    \u2506 cereals     \u2506 1         \u2506 50        \u2506 7           \u2502\n\u2502 stir_cereal \u2506 576.0      \u2506 705.0    \u2506 P03    \u2506 cereals     \u2506 37        \u2506 50        \u2506 7           \u2502\n\u2502 s           \u2506            \u2506          \u2506        \u2506             \u2506           \u2506           \u2506             \u2502\n\u2502 \u2026           \u2506 \u2026          \u2506 \u2026        \u2506 \u2026      \u2506 \u2026           \u2506 \u2026         \u2506 \u2026         \u2506 \u2026           \u2502\n\u2502 take_cup    \u2506 38.0       \u2506 92.0     \u2506 P54    \u2506 tea         \u2506 13        \u2506 12        \u2506 8           \u2502\n\u2502 pour_water  \u2506 93.0       \u2506 229.0    \u2506 P54    \u2506 tea         \u2506 23        \u2506 12        \u2506 8           \u2502\n\u2502 add_teabag  \u2506 230.0      \u2506 744.0    \u2506 P54    \u2506 tea         \u2506 25        \u2506 12        \u2506 8           \u2502\n\u2502 pour_sugar  \u2506 745.0      \u2506 884.0    \u2506 P54    \u2506 tea         \u2506 43        \u2506 12        \u2506 8           \u2502\n\u2502 SIL         \u2506 885.0      \u2506 973.0    \u2506 P54    \u2506 tea         \u2506 0         \u2506 12        \u2506 8           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can note that new columns are added and the data types of some columns have changed. <code>metadata</code> contains three vocabularies that are used to generate the new columns:</p> <pre><code>{'vocab_action': Vocabulary(\n   counter=Counter({'SIL': 1012, 'pour_milk': 199, 'cut_fruit': 175, 'crack_egg': 154, 'put_fruit2bowl': 139, 'take_plate': 132, 'put_egg2plate': 97, 'add_saltnpepper': 83, 'stir_dough': 78, 'peel_fruit': 74, 'fry_egg': 73, 'stirfry_egg': 67, 'butter_pan': 64, 'take_cup': 59, 'squeeze_orange': 59, 'pour_juice': 57, 'take_bowl': 56, 'put_toppingOnTop': 55, 'pour_oil': 55, 'fry_pancake': 55, 'spoon_powder': 53, 'pour_cereals': 53, 'stir_milk': 51, 'pour_water': 51, 'cut_bun': 51, 'add_teabag': 51, 'smear_butter': 49, 'pour_dough2pan': 49, 'pour_coffee': 49, 'spoon_flour': 48, 'cut_orange': 46, 'put_pancake2plate': 41, 'take_glass': 37, 'stir_egg': 30, 'take_knife': 28, 'put_bunTogether': 25, 'pour_egg2pan': 24, 'stir_cereals': 20, 'take_topping': 16, 'take_squeezer': 12, 'stir_fruit': 11, 'stir_coffee': 10, 'spoon_sugar': 10, 'pour_sugar': 8, 'pour_flour': 7, 'take_eggs': 6, 'take_butter': 4, 'stir_tea': 2}),\n   index_to_token=('SIL', 'pour_milk', 'cut_fruit', 'crack_egg', 'put_fruit2bowl', 'take_plate', 'put_egg2plate', 'add_saltnpepper', 'stir_dough', 'peel_fruit', 'fry_egg', 'stirfry_egg', 'butter_pan', 'take_cup', 'squeeze_orange', 'pour_juice', 'take_bowl', 'put_toppingOnTop', 'pour_oil', 'fry_pancake', 'spoon_powder', 'pour_cereals', 'stir_milk', 'pour_water', 'cut_bun', 'add_teabag', 'smear_butter', 'pour_dough2pan', 'pour_coffee', 'spoon_flour', 'cut_orange', 'put_pancake2plate', 'take_glass', 'stir_egg', 'take_knife', 'put_bunTogether', 'pour_egg2pan', 'stir_cereals', 'take_topping', 'take_squeezer', 'stir_fruit', 'stir_coffee', 'spoon_sugar', 'pour_sugar', 'pour_flour', 'take_eggs', 'take_butter', 'stir_tea'),\n   token_to_index={'SIL': 0, 'pour_milk': 1, 'cut_fruit': 2, 'crack_egg': 3, 'put_fruit2bowl': 4, 'take_plate': 5, 'put_egg2plate': 6, 'add_saltnpepper': 7, 'stir_dough': 8, 'peel_fruit': 9, 'fry_egg': 10, 'stirfry_egg': 11, 'butter_pan': 12, 'take_cup': 13, 'squeeze_orange': 14, 'pour_juice': 15, 'take_bowl': 16, 'put_toppingOnTop': 17, 'pour_oil': 18, 'fry_pancake': 19, 'spoon_powder': 20, 'pour_cereals': 21, 'stir_milk': 22, 'pour_water': 23, 'cut_bun': 24, 'add_teabag': 25, 'smear_butter': 26, 'pour_dough2pan': 27, 'pour_coffee': 28, 'spoon_flour': 29, 'cut_orange': 30, 'put_pancake2plate': 31, 'take_glass': 32, 'stir_egg': 33, 'take_knife': 34, 'put_bunTogether': 35, 'pour_egg2pan': 36, 'stir_cereals': 37, 'take_topping': 38, 'take_squeezer': 39, 'stir_fruit': 40, 'stir_coffee': 41, 'spoon_sugar': 42, 'pour_sugar': 43, 'pour_flour': 44, 'take_eggs': 45, 'take_butter': 46, 'stir_tea': 47},\n ),\n 'vocab_activity': Vocabulary(\n   counter=Counter({'pancake': 557, 'salat': 549, 'scrambledegg': 448, 'friedegg': 389, 'sandwich': 325, 'juice': 324, 'milk': 278, 'cereals': 256, 'tea': 233, 'coffee': 226}),\n   index_to_token=('pancake', 'salat', 'scrambledegg', 'friedegg', 'sandwich', 'juice', 'milk', 'cereals', 'tea', 'coffee'),\n   token_to_index={'pancake': 0, 'salat': 1, 'scrambledegg': 2, 'friedegg': 3, 'sandwich': 4, 'juice': 5, 'milk': 6, 'cereals': 7, 'tea': 8, 'coffee': 9},\n ),\n 'vocab_person': Vocabulary(\n   counter=Counter({'P47': 84, 'P31': 83, 'P05': 83, 'P16': 82, 'P51': 81, 'P09': 81, 'P07': 80, 'P50': 77, 'P41': 76, 'P27': 76, 'P20': 76, 'P18': 76, 'P54': 75, 'P32': 75, 'P43': 74, 'P38': 73, 'P30': 73, 'P23': 73, 'P08': 73, 'P39': 72, 'P53': 71, 'P49': 71, 'P42': 70, 'P22': 70, 'P48': 69, 'P14': 69, 'P10': 69, 'P06': 69, 'P35': 68, 'P25': 68, 'P04': 68, 'P44': 67, 'P33': 67, 'P21': 67, 'P17': 67, 'P52': 66, 'P11': 66, 'P46': 65, 'P40': 65, 'P24': 65, 'P19': 65, 'P13': 64, 'P45': 63, 'P26': 62, 'P37': 61, 'P12': 61, 'P15': 60, 'P36': 59, 'P29': 59, 'P34': 56, 'P03': 50, 'P28': 25}),\n   index_to_token=('P47', 'P31', 'P05', 'P16', 'P51', 'P09', 'P07', 'P50', 'P41', 'P27', 'P20', 'P18', 'P54', 'P32', 'P43', 'P38', 'P30', 'P23', 'P08', 'P39', 'P53', 'P49', 'P42', 'P22', 'P48', 'P14', 'P10', 'P06', 'P35', 'P25', 'P04', 'P44', 'P33', 'P21', 'P17', 'P52', 'P11', 'P46', 'P40', 'P24', 'P19', 'P13', 'P45', 'P26', 'P37', 'P12', 'P15', 'P36', 'P29', 'P34', 'P03', 'P28'),\n   token_to_index={'P47': 0, 'P31': 1, 'P05': 2, 'P16': 3, 'P51': 4, 'P09': 5, 'P07': 6, 'P50': 7, 'P41': 8, 'P27': 9, 'P20': 10, 'P18': 11, 'P54': 12, 'P32': 13, 'P43': 14, 'P38': 15, 'P30': 16, 'P23': 17, 'P08': 18, 'P39': 19, 'P53': 20, 'P49': 21, 'P42': 22, 'P22': 23, 'P48': 24, 'P14': 25, 'P10': 26, 'P06': 27, 'P35': 28, 'P25': 29, 'P04': 30, 'P44': 31, 'P33': 32, 'P21': 33, 'P17': 34, 'P52': 35, 'P11': 36, 'P46': 37, 'P40': 38, 'P24': 39, 'P19': 40, 'P13': 41, 'P45': 42, 'P26': 43, 'P37': 44, 'P12': 45, 'P15': 46, 'P36': 47, 'P29': 48, 'P34': 49, 'P03': 50, 'P28': 51},\n )}\n</code></pre> <p>It is possible to specify the dataset split to filter the data and keep only the data related to a given dataset split. The dataset has different can be decomposed in different splits. For example, the following line will filter the data to keep only the rows related to the first training dataset (a.k.a. <code>train1</code>):</p> <pre><code>&gt;&gt;&gt; data, metadata = prepare_data(data_raw, split=\"train1\")  # doctest: +SKIP\n</code></pre> <pre><code>shape: (2_692, 8)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action      \u2506 start_time \u2506 end_time \u2506 person \u2506 cooking_act \u2506 action_id \u2506 person_id \u2506 cooking_act \u2502\n\u2502 ---         \u2506 ---        \u2506 ---      \u2506 ---    \u2506 ivity       \u2506 ---       \u2506 ---       \u2506 ivity_id    \u2502\n\u2502 str         \u2506 f64        \u2506 f64      \u2506 str    \u2506 ---         \u2506 i64       \u2506 i64       \u2506 ---         \u2502\n\u2502             \u2506            \u2506          \u2506        \u2506 str         \u2506           \u2506           \u2506 i64         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SIL         \u2506 1.0        \u2506 9.0      \u2506 P16    \u2506 cereals     \u2506 0         \u2506 3         \u2506 7           \u2502\n\u2502 pour_cereal \u2506 10.0       \u2506 269.0    \u2506 P16    \u2506 cereals     \u2506 21        \u2506 3         \u2506 7           \u2502\n\u2502 s           \u2506            \u2506          \u2506        \u2506             \u2506           \u2506           \u2506             \u2502\n\u2502 pour_milk   \u2506 270.0      \u2506 474.0    \u2506 P16    \u2506 cereals     \u2506 1         \u2506 3         \u2506 7           \u2502\n\u2502 SIL         \u2506 475.0      \u2506 548.0    \u2506 P16    \u2506 cereals     \u2506 0         \u2506 3         \u2506 7           \u2502\n\u2502 SIL         \u2506 1.0        \u2506 39.0     \u2506 P17    \u2506 cereals     \u2506 0         \u2506 34        \u2506 7           \u2502\n\u2502 \u2026           \u2506 \u2026          \u2506 \u2026        \u2506 \u2026      \u2506 \u2026           \u2506 \u2026         \u2506 \u2026         \u2506 \u2026           \u2502\n\u2502 take_cup    \u2506 38.0       \u2506 92.0     \u2506 P54    \u2506 tea         \u2506 13        \u2506 12        \u2506 8           \u2502\n\u2502 pour_water  \u2506 93.0       \u2506 229.0    \u2506 P54    \u2506 tea         \u2506 23        \u2506 12        \u2506 8           \u2502\n\u2502 add_teabag  \u2506 230.0      \u2506 744.0    \u2506 P54    \u2506 tea         \u2506 25        \u2506 12        \u2506 8           \u2502\n\u2502 pour_sugar  \u2506 745.0      \u2506 884.0    \u2506 P54    \u2506 tea         \u2506 43        \u2506 12        \u2506 8           \u2502\n\u2502 SIL         \u2506 885.0      \u2506 973.0    \u2506 P54    \u2506 tea         \u2506 0         \u2506 12        \u2506 8           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p><code>arctix</code> provides the function <code>arctix.dataset.breakfast.to_array</code> to convert the <code>polars.DataFrame</code> to a dictionary of numpy arrays.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.breakfast import prepare_data\n&gt;&gt;&gt; arrays = to_array(data)  # doctest: +SKIP\n</code></pre> <p>The dictionary contains some regular arrays and masked arrays because sequences have variable lengths:</p> <pre><code>{'sequence_length': array([11, 19, 10,  ...,  5,  6,  4]),\n 'person_id': array([ 0,  0,  0,  ..., 51, 51, 51]),\n 'cooking_activity_id': array([0, 1, 2, ..., 4, 5, 7]),\n 'action_id': masked_array(\n   data=[[0, 3, 29, ..., --, --, --],\n         [0, 5, 16, ..., --, --, --],\n         [0, 3, 7, ..., --, --, --],\n         ...,\n         [0, 24, 26, ..., --, --, --],\n         [0, 32, 30, ..., --, --, --],\n         [0, 21, 1, ..., --, --, --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=999999),\n 'start_time': masked_array(\n   data=[[1.0, 2.0, 441.0, ..., --, --, --],\n         [1.0, 112.0, 227.0, ..., --, --, --],\n         [1.0, 5.0, 397.0, ..., --, --, --],\n         ...,\n         [1.0, 385.0, 650.0, ..., --, --, --],\n         [1.0, 31.0, 141.0, ..., --, --, --],\n         [1.0, 45.0, 213.0, ..., --, --, --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=1e+20),\n 'end_time': masked_array(\n   data=[[1.0, 440.0, 951.0, ..., --, --, --],\n         [111.0, 226.0, 281.0, ..., --, --, --],\n         [4.0, 396.0, 587.0, ..., --, --, --],\n         ...,\n         [384.0, 649.0, 1899.0, ..., --, --, --],\n         [30.0, 140.0, 530.0, ..., --, --, --],\n         [44.0, 212.0, 344.0, ..., --, --, --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=1e+20)}\n</code></pre>"},{"location":"datasets/ego4d/","title":"Ego4D","text":"<p>This page contains information about the Ego4D dataset, which was published with the following paper:</p> <pre><code>Ego4D: Around the World in 3,000 Hours of Egocentric Video.\nK Grauman et al.\narXiv:2110.07058 2021 (https://arxiv.org/abs/2110.07058)\n</code></pre> <p>The data can be downloaded from the official project page.</p>"},{"location":"datasets/ego4d/#get-the-raw-data","title":"Get the raw data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.ego4d.fetch_data</code> to easily load the raw data in a <code>polars.DataFrame</code> format. Note that you need to download the data by following the instructions on the Ego4d website.</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.ego4d import fetch_data\n&gt;&gt;&gt; dataset_path = Path(\"/path/to/dataset/ego4d\")\n&gt;&gt;&gt; data_raw, metadata_raw = fetch_data(dataset_path, split=\"train\")  # doctest: +SKIP\nshape: (63_956, 12)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action_cli \u2506 action_cli \u2506 action_cli \u2506 action_cl \u2506 \u2026 \u2506 split \u2506 verb      \u2506 verb_labe \u2506 video_uid \u2502\n\u2502 p_end_fram \u2506 p_end_sec  \u2506 p_start_fr \u2506 ip_start_ \u2506   \u2506 ---   \u2506 ---       \u2506 l         \u2506 ---       \u2502\n\u2502 e          \u2506 ---        \u2506 ame        \u2506 sec       \u2506   \u2506 str   \u2506 str       \u2506 ---       \u2506 str       \u2502\n\u2502 ---        \u2506 f64        \u2506 ---        \u2506 ---       \u2506   \u2506       \u2506           \u2506 i64       \u2506           \u2502\n\u2502 i64        \u2506            \u2506 i64        \u2506 f64       \u2506   \u2506       \u2506           \u2506           \u2506           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 373        \u2506 12.421029  \u2506 133        \u2506 4.4210286 \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 426        \u2506 14.187695  \u2506 186        \u2506 6.187695  \u2506 \u2026 \u2506 train \u2506 take_(pic \u2506 92        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 k,_grab,_ \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 get)      \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 610        \u2506 20.321029  \u2506 370        \u2506 12.321029 \u2506 \u2026 \u2506 train \u2506 move_(tra \u2506 49        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nsfer,_pa \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ss,_excha \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nge\u2026      \u2506           \u2506 5b3\u2026      \u2502\n\u2502 537        \u2506 17.887695  \u2506 297        \u2506 9.887695  \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 550        \u2506 18.321029  \u2506 310        \u2506 10.321029 \u2506 \u2026 \u2506 train \u2506 remove    \u2506 67        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 \u2026          \u2506 \u2026          \u2506 \u2026          \u2506 \u2026         \u2506 \u2026 \u2506 \u2026     \u2506 \u2026         \u2506 \u2026         \u2506 \u2026         \u2502\n\u2502 9142       \u2506 304.721029 \u2506 8902       \u2506 296.72102 \u2506 \u2026 \u2506 train \u2506 move_(tra \u2506 49        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 nsfer,_pa \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ss,_excha \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nge\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9199       \u2506 306.621029 \u2506 8959       \u2506 298.62102 \u2506 \u2026 \u2506 train \u2506 turn_(spi \u2506 99        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 n,_rotate \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ,_flip,_t \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 urn\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9269       \u2506 308.954362 \u2506 9029       \u2506 300.95436 \u2506 \u2026 \u2506 train \u2506 carry     \u2506 6         \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 2         \u2506   \u2506       \u2506           \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 eab\u2026      \u2502\n\u2502 9328       \u2506 310.921029 \u2506 9088       \u2506 302.92102 \u2506 \u2026 \u2506 train \u2506 turn_(spi \u2506 99        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 n,_rotate \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ,_flip,_t \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 urn\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9358       \u2506 311.921029 \u2506 9118       \u2506 303.92102 \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 eab\u2026      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n(vocab_noun): Vocabulary(vocab_size=521)\n(vocab_verb): Vocabulary(vocab_size=117)\n</code></pre>"},{"location":"datasets/ego4d/#prepare-the-data","title":"Prepare the data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.ego4d.prepare_data</code> to preprocess the raw data. It returns two outputs: the prepared data and the generate metadata.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.ego4d import prepare_data\n&gt;&gt;&gt; data, metadata = prepare_data(data_raw, metadata_raw)  # doctest: +SKIP\n</code></pre> <p><code>data</code> is a <code>polars.DataFrame</code> which contains the prepared data:</p> <pre><code>shape: (63_956, 12)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action_cli \u2506 action_cli \u2506 action_cli \u2506 action_cl \u2506 \u2026 \u2506 split \u2506 verb      \u2506 verb_labe \u2506 video_uid \u2502\n\u2502 p_end_fram \u2506 p_end_sec  \u2506 p_start_fr \u2506 ip_start_ \u2506   \u2506 ---   \u2506 ---       \u2506 l         \u2506 ---       \u2502\n\u2502 e          \u2506 ---        \u2506 ame        \u2506 sec       \u2506   \u2506 str   \u2506 str       \u2506 ---       \u2506 str       \u2502\n\u2502 ---        \u2506 f64        \u2506 ---        \u2506 ---       \u2506   \u2506       \u2506           \u2506 i64       \u2506           \u2502\n\u2502 i64        \u2506            \u2506 i64        \u2506 f64       \u2506   \u2506       \u2506           \u2506           \u2506           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 373        \u2506 12.421029  \u2506 133        \u2506 4.4210286 \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 426        \u2506 14.187695  \u2506 186        \u2506 6.187695  \u2506 \u2026 \u2506 train \u2506 take_(pic \u2506 92        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 k,_grab,_ \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 get)      \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 610        \u2506 20.321029  \u2506 370        \u2506 12.321029 \u2506 \u2026 \u2506 train \u2506 move_(tra \u2506 49        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nsfer,_pa \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ss,_excha \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nge\u2026      \u2506           \u2506 5b3\u2026      \u2502\n\u2502 537        \u2506 17.887695  \u2506 297        \u2506 9.887695  \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 550        \u2506 18.321029  \u2506 310        \u2506 10.321029 \u2506 \u2026 \u2506 train \u2506 remove    \u2506 67        \u2506 002d2729- \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 df71-438d \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 -8396-589 \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 5b3\u2026      \u2502\n\u2502 \u2026          \u2506 \u2026          \u2506 \u2026          \u2506 \u2026         \u2506 \u2026 \u2506 \u2026     \u2506 \u2026         \u2506 \u2026         \u2506 \u2026         \u2502\n\u2502 9142       \u2506 304.721029 \u2506 8902       \u2506 296.72102 \u2506 \u2026 \u2506 train \u2506 move_(tra \u2506 49        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 nsfer,_pa \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ss,_excha \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 nge\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9199       \u2506 306.621029 \u2506 8959       \u2506 298.62102 \u2506 \u2026 \u2506 train \u2506 turn_(spi \u2506 99        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 n,_rotate \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ,_flip,_t \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 urn\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9269       \u2506 308.954362 \u2506 9029       \u2506 300.95436 \u2506 \u2026 \u2506 train \u2506 carry     \u2506 6         \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 2         \u2506   \u2506       \u2506           \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 eab\u2026      \u2502\n\u2502 9328       \u2506 310.921029 \u2506 9088       \u2506 302.92102 \u2506 \u2026 \u2506 train \u2506 turn_(spi \u2506 99        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 n,_rotate \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 ,_flip,_t \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 urn\u2026      \u2506           \u2506 eab\u2026      \u2502\n\u2502 9358       \u2506 311.921029 \u2506 9118       \u2506 303.92102 \u2506 \u2026 \u2506 train \u2506 put_(plac \u2506 65        \u2506 ffb7ecf6- \u2502\n\u2502            \u2506            \u2506            \u2506 9         \u2506   \u2506       \u2506 e,_leave, \u2506           \u2506 f44e-499b \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506 _drop)    \u2506           \u2506 -b315-a4a \u2502\n\u2502            \u2506            \u2506            \u2506           \u2506   \u2506       \u2506           \u2506           \u2506 eab\u2026      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can note that new columns are added and the data types of some columns have changed. <code>metadata</code> contains a vocabulary that is used to generate the column <code>action_id</code>:</p> <pre><code>{'vocab_noun': Vocabulary(\n  counter=Counter({'apple': 1, 'apron': 1, 'arm': 1, 'artwork_(art,_draw,_drawing,_painting,_sketch)': 1, 'asparagus': 1, 'avocado': 1, 'awl': 1, 'axe': 1, 'baby': 1, 'bacon': 1, 'bag_(bag,_grocery,_nylon,_polythene,_pouch,_sachet,_sack,_suitcase)': 1, 'baking_soda': 1, 'ball_(ball,_baseball,_basketball)': 1, 'ball_bearing': 1, 'balloon': 1, 'banana_(banana,_plantain)': 1, 'bar': 1, 'baseboard': 1, 'basket': 1, 'bat_(sports)': 1, 'bat_(tool)': 1, 'bathtub': 1, 'batter_(batter,_mixture)': 1, 'battery': 1, 'bead': 1, 'beaker': 1, 'bean': 1, 'bed': 1, 'belt': 1, 'bench': 1, 'berry': 1, 'beverage_(drink,_juice,_beer,_beverage,_champagne)': 1, 'bicycle_(bicycle,_bike)': 1, 'blanket_(bedsheet,_blanket,_duvet)': 1, 'blender': 1, 'block_(material)': 1, 'blower': 1, 'bolt_extractor': 1, 'book_(book,_booklet,_magazine,_manual,_notebook,_novel,_page,_textbook)': 1, 'bookcase': 1, 'bottle_(bottle,_flask)': 1, 'bowl': 1, 'bracelet_(bangle,_bracelet)': 1, 'brake_(brake,_break)': 1, 'brake_pad': 1, 'branch': 1, 'bread_(bread,_bun,_chapati,_flatbread,_loaf,_roti,_tortilla)': 1, 'brick': 1, 'broccoli': 1, 'broom_(broom,_broomstick)': 1, 'brush': 1, 'bubble_gum': 1, 'bucket': 1, 'buckle': 1, 'burger': 1, 'butter': 1, 'butterfly': 1, 'button': 1, 'cabbage': 1, 'cabinet_(cabinet,_compartment,_cupboard)': 1, 'calculator': 1, 'caliper': 1, 'camera': 1, 'can_opener': 1, 'candle': 1, 'canvas': 1, 'car_(car,_vehicle)': 1, 'card': 1, 'cardboard_(cardboard,_paperboard)': 1, 'carpet': 1, 'carrot': 1, 'cart_(cart,_trolley)': 1, 'cat': 1, 'ceiling': 1, 'celery': 1, 'cello': 1, 'cement_(cement,_concrete,_mortar)': 1, 'cereal': 1, 'chaff': 1, 'chain': 1, 'chair': 1, 'chalk': 1, 'cheese': 1, 'chicken': 1, 'chip_(food)': 1, \"chip_(wood'_metal),\": 1, 'chip_(wood,_metal)': 1, 'chisel': 1, 'chocolate': 1, 'chopping_board': 1, 'chopstick': 1, 'cigarette_(cigarette,_vape)': 1, 'circuit': 1, 'clamp': 1, 'clay': 1, 'clip': 1, 'clock': 1, 'cloth_(cloth,_fabric,_garment,_kanga,_rag)': 1, 'coaster': 1, 'coconut': 1, 'coffee': 1, 'coffee_machine': 1, 'colander': 1, 'comb': 1, 'computer_(computer,_ipad,_laptop,_motherboard,_screen)': 1, 'container_(box,_can,_carton,_case,_casing,_container,_crate,_holder,_jar,_jerrycan,_keg,_pack,_package,_packaging,_packet,_storage,_tank,_tin)': 1, 'cooker': 1, 'cookie': 1, 'cork': 1, 'corn': 1, 'corner': 1, 'countertop_(counter,_countertop)': 1, 'crab': 1, 'cracker_(biscuit,_cracker)': 1, 'crayon': 1, 'cream': 1, 'crochet': 1, 'crowbar': 1, 'cucumber': 1, 'cup_(cup,_mug,_tumbler)': 1, 'curtain': 1, 'cushion': 1, 'cutter_(tool)': 1, 'decoration_(decoration,_ornament)': 1, 'derailleur': 1, 'detergent': 1, 'dice_(dice,_die)': 1, 'dishwasher': 1, 'dog': 1, 'door': 1, 'doorbell': 1, 'dough': 1, 'dough_mixer': 1, 'doughnut': 1, 'drawer': 1, 'dress': 1, 'drill_(drill,_driller)': 1, 'drill_bit': 1, 'drum': 1, 'dumbbell': 1, 'dust_(dust,_sawdust)': 1, 'duster': 1, 'dustpan': 1, 'egg': 1, 'eggplant': 1, 'engine_(assembly,_carburetor,_engine,_motor)': 1, 'envelope_(envelop,_envelope)': 1, 'eraser_(eraser,_rubber)': 1, 'facemask': 1, 'fan': 1, 'faucet_(faucet,_tap)': 1, 'fence': 1, 'file_(tool)': 1, 'filler': 1, 'filter': 1, 'fish': 1, 'fishing_rod': 1, 'flash_drive': 1, 'floor_(floor,_ground)': 1, 'flour': 1, 'flower': 1, 'foam': 1, 'foil': 1, 'food': 1, 'foot_(foot,_toe)': 1, 'fork': 1, 'fridge_(fridge,_refrigerator)': 1, 'fries': 1, 'fuel': 1, 'funnel': 1, 'game_controller': 1, 'garbage_can_(bin,_dustbin)': 1, 'garlic': 1, 'gasket': 1, 'gate': 1, 'gauge': 1, 'gauze': 1, 'gear': 1, 'generator': 1, 'ginger': 1, 'glass': 1, 'glasses_(goggle,_shade,_spectacle,_sunglass)': 1, 'glove': 1, 'glue_(adhesive,_glue,_gum,_sealant)': 1, 'glue_gun': 1, 'golf_club': 1, 'gourd': 1, 'grain': 1, 'grape': 1, 'grapefruit': 1, 'grass': 1, 'grater': 1, 'grill': 1, 'grinder': 1, 'guava': 1, 'guitar': 1, 'hair': 1, 'hammer_(hammer,_mallet)': 1, 'hand_(finger,_hand,_palm,_thumb)': 1, 'handle': 1, 'hanger': 1, 'hat': 1, 'hay': 1, 'haystack': 1, 'head': 1, 'headphones_(earphone,_headphone)': 1, 'heater': 1, 'helmet': 1, 'hinge': 1, 'hole': 1, 'horse': 1, 'hose': 1, 'house': 1, 'ice': 1, 'ice_cream': 1, 'ink': 1, 'iron': 1, 'jack_(tool)_(jack,_lift)': 1, 'jacket_(coat,_jacket)': 1, 'jug': 1, 'kale': 1, 'ketchup': 1, 'kettle': 1, 'key': 1, 'keyboard': 1, 'knife_(knife,_machete)': 1, 'label_(label,_tag)': 1, 'ladder': 1, 'leaf_(leaf,_leave)': 1, 'leash': 1, 'leg_(knee,_leg,_thigh)': 1, 'lemon': 1, 'lever': 1, 'lid_(cap,_cover,_lid)': 1, 'light_(bulb,_flashlight,_lamp,_light)': 1, 'lighter': 1, 'lime': 1, 'lock': 1, 'lubricant_(grease,_lubricant)': 1, 'magnet_(magnet,_sphere)': 1, 'mango': 1, 'manure_(dung,_manure)': 1, 'mask': 1, 'mat_(mat,_rug)': 1, 'matchstick': 1, 'meat_(beef,_ham,_meat)': 1, 'medicine': 1, 'metal_(lead,_metal,_steel)': 1, 'microscope': 1, 'microwave': 1, 'milk': 1, 'mirror': 1, 'mixer': 1, 'mold_(mold,_molder,_mould)': 1, 'money_(cash,_coin,_money)': 1, 'mop': 1, 'motorcycle_(motorbike,_motorcycle)': 1, 'mouse_(computer)': 1, 'mouth': 1, 'mower_(lawnmower,_mower)': 1, 'multimeter': 1, 'mushroom': 1, 'nail_cutter': 1, 'nail_gun': 1, 'nail_polish': 1, 'napkin_(handkerchief,_napkin,_serviette,_tissue,_wipe)': 1, 'necklace': 1, 'needle_(hook,_needle)': 1, 'net': 1, 'nozzle': 1, 'nut_(food)': 1, 'nut_(tool)': 1, 'oil_(fat,_oil)': 1, 'okra': 1, 'onion': 1, 'oven': 1, 'paddle': 1, 'paint': 1, 'paint_roller': 1, 'paintbrush': 1, 'palette': 1, 'pan_(frypan,_pan,_saucepan)': 1, 'pancake': 1, 'panel': 1, 'pants_(jean,_pant,_short,_trouser)': 1, 'papaya': 1, 'paper_(chart,_craft,_newspaper,_note,_paper,_papercraft,_poster,_receipt)': 1, 'pasta_(noodle,_pasta,_spaghetti)': 1, 'paste': 1, 'pastry': 1, 'pea': 1, 'peanut': 1, 'pear': 1, 'pedal': 1, 'peel': 1, 'peeler': 1, 'peg': 1, 'pen_(marker,_pen)': 1, 'pencil': 1, 'pepper_(vegetable)_(capsicum,_pepper)': 1, 'phone_(cellphone,_phone,_smartphone)': 1, 'photo': 1, 'piano': 1, 'pickle': 1, 'picture_(picture,_portrait)': 1, 'pie': 1, 'pillow': 1, 'pilot_jet': 1, 'pin': 1, 'pipe': 1, 'pizza': 1, 'planer_(plane,_planer)': 1, 'plant_(bud,_frond,_plant,_reed,_seedling,_shrub,_stem,_vine,_weed)': 1, 'plate_(dish,_plate,_platter,_saucer)': 1, 'playing_cards': 1, 'plier': 1, 'plug': 1, 'pole': 1, 'popcorn': 1, 'pot': 1, 'pot_(planter)': 1, 'potato': 1, 'pump': 1, 'pumpkin': 1, 'purse': 1, 'puzzle_or_game_piece_(chess,_domino,_jenga,_jigsaw,_pawn,_puzzle)': 1, 'rack': 1, 'radio': 1, 'rail_(rail,_railing)': 1, 'rake': 1, 'razor_blade': 1, 'remote_control_(control,_remote)': 1, 'rice': 1, 'ring': 1, 'rod_(dipstick,_rod,_rod_metal,_shaft)': 1, 'rolling_pin': 1, 'root': 1, 'rope': 1, 'router': 1, 'rubber_band': 1, 'ruler_(rule,_ruler)': 1, 'sand': 1, 'sander': 1, 'sandpaper': 1, 'sandwich': 1, 'sauce': 1, 'sausage': 1, 'saw_(chainsaw,_saw,_hacksaw)': 1, 'scarf_(scarf,_shawl)': 1, 'scissors': 1, 'scoop_(scoop,_scooper)': 1, 'scraper_(scraper,_scrapper)': 1, 'screw_(bolt,_nail,_screw)': 1, 'screwdriver': 1, 'sculpture': 1, 'seasoning_(salt,_seasoning,_shaker,_spice,_sugar)': 1, 'seed': 1, 'set_square_(tool)': 1, 'sewing_machine': 1, 'sharpener': 1, 'shears': 1, 'sheet': 1, 'shelf': 1, 'shell_(egg_shell,_shell_egg)': 1, 'shirt_(cardigan,_shirt,_sweater,_sweatshirt,_top)': 1, 'shoe_(boot,_sandal,_shoe,_slipper)': 1, 'shovel_(hoe,_shovel,_spade)': 1, 'shower_head': 1, 'sickle': 1, 'sieve_(sieve,_strainer)': 1, 'sink_(basin,_sink)': 1, 'sketch_pad': 1, 'skirt': 1, 'slab': 1, 'snorkel': 1, 'soap': 1, 'sock': 1, 'socket': 1, 'sofa': 1, 'soil_(dirt,_mud,_soil)': 1, 'solder_iron': 1, 'soup': 1, 'spacer': 1, 'spatula': 1, 'speaker': 1, 'sphygmomanometer': 1, 'spice': 1, 'spinach': 1, 'spirit_level': 1, 'sponge_(scrubber,_sponge)': 1, 'spoon_(spoon,_spoonful)': 1, 'spray_(spray,_sprayer)': 1, 'spring': 1, 'squeezer': 1, 'stairs_(stair,_staircase)': 1, 'stamp': 1, 'stapler': 1, 'steamer': 1, 'steering_wheel': 1, 'stick_(stick,_twig)': 1, 'sticker': 1, 'stock_(food)': 1, 'stone_(rock,_stone)': 1, 'stool': 1, 'stove_(burner,_gas,_stove)': 1, 'strap': 1, 'straw': 1, 'string_(bobbin,_knot,_lace,_ribbon,_spool,_strand,_string,_thread,_twine,_wool,_yarn)': 1, 'stroller': 1, 'switch_(knob,_switch)': 1, 'syringe': 1, 'table_(stand,_table)': 1, 'tablet': 1, 'taco': 1, 'tape_(cellotape,_sellotape,_tape)': 1, 'tape_measure_(measure,_measurement)': 1, 'tea': 1, 'teapot': 1, 'television_(television,_tv)': 1, 'tent': 1, 'test_tube': 1, 'tie': 1, 'tile': 1, 'timer': 1, 'toaster': 1, 'toilet': 1, 'toilet_paper': 1, 'tomato': 1, 'tongs': 1, 'toolbox': 1, 'toothbrush': 1, 'toothpick': 1, 'torch_(torch,_torchlight)': 1, 'towel': 1, 'toy_(doll,_toy)': 1, 'tractor': 1, 'trash_(debris,_garbage,_litter,_trash,_waste)': 1, 'tray': 1, 'treadmill': 1, 'tree': 1, 'trimmer_(pruner,_trimmer)': 1, 'trowel': 1, 'truck': 1, 'tweezer': 1, 'umbrella': 1, 'undergarment_(boxer,_bra)': 1, 'vacuum': 1, 'vacuum_cleaner': 1, 'valve': 1, 'vase': 1, 'video_game': 1, 'violin': 1, 'wall': 1, 'wallet': 1, 'wallpaper': 1, 'washing_machine': 1, 'watch': 1, 'water': 1, 'watermelon': 1, 'weighing_scale': 1, 'welding_torch': 1, 'wheat_(maize,_wheat)': 1, 'wheel_(tyre,_wheel)': 1, 'wheelbarrow': 1, 'whisk': 1, 'window': 1, 'windshield': 1, 'wiper_(car)': 1, 'wire_(adapter,_cable,_charger,_connector,_cord,_wire)': 1, 'wood_(fiber,_firewood,_floorboard,_log,_lumber,_plank,_plywood,_timber,_wood,_woodcraft,_woodwork)': 1, 'worm': 1, 'wrapper_(covering,_film,_seal,_wrap,_wrapper,_wrapping)': 1, 'wrench_(spanner,_wrench)': 1, 'yam': 1, 'yeast': 1, 'yoghurt': 1, 'zipper_(zip,_zipper)': 1, 'zucchini': 1, 'ambulance': 1, 'back': 1, 'bamboo': 1, 'bandage': 1, 'baton': 1, 'bird': 1, 'brownie': 1, 'cake': 1, 'cash_register': 1, 'cassava': 1, 'cocoa': 1, 'courgette': 1, 'cow': 1, 'cupcake': 1, 'drone': 1, 'earplug': 1, 'hotdog': 1, 'juicer': 1, 'kiwi': 1, 'ladle': 1, 'leek': 1, 'lettuce': 1, 'marble': 1, 'melon': 1, 'orange': 1, 'peach': 1, 'person_(herself,_himself,_lady,_man,_person,_shoulder,_they,_woman)': 1, 'pipette': 1, 'plum': 1, 'plunger': 1, 'printer': 1, 'putty': 1, 'racket': 1, 'ratchet': 1, 'road': 1, 'salad': 1, 'scaffold': 1, 'squash': 1, 'stereo': 1, 'strawberry': 1, 'thermometer': 1, 'transistor': 1, 'vinegar': 1}),\n  index_to_token=('apple', 'apron', 'arm', 'artwork_(art,_draw,_drawing,_painting,_sketch)', 'asparagus', 'avocado', 'awl', 'axe', 'baby', 'bacon', 'bag_(bag,_grocery,_nylon,_polythene,_pouch,_sachet,_sack,_suitcase)', 'baking_soda', 'ball_(ball,_baseball,_basketball)', 'ball_bearing', 'balloon', 'banana_(banana,_plantain)', 'bar', 'baseboard', 'basket', 'bat_(sports)', 'bat_(tool)', 'bathtub', 'batter_(batter,_mixture)', 'battery', 'bead', 'beaker', 'bean', 'bed', 'belt', 'bench', 'berry', 'beverage_(drink,_juice,_beer,_beverage,_champagne)', 'bicycle_(bicycle,_bike)', 'blanket_(bedsheet,_blanket,_duvet)', 'blender', 'block_(material)', 'blower', 'bolt_extractor', 'book_(book,_booklet,_magazine,_manual,_notebook,_novel,_page,_textbook)', 'bookcase', 'bottle_(bottle,_flask)', 'bowl', 'bracelet_(bangle,_bracelet)', 'brake_(brake,_break)', 'brake_pad', 'branch', 'bread_(bread,_bun,_chapati,_flatbread,_loaf,_roti,_tortilla)', 'brick', 'broccoli', 'broom_(broom,_broomstick)', 'brush', 'bubble_gum', 'bucket', 'buckle', 'burger', 'butter', 'butterfly', 'button', 'cabbage', 'cabinet_(cabinet,_compartment,_cupboard)', 'calculator', 'caliper', 'camera', 'can_opener', 'candle', 'canvas', 'car_(car,_vehicle)', 'card', 'cardboard_(cardboard,_paperboard)', 'carpet', 'carrot', 'cart_(cart,_trolley)', 'cat', 'ceiling', 'celery', 'cello', 'cement_(cement,_concrete,_mortar)', 'cereal', 'chaff', 'chain', 'chair', 'chalk', 'cheese', 'chicken', 'chip_(food)', \"chip_(wood'_metal),\", 'chip_(wood,_metal)', 'chisel', 'chocolate', 'chopping_board', 'chopstick', 'cigarette_(cigarette,_vape)', 'circuit', 'clamp', 'clay', 'clip', 'clock', 'cloth_(cloth,_fabric,_garment,_kanga,_rag)', 'coaster', 'coconut', 'coffee', 'coffee_machine', 'colander', 'comb', 'computer_(computer,_ipad,_laptop,_motherboard,_screen)', 'container_(box,_can,_carton,_case,_casing,_container,_crate,_holder,_jar,_jerrycan,_keg,_pack,_package,_packaging,_packet,_storage,_tank,_tin)', 'cooker', 'cookie', 'cork', 'corn', 'corner', 'countertop_(counter,_countertop)', 'crab', 'cracker_(biscuit,_cracker)', 'crayon', 'cream', 'crochet', 'crowbar', 'cucumber', 'cup_(cup,_mug,_tumbler)', 'curtain', 'cushion', 'cutter_(tool)', 'decoration_(decoration,_ornament)', 'derailleur', 'detergent', 'dice_(dice,_die)', 'dishwasher', 'dog', 'door', 'doorbell', 'dough', 'dough_mixer', 'doughnut', 'drawer', 'dress', 'drill_(drill,_driller)', 'drill_bit', 'drum', 'dumbbell', 'dust_(dust,_sawdust)', 'duster', 'dustpan', 'egg', 'eggplant', 'engine_(assembly,_carburetor,_engine,_motor)', 'envelope_(envelop,_envelope)', 'eraser_(eraser,_rubber)', 'facemask', 'fan', 'faucet_(faucet,_tap)', 'fence', 'file_(tool)', 'filler', 'filter', 'fish', 'fishing_rod', 'flash_drive', 'floor_(floor,_ground)', 'flour', 'flower', 'foam', 'foil', 'food', 'foot_(foot,_toe)', 'fork', 'fridge_(fridge,_refrigerator)', 'fries', 'fuel', 'funnel', 'game_controller', 'garbage_can_(bin,_dustbin)', 'garlic', 'gasket', 'gate', 'gauge', 'gauze', 'gear', 'generator', 'ginger', 'glass', 'glasses_(goggle,_shade,_spectacle,_sunglass)', 'glove', 'glue_(adhesive,_glue,_gum,_sealant)', 'glue_gun', 'golf_club', 'gourd', 'grain', 'grape', 'grapefruit', 'grass', 'grater', 'grill', 'grinder', 'guava', 'guitar', 'hair', 'hammer_(hammer,_mallet)', 'hand_(finger,_hand,_palm,_thumb)', 'handle', 'hanger', 'hat', 'hay', 'haystack', 'head', 'headphones_(earphone,_headphone)', 'heater', 'helmet', 'hinge', 'hole', 'horse', 'hose', 'house', 'ice', 'ice_cream', 'ink', 'iron', 'jack_(tool)_(jack,_lift)', 'jacket_(coat,_jacket)', 'jug', 'kale', 'ketchup', 'kettle', 'key', 'keyboard', 'knife_(knife,_machete)', 'label_(label,_tag)', 'ladder', 'leaf_(leaf,_leave)', 'leash', 'leg_(knee,_leg,_thigh)', 'lemon', 'lever', 'lid_(cap,_cover,_lid)', 'light_(bulb,_flashlight,_lamp,_light)', 'lighter', 'lime', 'lock', 'lubricant_(grease,_lubricant)', 'magnet_(magnet,_sphere)', 'mango', 'manure_(dung,_manure)', 'mask', 'mat_(mat,_rug)', 'matchstick', 'meat_(beef,_ham,_meat)', 'medicine', 'metal_(lead,_metal,_steel)', 'microscope', 'microwave', 'milk', 'mirror', 'mixer', 'mold_(mold,_molder,_mould)', 'money_(cash,_coin,_money)', 'mop', 'motorcycle_(motorbike,_motorcycle)', 'mouse_(computer)', 'mouth', 'mower_(lawnmower,_mower)', 'multimeter', 'mushroom', 'nail_cutter', 'nail_gun', 'nail_polish', 'napkin_(handkerchief,_napkin,_serviette,_tissue,_wipe)', 'necklace', 'needle_(hook,_needle)', 'net', 'nozzle', 'nut_(food)', 'nut_(tool)', 'oil_(fat,_oil)', 'okra', 'onion', 'oven', 'paddle', 'paint', 'paint_roller', 'paintbrush', 'palette', 'pan_(frypan,_pan,_saucepan)', 'pancake', 'panel', 'pants_(jean,_pant,_short,_trouser)', 'papaya', 'paper_(chart,_craft,_newspaper,_note,_paper,_papercraft,_poster,_receipt)', 'pasta_(noodle,_pasta,_spaghetti)', 'paste', 'pastry', 'pea', 'peanut', 'pear', 'pedal', 'peel', 'peeler', 'peg', 'pen_(marker,_pen)', 'pencil', 'pepper_(vegetable)_(capsicum,_pepper)', 'phone_(cellphone,_phone,_smartphone)', 'photo', 'piano', 'pickle', 'picture_(picture,_portrait)', 'pie', 'pillow', 'pilot_jet', 'pin', 'pipe', 'pizza', 'planer_(plane,_planer)', 'plant_(bud,_frond,_plant,_reed,_seedling,_shrub,_stem,_vine,_weed)', 'plate_(dish,_plate,_platter,_saucer)', 'playing_cards', 'plier', 'plug', 'pole', 'popcorn', 'pot', 'pot_(planter)', 'potato', 'pump', 'pumpkin', 'purse', 'puzzle_or_game_piece_(chess,_domino,_jenga,_jigsaw,_pawn,_puzzle)', 'rack', 'radio', 'rail_(rail,_railing)', 'rake', 'razor_blade', 'remote_control_(control,_remote)', 'rice', 'ring', 'rod_(dipstick,_rod,_rod_metal,_shaft)', 'rolling_pin', 'root', 'rope', 'router', 'rubber_band', 'ruler_(rule,_ruler)', 'sand', 'sander', 'sandpaper', 'sandwich', 'sauce', 'sausage', 'saw_(chainsaw,_saw,_hacksaw)', 'scarf_(scarf,_shawl)', 'scissors', 'scoop_(scoop,_scooper)', 'scraper_(scraper,_scrapper)', 'screw_(bolt,_nail,_screw)', 'screwdriver', 'sculpture', 'seasoning_(salt,_seasoning,_shaker,_spice,_sugar)', 'seed', 'set_square_(tool)', 'sewing_machine', 'sharpener', 'shears', 'sheet', 'shelf', 'shell_(egg_shell,_shell_egg)', 'shirt_(cardigan,_shirt,_sweater,_sweatshirt,_top)', 'shoe_(boot,_sandal,_shoe,_slipper)', 'shovel_(hoe,_shovel,_spade)', 'shower_head', 'sickle', 'sieve_(sieve,_strainer)', 'sink_(basin,_sink)', 'sketch_pad', 'skirt', 'slab', 'snorkel', 'soap', 'sock', 'socket', 'sofa', 'soil_(dirt,_mud,_soil)', 'solder_iron', 'soup', 'spacer', 'spatula', 'speaker', 'sphygmomanometer', 'spice', 'spinach', 'spirit_level', 'sponge_(scrubber,_sponge)', 'spoon_(spoon,_spoonful)', 'spray_(spray,_sprayer)', 'spring', 'squeezer', 'stairs_(stair,_staircase)', 'stamp', 'stapler', 'steamer', 'steering_wheel', 'stick_(stick,_twig)', 'sticker', 'stock_(food)', 'stone_(rock,_stone)', 'stool', 'stove_(burner,_gas,_stove)', 'strap', 'straw', 'string_(bobbin,_knot,_lace,_ribbon,_spool,_strand,_string,_thread,_twine,_wool,_yarn)', 'stroller', 'switch_(knob,_switch)', 'syringe', 'table_(stand,_table)', 'tablet', 'taco', 'tape_(cellotape,_sellotape,_tape)', 'tape_measure_(measure,_measurement)', 'tea', 'teapot', 'television_(television,_tv)', 'tent', 'test_tube', 'tie', 'tile', 'timer', 'toaster', 'toilet', 'toilet_paper', 'tomato', 'tongs', 'toolbox', 'toothbrush', 'toothpick', 'torch_(torch,_torchlight)', 'towel', 'toy_(doll,_toy)', 'tractor', 'trash_(debris,_garbage,_litter,_trash,_waste)', 'tray', 'treadmill', 'tree', 'trimmer_(pruner,_trimmer)', 'trowel', 'truck', 'tweezer', 'umbrella', 'undergarment_(boxer,_bra)', 'vacuum', 'vacuum_cleaner', 'valve', 'vase', 'video_game', 'violin', 'wall', 'wallet', 'wallpaper', 'washing_machine', 'watch', 'water', 'watermelon', 'weighing_scale', 'welding_torch', 'wheat_(maize,_wheat)', 'wheel_(tyre,_wheel)', 'wheelbarrow', 'whisk', 'window', 'windshield', 'wiper_(car)', 'wire_(adapter,_cable,_charger,_connector,_cord,_wire)', 'wood_(fiber,_firewood,_floorboard,_log,_lumber,_plank,_plywood,_timber,_wood,_woodcraft,_woodwork)', 'worm', 'wrapper_(covering,_film,_seal,_wrap,_wrapper,_wrapping)', 'wrench_(spanner,_wrench)', 'yam', 'yeast', 'yoghurt', 'zipper_(zip,_zipper)', 'zucchini', 'ambulance', 'back', 'bamboo', 'bandage', 'baton', 'bird', 'brownie', 'cake', 'cash_register', 'cassava', 'cocoa', 'courgette', 'cow', 'cupcake', 'drone', 'earplug', 'hotdog', 'juicer', 'kiwi', 'ladle', 'leek', 'lettuce', 'marble', 'melon', 'orange', 'peach', 'person_(herself,_himself,_lady,_man,_person,_shoulder,_they,_woman)', 'pipette', 'plum', 'plunger', 'printer', 'putty', 'racket', 'ratchet', 'road', 'salad', 'scaffold', 'squash', 'stereo', 'strawberry', 'thermometer', 'transistor', 'vinegar'),\n  token_to_index={'apple': 0, 'apron': 1, 'arm': 2, 'artwork_(art,_draw,_drawing,_painting,_sketch)': 3, 'asparagus': 4, 'avocado': 5, 'awl': 6, 'axe': 7, 'baby': 8, 'bacon': 9, 'bag_(bag,_grocery,_nylon,_polythene,_pouch,_sachet,_sack,_suitcase)': 10, 'baking_soda': 11, 'ball_(ball,_baseball,_basketball)': 12, 'ball_bearing': 13, 'balloon': 14, 'banana_(banana,_plantain)': 15, 'bar': 16, 'baseboard': 17, 'basket': 18, 'bat_(sports)': 19, 'bat_(tool)': 20, 'bathtub': 21, 'batter_(batter,_mixture)': 22, 'battery': 23, 'bead': 24, 'beaker': 25, 'bean': 26, 'bed': 27, 'belt': 28, 'bench': 29, 'berry': 30, 'beverage_(drink,_juice,_beer,_beverage,_champagne)': 31, 'bicycle_(bicycle,_bike)': 32, 'blanket_(bedsheet,_blanket,_duvet)': 33, 'blender': 34, 'block_(material)': 35, 'blower': 36, 'bolt_extractor': 37, 'book_(book,_booklet,_magazine,_manual,_notebook,_novel,_page,_textbook)': 38, 'bookcase': 39, 'bottle_(bottle,_flask)': 40, 'bowl': 41, 'bracelet_(bangle,_bracelet)': 42, 'brake_(brake,_break)': 43, 'brake_pad': 44, 'branch': 45, 'bread_(bread,_bun,_chapati,_flatbread,_loaf,_roti,_tortilla)': 46, 'brick': 47, 'broccoli': 48, 'broom_(broom,_broomstick)': 49, 'brush': 50, 'bubble_gum': 51, 'bucket': 52, 'buckle': 53, 'burger': 54, 'butter': 55, 'butterfly': 56, 'button': 57, 'cabbage': 58, 'cabinet_(cabinet,_compartment,_cupboard)': 59, 'calculator': 60, 'caliper': 61, 'camera': 62, 'can_opener': 63, 'candle': 64, 'canvas': 65, 'car_(car,_vehicle)': 66, 'card': 67, 'cardboard_(cardboard,_paperboard)': 68, 'carpet': 69, 'carrot': 70, 'cart_(cart,_trolley)': 71, 'cat': 72, 'ceiling': 73, 'celery': 74, 'cello': 75, 'cement_(cement,_concrete,_mortar)': 76, 'cereal': 77, 'chaff': 78, 'chain': 79, 'chair': 80, 'chalk': 81, 'cheese': 82, 'chicken': 83, 'chip_(food)': 84, \"chip_(wood'_metal),\": 85, 'chip_(wood,_metal)': 86, 'chisel': 87, 'chocolate': 88, 'chopping_board': 89, 'chopstick': 90, 'cigarette_(cigarette,_vape)': 91, 'circuit': 92, 'clamp': 93, 'clay': 94, 'clip': 95, 'clock': 96, 'cloth_(cloth,_fabric,_garment,_kanga,_rag)': 97, 'coaster': 98, 'coconut': 99, 'coffee': 100, 'coffee_machine': 101, 'colander': 102, 'comb': 103, 'computer_(computer,_ipad,_laptop,_motherboard,_screen)': 104, 'container_(box,_can,_carton,_case,_casing,_container,_crate,_holder,_jar,_jerrycan,_keg,_pack,_package,_packaging,_packet,_storage,_tank,_tin)': 105, 'cooker': 106, 'cookie': 107, 'cork': 108, 'corn': 109, 'corner': 110, 'countertop_(counter,_countertop)': 111, 'crab': 112, 'cracker_(biscuit,_cracker)': 113, 'crayon': 114, 'cream': 115, 'crochet': 116, 'crowbar': 117, 'cucumber': 118, 'cup_(cup,_mug,_tumbler)': 119, 'curtain': 120, 'cushion': 121, 'cutter_(tool)': 122, 'decoration_(decoration,_ornament)': 123, 'derailleur': 124, 'detergent': 125, 'dice_(dice,_die)': 126, 'dishwasher': 127, 'dog': 128, 'door': 129, 'doorbell': 130, 'dough': 131, 'dough_mixer': 132, 'doughnut': 133, 'drawer': 134, 'dress': 135, 'drill_(drill,_driller)': 136, 'drill_bit': 137, 'drum': 138, 'dumbbell': 139, 'dust_(dust,_sawdust)': 140, 'duster': 141, 'dustpan': 142, 'egg': 143, 'eggplant': 144, 'engine_(assembly,_carburetor,_engine,_motor)': 145, 'envelope_(envelop,_envelope)': 146, 'eraser_(eraser,_rubber)': 147, 'facemask': 148, 'fan': 149, 'faucet_(faucet,_tap)': 150, 'fence': 151, 'file_(tool)': 152, 'filler': 153, 'filter': 154, 'fish': 155, 'fishing_rod': 156, 'flash_drive': 157, 'floor_(floor,_ground)': 158, 'flour': 159, 'flower': 160, 'foam': 161, 'foil': 162, 'food': 163, 'foot_(foot,_toe)': 164, 'fork': 165, 'fridge_(fridge,_refrigerator)': 166, 'fries': 167, 'fuel': 168, 'funnel': 169, 'game_controller': 170, 'garbage_can_(bin,_dustbin)': 171, 'garlic': 172, 'gasket': 173, 'gate': 174, 'gauge': 175, 'gauze': 176, 'gear': 177, 'generator': 178, 'ginger': 179, 'glass': 180, 'glasses_(goggle,_shade,_spectacle,_sunglass)': 181, 'glove': 182, 'glue_(adhesive,_glue,_gum,_sealant)': 183, 'glue_gun': 184, 'golf_club': 185, 'gourd': 186, 'grain': 187, 'grape': 188, 'grapefruit': 189, 'grass': 190, 'grater': 191, 'grill': 192, 'grinder': 193, 'guava': 194, 'guitar': 195, 'hair': 196, 'hammer_(hammer,_mallet)': 197, 'hand_(finger,_hand,_palm,_thumb)': 198, 'handle': 199, 'hanger': 200, 'hat': 201, 'hay': 202, 'haystack': 203, 'head': 204, 'headphones_(earphone,_headphone)': 205, 'heater': 206, 'helmet': 207, 'hinge': 208, 'hole': 209, 'horse': 210, 'hose': 211, 'house': 212, 'ice': 213, 'ice_cream': 214, 'ink': 215, 'iron': 216, 'jack_(tool)_(jack,_lift)': 217, 'jacket_(coat,_jacket)': 218, 'jug': 219, 'kale': 220, 'ketchup': 221, 'kettle': 222, 'key': 223, 'keyboard': 224, 'knife_(knife,_machete)': 225, 'label_(label,_tag)': 226, 'ladder': 227, 'leaf_(leaf,_leave)': 228, 'leash': 229, 'leg_(knee,_leg,_thigh)': 230, 'lemon': 231, 'lever': 232, 'lid_(cap,_cover,_lid)': 233, 'light_(bulb,_flashlight,_lamp,_light)': 234, 'lighter': 235, 'lime': 236, 'lock': 237, 'lubricant_(grease,_lubricant)': 238, 'magnet_(magnet,_sphere)': 239, 'mango': 240, 'manure_(dung,_manure)': 241, 'mask': 242, 'mat_(mat,_rug)': 243, 'matchstick': 244, 'meat_(beef,_ham,_meat)': 245, 'medicine': 246, 'metal_(lead,_metal,_steel)': 247, 'microscope': 248, 'microwave': 249, 'milk': 250, 'mirror': 251, 'mixer': 252, 'mold_(mold,_molder,_mould)': 253, 'money_(cash,_coin,_money)': 254, 'mop': 255, 'motorcycle_(motorbike,_motorcycle)': 256, 'mouse_(computer)': 257, 'mouth': 258, 'mower_(lawnmower,_mower)': 259, 'multimeter': 260, 'mushroom': 261, 'nail_cutter': 262, 'nail_gun': 263, 'nail_polish': 264, 'napkin_(handkerchief,_napkin,_serviette,_tissue,_wipe)': 265, 'necklace': 266, 'needle_(hook,_needle)': 267, 'net': 268, 'nozzle': 269, 'nut_(food)': 270, 'nut_(tool)': 271, 'oil_(fat,_oil)': 272, 'okra': 273, 'onion': 274, 'oven': 275, 'paddle': 276, 'paint': 277, 'paint_roller': 278, 'paintbrush': 279, 'palette': 280, 'pan_(frypan,_pan,_saucepan)': 281, 'pancake': 282, 'panel': 283, 'pants_(jean,_pant,_short,_trouser)': 284, 'papaya': 285, 'paper_(chart,_craft,_newspaper,_note,_paper,_papercraft,_poster,_receipt)': 286, 'pasta_(noodle,_pasta,_spaghetti)': 287, 'paste': 288, 'pastry': 289, 'pea': 290, 'peanut': 291, 'pear': 292, 'pedal': 293, 'peel': 294, 'peeler': 295, 'peg': 296, 'pen_(marker,_pen)': 297, 'pencil': 298, 'pepper_(vegetable)_(capsicum,_pepper)': 299, 'phone_(cellphone,_phone,_smartphone)': 300, 'photo': 301, 'piano': 302, 'pickle': 303, 'picture_(picture,_portrait)': 304, 'pie': 305, 'pillow': 306, 'pilot_jet': 307, 'pin': 308, 'pipe': 309, 'pizza': 310, 'planer_(plane,_planer)': 311, 'plant_(bud,_frond,_plant,_reed,_seedling,_shrub,_stem,_vine,_weed)': 312, 'plate_(dish,_plate,_platter,_saucer)': 313, 'playing_cards': 314, 'plier': 315, 'plug': 316, 'pole': 317, 'popcorn': 318, 'pot': 319, 'pot_(planter)': 320, 'potato': 321, 'pump': 322, 'pumpkin': 323, 'purse': 324, 'puzzle_or_game_piece_(chess,_domino,_jenga,_jigsaw,_pawn,_puzzle)': 325, 'rack': 326, 'radio': 327, 'rail_(rail,_railing)': 328, 'rake': 329, 'razor_blade': 330, 'remote_control_(control,_remote)': 331, 'rice': 332, 'ring': 333, 'rod_(dipstick,_rod,_rod_metal,_shaft)': 334, 'rolling_pin': 335, 'root': 336, 'rope': 337, 'router': 338, 'rubber_band': 339, 'ruler_(rule,_ruler)': 340, 'sand': 341, 'sander': 342, 'sandpaper': 343, 'sandwich': 344, 'sauce': 345, 'sausage': 346, 'saw_(chainsaw,_saw,_hacksaw)': 347, 'scarf_(scarf,_shawl)': 348, 'scissors': 349, 'scoop_(scoop,_scooper)': 350, 'scraper_(scraper,_scrapper)': 351, 'screw_(bolt,_nail,_screw)': 352, 'screwdriver': 353, 'sculpture': 354, 'seasoning_(salt,_seasoning,_shaker,_spice,_sugar)': 355, 'seed': 356, 'set_square_(tool)': 357, 'sewing_machine': 358, 'sharpener': 359, 'shears': 360, 'sheet': 361, 'shelf': 362, 'shell_(egg_shell,_shell_egg)': 363, 'shirt_(cardigan,_shirt,_sweater,_sweatshirt,_top)': 364, 'shoe_(boot,_sandal,_shoe,_slipper)': 365, 'shovel_(hoe,_shovel,_spade)': 366, 'shower_head': 367, 'sickle': 368, 'sieve_(sieve,_strainer)': 369, 'sink_(basin,_sink)': 370, 'sketch_pad': 371, 'skirt': 372, 'slab': 373, 'snorkel': 374, 'soap': 375, 'sock': 376, 'socket': 377, 'sofa': 378, 'soil_(dirt,_mud,_soil)': 379, 'solder_iron': 380, 'soup': 381, 'spacer': 382, 'spatula': 383, 'speaker': 384, 'sphygmomanometer': 385, 'spice': 386, 'spinach': 387, 'spirit_level': 388, 'sponge_(scrubber,_sponge)': 389, 'spoon_(spoon,_spoonful)': 390, 'spray_(spray,_sprayer)': 391, 'spring': 392, 'squeezer': 393, 'stairs_(stair,_staircase)': 394, 'stamp': 395, 'stapler': 396, 'steamer': 397, 'steering_wheel': 398, 'stick_(stick,_twig)': 399, 'sticker': 400, 'stock_(food)': 401, 'stone_(rock,_stone)': 402, 'stool': 403, 'stove_(burner,_gas,_stove)': 404, 'strap': 405, 'straw': 406, 'string_(bobbin,_knot,_lace,_ribbon,_spool,_strand,_string,_thread,_twine,_wool,_yarn)': 407, 'stroller': 408, 'switch_(knob,_switch)': 409, 'syringe': 410, 'table_(stand,_table)': 411, 'tablet': 412, 'taco': 413, 'tape_(cellotape,_sellotape,_tape)': 414, 'tape_measure_(measure,_measurement)': 415, 'tea': 416, 'teapot': 417, 'television_(television,_tv)': 418, 'tent': 419, 'test_tube': 420, 'tie': 421, 'tile': 422, 'timer': 423, 'toaster': 424, 'toilet': 425, 'toilet_paper': 426, 'tomato': 427, 'tongs': 428, 'toolbox': 429, 'toothbrush': 430, 'toothpick': 431, 'torch_(torch,_torchlight)': 432, 'towel': 433, 'toy_(doll,_toy)': 434, 'tractor': 435, 'trash_(debris,_garbage,_litter,_trash,_waste)': 436, 'tray': 437, 'treadmill': 438, 'tree': 439, 'trimmer_(pruner,_trimmer)': 440, 'trowel': 441, 'truck': 442, 'tweezer': 443, 'umbrella': 444, 'undergarment_(boxer,_bra)': 445, 'vacuum': 446, 'vacuum_cleaner': 447, 'valve': 448, 'vase': 449, 'video_game': 450, 'violin': 451, 'wall': 452, 'wallet': 453, 'wallpaper': 454, 'washing_machine': 455, 'watch': 456, 'water': 457, 'watermelon': 458, 'weighing_scale': 459, 'welding_torch': 460, 'wheat_(maize,_wheat)': 461, 'wheel_(tyre,_wheel)': 462, 'wheelbarrow': 463, 'whisk': 464, 'window': 465, 'windshield': 466, 'wiper_(car)': 467, 'wire_(adapter,_cable,_charger,_connector,_cord,_wire)': 468, 'wood_(fiber,_firewood,_floorboard,_log,_lumber,_plank,_plywood,_timber,_wood,_woodcraft,_woodwork)': 469, 'worm': 470, 'wrapper_(covering,_film,_seal,_wrap,_wrapper,_wrapping)': 471, 'wrench_(spanner,_wrench)': 472, 'yam': 473, 'yeast': 474, 'yoghurt': 475, 'zipper_(zip,_zipper)': 476, 'zucchini': 477, 'ambulance': 478, 'back': 479, 'bamboo': 480, 'bandage': 481, 'baton': 482, 'bird': 483, 'brownie': 484, 'cake': 485, 'cash_register': 486, 'cassava': 487, 'cocoa': 488, 'courgette': 489, 'cow': 490, 'cupcake': 491, 'drone': 492, 'earplug': 493, 'hotdog': 494, 'juicer': 495, 'kiwi': 496, 'ladle': 497, 'leek': 498, 'lettuce': 499, 'marble': 500, 'melon': 501, 'orange': 502, 'peach': 503, 'person_(herself,_himself,_lady,_man,_person,_shoulder,_they,_woman)': 504, 'pipette': 505, 'plum': 506, 'plunger': 507, 'printer': 508, 'putty': 509, 'racket': 510, 'ratchet': 511, 'road': 512, 'salad': 513, 'scaffold': 514, 'squash': 515, 'stereo': 516, 'strawberry': 517, 'thermometer': 518, 'transistor': 519, 'vinegar': 520},\n),\n'vocab_verb': Vocabulary(\n  counter=Counter({'adjust_(regulate,_increase/reduce,_change)': 1, 'apply_(spread,_smear)': 1, 'arrange_(straighten,_sort,_distribute,_align)': 1, 'attach_(plug-in,_join,_fasten,_connect,_attach)': 1, 'blow': 1, 'break': 1, 'carry': 1, 'catch': 1, 'clap': 1, 'clean_(sweep,_scrub,_mop,_dust)': 1, 'climb': 1, 'close': 1, 'consume_(taste,_sip,_eat,_drink)': 1, 'count': 1, 'cover': 1, 'crochet': 1, 'cut_(trim,_slice,_chop)': 1, 'detach_(unplug,_unhook,_disconnect)': 1, 'dig': 1, 'dip': 1, 'divide_(split,_separate)': 1, 'draw': 1, 'drill': 1, 'drive_(ride,_drive)': 1, 'enter': 1, 'feed': 1, 'file_(with_tool)': 1, 'fill': 1, 'fold': 1, 'fry': 1, 'give': 1, 'grate': 1, 'grind': 1, 'hang': 1, 'hit_(knock,_hit,_hammer)': 1, 'hold_(support,_grip,_grasp)': 1, 'insert': 1, 'inspect_(check,_look,_examine,_view)': 1, 'iron': 1, 'kick': 1, 'knead': 1, 'knit': 1, 'lift': 1, 'lock': 1, 'loosen': 1, 'mark': 1, 'measure_(weigh,_measure)': 1, 'mix': 1, 'mold': 1, 'move_(transfer,_pass,_exchange)': 1, 'open': 1, 'operate_(use,_dial,_click-button)': 1, 'pack': 1, 'paint': 1, 'park': 1, 'peel': 1, 'pet': 1, 'plant': 1, 'play': 1, 'point': 1, 'pour': 1, 'press': 1, 'pull': 1, 'pump': 1, 'push': 1, 'put_(place,_leave,_drop)': 1, 'read': 1, 'remove': 1, 'repair': 1, 'roll': 1, 'sand': 1, 'scoop': 1, 'scrape': 1, 'screw': 1, 'scroll': 1, 'search': 1, 'serve': 1, 'sew_(weave,_stitch,_sew)': 1, 'shake': 1, 'sharpen': 1, 'shuffle': 1, 'sieve': 1, 'sit': 1, 'smooth': 1, 'spray': 1, 'sprinkle': 1, 'squeeze': 1, 'stand': 1, 'step': 1, 'stick_(tape,_stick,_glue)': 1, 'stretch': 1, 'swing': 1, 'take_(pick,_grab,_get)': 1, 'talk_(talk,_interact,_converse)': 1, 'throw_(toss,_dump,_dispose)': 1, 'tie': 1, 'tighten': 1, 'tilt': 1, 'touch': 1, 'turn_(spin,_rotate,_flip,_turn_over)': 1, 'turn_off_(turn_off,_switch_off)': 1, 'turn_on_(switch_on,_start,_light)': 1, 'uncover': 1, 'unfold': 1, 'unroll': 1, 'unscrew': 1, 'untie': 1, 'walk': 1, 'wash': 1, 'water': 1, 'wear': 1, 'weld': 1, 'wipe': 1, 'write': 1, 'zip': 1, 'watch': 1, 'wave': 1}),\n  index_to_token=('adjust_(regulate,_increase/reduce,_change)', 'apply_(spread,_smear)', 'arrange_(straighten,_sort,_distribute,_align)', 'attach_(plug-in,_join,_fasten,_connect,_attach)', 'blow', 'break', 'carry', 'catch', 'clap', 'clean_(sweep,_scrub,_mop,_dust)', 'climb', 'close', 'consume_(taste,_sip,_eat,_drink)', 'count', 'cover', 'crochet', 'cut_(trim,_slice,_chop)', 'detach_(unplug,_unhook,_disconnect)', 'dig', 'dip', 'divide_(split,_separate)', 'draw', 'drill', 'drive_(ride,_drive)', 'enter', 'feed', 'file_(with_tool)', 'fill', 'fold', 'fry', 'give', 'grate', 'grind', 'hang', 'hit_(knock,_hit,_hammer)', 'hold_(support,_grip,_grasp)', 'insert', 'inspect_(check,_look,_examine,_view)', 'iron', 'kick', 'knead', 'knit', 'lift', 'lock', 'loosen', 'mark', 'measure_(weigh,_measure)', 'mix', 'mold', 'move_(transfer,_pass,_exchange)', 'open', 'operate_(use,_dial,_click-button)', 'pack', 'paint', 'park', 'peel', 'pet', 'plant', 'play', 'point', 'pour', 'press', 'pull', 'pump', 'push', 'put_(place,_leave,_drop)', 'read', 'remove', 'repair', 'roll', 'sand', 'scoop', 'scrape', 'screw', 'scroll', 'search', 'serve', 'sew_(weave,_stitch,_sew)', 'shake', 'sharpen', 'shuffle', 'sieve', 'sit', 'smooth', 'spray', 'sprinkle', 'squeeze', 'stand', 'step', 'stick_(tape,_stick,_glue)', 'stretch', 'swing', 'take_(pick,_grab,_get)', 'talk_(talk,_interact,_converse)', 'throw_(toss,_dump,_dispose)', 'tie', 'tighten', 'tilt', 'touch', 'turn_(spin,_rotate,_flip,_turn_over)', 'turn_off_(turn_off,_switch_off)', 'turn_on_(switch_on,_start,_light)', 'uncover', 'unfold', 'unroll', 'unscrew', 'untie', 'walk', 'wash', 'water', 'wear', 'weld', 'wipe', 'write', 'zip', 'watch', 'wave'),\n  token_to_index={'adjust_(regulate,_increase/reduce,_change)': 0, 'apply_(spread,_smear)': 1, 'arrange_(straighten,_sort,_distribute,_align)': 2, 'attach_(plug-in,_join,_fasten,_connect,_attach)': 3, 'blow': 4, 'break': 5, 'carry': 6, 'catch': 7, 'clap': 8, 'clean_(sweep,_scrub,_mop,_dust)': 9, 'climb': 10, 'close': 11, 'consume_(taste,_sip,_eat,_drink)': 12, 'count': 13, 'cover': 14, 'crochet': 15, 'cut_(trim,_slice,_chop)': 16, 'detach_(unplug,_unhook,_disconnect)': 17, 'dig': 18, 'dip': 19, 'divide_(split,_separate)': 20, 'draw': 21, 'drill': 22, 'drive_(ride,_drive)': 23, 'enter': 24, 'feed': 25, 'file_(with_tool)': 26, 'fill': 27, 'fold': 28, 'fry': 29, 'give': 30, 'grate': 31, 'grind': 32, 'hang': 33, 'hit_(knock,_hit,_hammer)': 34, 'hold_(support,_grip,_grasp)': 35, 'insert': 36, 'inspect_(check,_look,_examine,_view)': 37, 'iron': 38, 'kick': 39, 'knead': 40, 'knit': 41, 'lift': 42, 'lock': 43, 'loosen': 44, 'mark': 45, 'measure_(weigh,_measure)': 46, 'mix': 47, 'mold': 48, 'move_(transfer,_pass,_exchange)': 49, 'open': 50, 'operate_(use,_dial,_click-button)': 51, 'pack': 52, 'paint': 53, 'park': 54, 'peel': 55, 'pet': 56, 'plant': 57, 'play': 58, 'point': 59, 'pour': 60, 'press': 61, 'pull': 62, 'pump': 63, 'push': 64, 'put_(place,_leave,_drop)': 65, 'read': 66, 'remove': 67, 'repair': 68, 'roll': 69, 'sand': 70, 'scoop': 71, 'scrape': 72, 'screw': 73, 'scroll': 74, 'search': 75, 'serve': 76, 'sew_(weave,_stitch,_sew)': 77, 'shake': 78, 'sharpen': 79, 'shuffle': 80, 'sieve': 81, 'sit': 82, 'smooth': 83, 'spray': 84, 'sprinkle': 85, 'squeeze': 86, 'stand': 87, 'step': 88, 'stick_(tape,_stick,_glue)': 89, 'stretch': 90, 'swing': 91, 'take_(pick,_grab,_get)': 92, 'talk_(talk,_interact,_converse)': 93, 'throw_(toss,_dump,_dispose)': 94, 'tie': 95, 'tighten': 96, 'tilt': 97, 'touch': 98, 'turn_(spin,_rotate,_flip,_turn_over)': 99, 'turn_off_(turn_off,_switch_off)': 100, 'turn_on_(switch_on,_start,_light)': 101, 'uncover': 102, 'unfold': 103, 'unroll': 104, 'unscrew': 105, 'untie': 106, 'walk': 107, 'wash': 108, 'water': 109, 'wear': 110, 'weld': 111, 'wipe': 112, 'write': 113, 'zip': 114, 'watch': 115, 'wave': 116},\n)}\n</code></pre> <p><code>arctix</code> provides the function <code>arctix.dataset.ego4d.to_array</code> to convert the <code>polars.DataFrame</code> to a dictionary of numpy arrays.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.ego4d import to_array\n&gt;&gt;&gt; arrays = to_array(data)  # doctest: +SKIP\n</code></pre> <p>The dictionary contains some regular arrays and masked arrays because sequences have variable lengths:</p> <pre><code>{'noun': masked_array(\n  data=[['container_(box,_can,_carton,_case,_casing,_container,_crate,_holder,_jar,_jerrycan,_keg,_pack,_package,_packaging,_packet,_storage,_tank,_tin)',\n         'container_(box,_can,_carton,_case,_casing,_container,_crate,_holder,_jar,_jerrycan,_keg,_pack,_package,_packaging,_packet,_storage,_tank,_tin)',\n         'scissors', ..., --, --, --],\n        ['paintbrush', 'paintbrush', 'brush', ..., --, --, --],\n        ['faucet_(faucet,_tap)',\n         'napkin_(handkerchief,_napkin,_serviette,_tissue,_wipe)',\n         'napkin_(handkerchief,_napkin,_serviette,_tissue,_wipe)', ...,\n         --, --, --],\n        ...,\n        ['metal_(lead,_metal,_steel)', 'metal_(lead,_metal,_steel)',\n         'metal_(lead,_metal,_steel)', ..., --, --, --],\n        ['paper_(chart,_craft,_newspaper,_note,_paper,_papercraft,_poster,_receipt)',\n         'door', 'switch_(knob,_switch)', ..., --, --, --],\n        ['hose', 'hose', 'spray_(spray,_sprayer)', ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U142'), 'noun_label': masked_array(\n  data=[[105, 105, 349, ..., --, --, --],\n        [279, 279, 50, ..., --, --, --],\n        [150, 265, 265, ..., --, --, --],\n        ...,\n        [247, 247, 247, ..., --, --, --],\n        [286, 129, 409, ..., --, --, --],\n        [211, 211, 391, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'split': array(['train', 'train', 'train', ..., 'train', 'train', 'train'],\n      dtype='&lt;U5'), 'sequence_length': array([73, 31, 68, ..., 64, 22,  3]), 'action_clip_start_frame': masked_array(\n  data=[[0, 8, 25, ..., --, --, --],\n        [137, 363, 655, ..., --, --, --],\n        [144, 210, 198, ..., --, --, --],\n        ...,\n        [155, 283, 299, ..., --, --, --],\n        [422, 1003, 1201, ..., --, --, --],\n        [1673, 1681, 2740, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'action_clip_start_sec': masked_array(\n  data=[[0.021028645833333335, 0.2876953125, 0.8543619791666667, ..., --,\n         --, --],\n        [4.554361979166686, 12.087695266666685, 21.821028599999977, ...,\n         --, --, --],\n        [4.787695266666674, 6.9876952666666625, 6.587695266666685, ...,\n         --, --, --],\n        ...,\n        [5.151028600000018, 9.41769526666667, 9.951028599999972, ..., --,\n         --, --],\n        [14.066666666666606, 33.433333333333394, 40.0333333333333, ...,\n         --, --, --],\n        [55.75436193333337, 56.02102860000002, 91.32102860000009, ...,\n         --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=1e+20), 'action_clip_end_frame': masked_array(\n  data=[[194, 248, 265, ..., --, --, --],\n        [377, 603, 895, ..., --, --, --],\n        [384, 450, 438, ..., --, --, --],\n        ...,\n        [395, 523, 539, ..., --, --, --],\n        [662, 1243, 1441, ..., --, --, --],\n        [1913, 1921, 2980, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'action_clip_end_sec': masked_array(\n  data=[[6.4876953125, 8.2876953125, 8.854361979166667, ..., --, --, --],\n        [12.554361979166686, 20.087695266666685, 29.821028599999977, ...,\n         --, --, --],\n        [12.787695266666674, 14.987695266666663, 14.587695266666685, ...,\n         --, --, --],\n        ...,\n        [13.151028600000018, 17.41769526666667, 17.951028599999972, ...,\n         --, --, --],\n        [22.066666666666606, 41.433333333333394, 48.0333333333333, ...,\n         --, --, --],\n        [63.75436193333337, 64.02102860000002, 99.32102860000009, ...,\n         --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=1e+20), 'verb': masked_array(\n  data=[['take_(pick,_grab,_get)', 'put_(place,_leave,_drop)',\n         'take_(pick,_grab,_get)', ..., --, --, --],\n        ['remove', 'dip', 'dip', ..., --, --, --],\n        ['turn_off_(turn_off,_switch_off)',\n         'clean_(sweep,_scrub,_mop,_dust)', 'take_(pick,_grab,_get)',\n         ..., --, --, --],\n        ...,\n        ['remove', 'remove', 'put_(place,_leave,_drop)', ..., --, --, --],\n        ['take_(pick,_grab,_get)', 'open',\n         'turn_on_(switch_on,_start,_light)', ..., --, --, --],\n        ['turn_on_(switch_on,_start,_light)', 'spray',\n         'turn_off_(turn_off,_switch_off)', ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U47'), 'verb_label': masked_array(\n  data=[[92, 65, 92, ..., --, --, --],\n        [67, 19, 19, ..., --, --, --],\n        [100, 9, 92, ..., --, --, --],\n        ...,\n        [67, 67, 65, ..., --, --, --],\n        [92, 50, 101, ..., --, --, --],\n        [101, 84, 100, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'clip_uid': array(['002e11bc-deef-45f7-9af8-59421a606d69',\n       '00600a90-0934-4d5f-aa9d-1cdea46ab740',\n       '00be9fe7-617c-46cf-a0de-7432896c1705', ...,\n       'ffab3f83-5c60-431c-8d5d-543695fd11f7',\n       'ffdbd08d-d9e0-4669-b043-6f3d1c02d4d8',\n       'ffffec25-661a-4450-ad99-6f3d58144930'], dtype='&lt;U36')}\n</code></pre>"},{"location":"datasets/epic_kitchen_100/","title":"EPIC-KITCHENS-100","text":"<p>This page contains information about the EPIC-KITCHENS-100 dataset, which was published with the following paper:</p> <pre><code>Rescaling Egocentric Vision\nDamen D., Doughty H., Farinella G., Furnari A., Ma J., Kazakos E., Moltisanti D.,\nMunro J., Perrett T., Price W., and Wray M.\nIJCV 2022 (https://arxiv.org/abs/2006.13256)\n</code></pre> <p>The data can be downloaded from the official project page and the associated GitHub repository.</p>"},{"location":"datasets/epic_kitchen_100/#get-the-raw-data","title":"Get the raw data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.epic_kitchen_100.fetch_data</code> to easily load the raw data in a <code>polars.DataFrame</code> format.</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.epic_kitchen_100 import fetch_data\n&gt;&gt;&gt; dataset_path = Path(\"/path/to/dataset/epic_kitchen_100\")\n&gt;&gt;&gt; data_raw, metadata_raw = fetch_data(dataset_path, split=\"train\")  # doctest: +SKIP\nshape: (67_217, 15)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 all_noun_c \u2506 all_nouns \u2506 narration \u2506 narration \u2506 \u2026 \u2506 stop_time \u2506 verb     \u2506 verb_clas \u2506 video_id \u2502\n\u2502 lasses     \u2506 ---       \u2506 ---       \u2506 _id       \u2506   \u2506 stamp     \u2506 ---      \u2506 s         \u2506 ---      \u2502\n\u2502 ---        \u2506 list[str] \u2506 str       \u2506 ---       \u2506   \u2506 ---       \u2506 str      \u2506 ---       \u2506 str      \u2502\n\u2502 list[i64]  \u2506           \u2506           \u2506 str       \u2506   \u2506 time      \u2506          \u2506 i64       \u2506          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [3]        \u2506 [\"door\"]  \u2506 open door \u2506 P01_01_0  \u2506 \u2026 \u2506 00:00:03. \u2506 open     \u2506 3         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506           \u2506           \u2506   \u2506 370       \u2506          \u2506           \u2506          \u2502\n\u2502 [114]      \u2506 [\"light\"] \u2506 turn on   \u2506 P01_01_1  \u2506 \u2026 \u2506 00:00:06. \u2506 turn-on  \u2506 6         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506 light     \u2506           \u2506   \u2506 170       \u2506          \u2506           \u2506          \u2502\n\u2502 [3]        \u2506 [\"door\"]  \u2506 close     \u2506 P01_01_2  \u2506 \u2026 \u2506 00:00:09. \u2506 close    \u2506 4         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506 door      \u2506           \u2506   \u2506 490       \u2506          \u2506           \u2506          \u2502\n\u2502 [12]       \u2506 [\"fridge\" \u2506 open      \u2506 P01_01_3  \u2506 \u2026 \u2506 00:00:13. \u2506 open     \u2506 3         \u2506 P01_01   \u2502\n\u2502            \u2506 ]         \u2506 fridge    \u2506           \u2506   \u2506 990       \u2506          \u2506           \u2506          \u2502\n\u2502 [223]      \u2506 [\"celery\" \u2506 take      \u2506 P01_01_4  \u2506 \u2026 \u2506 00:00:16. \u2506 take     \u2506 0         \u2506 P01_01   \u2502\n\u2502            \u2506 ]         \u2506 celery    \u2506           \u2506   \u2506 400       \u2506          \u2506           \u2506          \u2502\n\u2502 \u2026          \u2506 \u2026         \u2506 \u2026         \u2506 \u2026         \u2506 \u2026 \u2506 \u2026         \u2506 \u2026        \u2506 \u2026         \u2506 \u2026        \u2502\n\u2502 [0]        \u2506 [\"tap\"]   \u2506 turn on   \u2506 P37_103_6 \u2506 \u2026 \u2506 00:06:16. \u2506 turn-on  \u2506 6         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 tap       \u2506 9         \u2506   \u2506 690       \u2506          \u2506           \u2506          \u2502\n\u2502 [11]       \u2506 [\"hand\"]  \u2506 wash      \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:17. \u2506 wash     \u2506 2         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 hands     \u2506 0         \u2506   \u2506 290       \u2506          \u2506           \u2506          \u2502\n\u2502 [0]        \u2506 [\"tap\"]   \u2506 turn off  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:17. \u2506 turn-off \u2506 8         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 tap       \u2506 1         \u2506   \u2506 670       \u2506          \u2506           \u2506          \u2502\n\u2502 [5]        \u2506 [\"pan\"]   \u2506 take pan  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:23. \u2506 take     \u2506 0         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506           \u2506 2         \u2506   \u2506 770       \u2506          \u2506           \u2506          \u2502\n\u2502 [27]       \u2506 [\"water:b \u2506 pour out  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:32. \u2506 pour-out \u2506 9         \u2506 P37_103  \u2502\n\u2502            \u2506 oiled\"]   \u2506 boiled    \u2506 3         \u2506   \u2506 660       \u2506          \u2506           \u2506          \u2502\n\u2502            \u2506           \u2506 water     \u2506           \u2506   \u2506           \u2506          \u2506           \u2506          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n(vocab_noun): Vocabulary(vocab_size=300)\n(vocab_verb): Vocabulary(vocab_size=97)\n</code></pre> <p>If the data is not downloaded in the dataset path, <code>fetch_data</code> automatically downloads the data. You can set <code>force_download=True</code> to force to re-download the data if the data is already downloaded.</p>"},{"location":"datasets/epic_kitchen_100/#prepare-the-data","title":"Prepare the data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.epic_kitchen_100.prepare_data</code> to preprocess the raw data. It returns two outputs: the prepared data and the generate metadata.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.epic_kitchen_100 import prepare_data\n&gt;&gt;&gt; data, metadata = prepare_data(data_raw, metadata_raw)  # doctest: +SKIP\n</code></pre> <p><code>data</code> is a <code>polars.DataFrame</code> which contains the prepared data:</p> <pre><code>shape: (67_217, 17)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 all_noun_c \u2506 all_nouns \u2506 narration \u2506 narration \u2506 \u2026 \u2506 stop_time \u2506 verb     \u2506 verb_clas \u2506 video_id \u2502\n\u2502 lasses     \u2506 ---       \u2506 ---       \u2506 _id       \u2506   \u2506 stamp     \u2506 ---      \u2506 s         \u2506 ---      \u2502\n\u2502 ---        \u2506 list[str] \u2506 str       \u2506 ---       \u2506   \u2506 ---       \u2506 str      \u2506 ---       \u2506 str      \u2502\n\u2502 list[i64]  \u2506           \u2506           \u2506 str       \u2506   \u2506 time      \u2506          \u2506 i64       \u2506          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [3]        \u2506 [\"door\"]  \u2506 open door \u2506 P01_01_0  \u2506 \u2026 \u2506 00:00:03. \u2506 open     \u2506 3         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506           \u2506           \u2506   \u2506 370       \u2506          \u2506           \u2506          \u2502\n\u2502 [114]      \u2506 [\"light\"] \u2506 turn on   \u2506 P01_01_1  \u2506 \u2026 \u2506 00:00:06. \u2506 turn-on  \u2506 6         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506 light     \u2506           \u2506   \u2506 170       \u2506          \u2506           \u2506          \u2502\n\u2502 [3]        \u2506 [\"door\"]  \u2506 close     \u2506 P01_01_2  \u2506 \u2026 \u2506 00:00:09. \u2506 close    \u2506 4         \u2506 P01_01   \u2502\n\u2502            \u2506           \u2506 door      \u2506           \u2506   \u2506 490       \u2506          \u2506           \u2506          \u2502\n\u2502 [12]       \u2506 [\"fridge\" \u2506 open      \u2506 P01_01_3  \u2506 \u2026 \u2506 00:00:13. \u2506 open     \u2506 3         \u2506 P01_01   \u2502\n\u2502            \u2506 ]         \u2506 fridge    \u2506           \u2506   \u2506 990       \u2506          \u2506           \u2506          \u2502\n\u2502 [223]      \u2506 [\"celery\" \u2506 take      \u2506 P01_01_4  \u2506 \u2026 \u2506 00:00:16. \u2506 take     \u2506 0         \u2506 P01_01   \u2502\n\u2502            \u2506 ]         \u2506 celery    \u2506           \u2506   \u2506 400       \u2506          \u2506           \u2506          \u2502\n\u2502 \u2026          \u2506 \u2026         \u2506 \u2026         \u2506 \u2026         \u2506 \u2026 \u2506 \u2026         \u2506 \u2026        \u2506 \u2026         \u2506 \u2026        \u2502\n\u2502 [0]        \u2506 [\"tap\"]   \u2506 turn on   \u2506 P37_103_6 \u2506 \u2026 \u2506 00:06:16. \u2506 turn-on  \u2506 6         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 tap       \u2506 9         \u2506   \u2506 690       \u2506          \u2506           \u2506          \u2502\n\u2502 [11]       \u2506 [\"hand\"]  \u2506 wash      \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:17. \u2506 wash     \u2506 2         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 hands     \u2506 0         \u2506   \u2506 290       \u2506          \u2506           \u2506          \u2502\n\u2502 [0]        \u2506 [\"tap\"]   \u2506 turn off  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:17. \u2506 turn-off \u2506 8         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506 tap       \u2506 1         \u2506   \u2506 670       \u2506          \u2506           \u2506          \u2502\n\u2502 [5]        \u2506 [\"pan\"]   \u2506 take pan  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:23. \u2506 take     \u2506 0         \u2506 P37_103  \u2502\n\u2502            \u2506           \u2506           \u2506 2         \u2506   \u2506 770       \u2506          \u2506           \u2506          \u2502\n\u2502 [27]       \u2506 [\"water:b \u2506 pour out  \u2506 P37_103_7 \u2506 \u2026 \u2506 00:06:32. \u2506 pour-out \u2506 9         \u2506 P37_103  \u2502\n\u2502            \u2506 oiled\"]   \u2506 boiled    \u2506 3         \u2506   \u2506 660       \u2506          \u2506           \u2506          \u2502\n\u2502            \u2506           \u2506 water     \u2506           \u2506   \u2506           \u2506          \u2506           \u2506          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can note that new columns are added and the data types of some columns have changed. <code>metadata</code> contains a vocabulary that is used to generate the column <code>action_id</code>:</p> <pre><code>{'vocab_noun': Vocabulary(\n  counter=Counter({'tap': 1, 'spoon': 1, 'plate': 1, 'cupboard': 1, 'knife': 1, 'pan': 1, 'lid': 1, 'bowl': 1, 'drawer': 1, 'sponge': 1, 'glass': 1, 'hand': 1, 'fridge': 1, 'cup': 1, 'fork': 1, 'bottle': 1, 'onion': 1, 'cloth': 1, 'board:chopping': 1, 'bag': 1, 'spatula': 1, 'container': 1, 'liquid:washing': 1, 'box': 1, 'hob': 1, 'dough': 1, 'package': 1, 'water': 1, 'meat': 1, 'pot': 1, 'potato': 1, 'oil': 1, 'cheese': 1, 'bread': 1, 'food': 1, 'tray': 1, 'bin': 1, 'pepper': 1, 'salt': 1, 'colander': 1, 'jar': 1, 'carrot': 1, 'top': 1, 'tomato': 1, 'kettle': 1, 'pasta': 1, 'oven': 1, 'sauce': 1, 'skin': 1, 'paper': 1, 'maker:coffee': 1, 'garlic': 1, 'towel': 1, 'egg': 1, 'rubbish': 1, 'rice': 1, 'mushroom': 1, 'chicken': 1, 'cutlery': 1, 'coffee': 1, 'glove': 1, 'can': 1, 'leaf': 1, 'sink': 1, 'milk': 1, 'heat': 1, 'jug': 1, 'aubergine': 1, 'salad': 1, 'chilli': 1, 'dishwasher': 1, 'mixture': 1, 'cucumber': 1, 'clothes': 1, 'peach': 1, 'flour': 1, 'courgette': 1, 'filter': 1, 'butter': 1, 'scissors': 1, 'chopstick': 1, 'tofu': 1, 'blender': 1, 'olive': 1, 'mat': 1, 'spice': 1, 'sausage': 1, 'peeler:potato': 1, 'napkin': 1, 'cover': 1, 'microwave': 1, 'pizza': 1, 'button': 1, 'towel:kitchen': 1, 'vegetable': 1, 'stock': 1, 'grater': 1, 'ladle': 1, 'yoghurt': 1, 'cereal': 1, 'wrap:plastic': 1, 'broccoli': 1, 'sugar': 1, 'brush': 1, 'biscuit': 1, 'lemon': 1, 'juicer': 1, 'wrap': 1, 'scale': 1, 'rest': 1, 'rack:drying': 1, 'alarm': 1, 'salmon': 1, 'freezer': 1, 'light': 1, 'spreads': 1, 'squash': 1, 'leek': 1, 'cap': 1, 'fish': 1, 'lettuce': 1, 'curry': 1, 'seed': 1, 'foil': 1, 'machine:washing': 1, 'corn': 1, 'soup': 1, 'oatmeal': 1, 'onion:spring': 1, 'clip': 1, 'lighter': 1, 'ginger': 1, 'tea': 1, 'nut': 1, 'vinegar': 1, 'holder': 1, 'pin:rolling': 1, 'pie': 1, 'powder': 1, 'burger': 1, 'book': 1, 'shell:egg': 1, 'tongs': 1, 'cream': 1, 'pork': 1, 'oregano': 1, 'banana': 1, 'processor:food': 1, 'paste': 1, 'recipe': 1, 'liquid': 1, 'choi:pak': 1, 'cooker:slow': 1, 'plug': 1, 'utensil': 1, 'noodle': 1, 'salami': 1, 'kitchen': 1, 'teapot': 1, 'floor': 1, 'tuna': 1, 'lime': 1, 'omelette': 1, 'bacon': 1, 'sandwich': 1, 'phone': 1, 'thermometer': 1, 'orange': 1, 'basket': 1, 'parsley': 1, 'spinner:salad': 1, 'tablet': 1, 'presser': 1, 'coriander': 1, 'opener:bottle': 1, 'cake': 1, 'avocado': 1, 'lentil': 1, 'blueberry': 1, 'fan:extractor': 1, 'cellar:salt': 1, 'hummus': 1, 'chair': 1, 'juice': 1, 'pancake': 1, 'bean:green': 1, 'toaster': 1, 'apple': 1, 'chocolate': 1, 'ice': 1, 'knob': 1, 'handle': 1, 'wine': 1, 'pea': 1, 'pith': 1, 'yeast': 1, 'coconut': 1, 'fishcakes': 1, 'spinach': 1, 'apron': 1, 'raisin': 1, 'basil': 1, 'grape': 1, 'kale': 1, 'wire': 1, 'asparagus': 1, 'paprika': 1, 'mango': 1, 'caper': 1, 'drink': 1, 'stalk': 1, 'turmeric': 1, 'whetstone': 1, 'kiwi': 1, 'bean': 1, 'thyme': 1, 'finger:lady': 1, 'beef': 1, 'whisk': 1, 'blackberry': 1, 'slicer': 1, 'control:remote': 1, 'label': 1, 'celery': 1, 'cabbage': 1, 'hoover': 1, 'breadstick': 1, 'roll': 1, 'cocktail': 1, 'crisp': 1, 'ladder': 1, 'beer': 1, 'pan:dust': 1, 'battery': 1, 'powder:washing': 1, 'backpack': 1, 'cumin': 1, 'cutter:pizza': 1, 'air': 1, 'pear': 1, 'quorn': 1, 'funnel': 1, 'wall': 1, 'strawberry': 1, 'almond': 1, 'tv': 1, 'scotch:egg': 1, 'shelf': 1, 'straw': 1, 'stand': 1, 'machine:sous:vide': 1, 'masher': 1, 'guard:hand': 1, 'shrimp': 1, 'fruit': 1, 'artichoke': 1, 'cork': 1, 'cherry': 1, 'sprout': 1, 'mat:sushi': 1, 'stick:crab': 1, 'ring:onion': 1, 'pestle': 1, 'window': 1, 'gin': 1, 'bar': 1, 'mint': 1, 'heater': 1, 'grass:lemon': 1, 'rubber': 1, 'gherkin': 1, 'breadcrumb': 1, 'watch': 1, 'melon': 1, 'cinnamon': 1, 'popcorn': 1, 'dumpling': 1, 'rosemary': 1, 'power': 1, 'syrup': 1, 'candle': 1, 'pineapple': 1, 'sheets': 1, 'soda': 1, 'raspberry': 1, 'airer': 1, 'balloon': 1, 'turkey': 1, 'computer': 1, 'key': 1, 'pillow': 1, 'pen': 1, 'face': 1, 'plum': 1, 'whiskey': 1, 'door:kitchen': 1, 'tape': 1, 'camera': 1, 'cd': 1, 'extract:vanilla': 1}),\n  index_to_token=('tap', 'spoon', 'plate', 'cupboard', 'knife', 'pan', 'lid', 'bowl', 'drawer', 'sponge', 'glass', 'hand', 'fridge', 'cup', 'fork', 'bottle', 'onion', 'cloth', 'board:chopping', 'bag', 'spatula', 'container', 'liquid:washing', 'box', 'hob', 'dough', 'package', 'water', 'meat', 'pot', 'potato', 'oil', 'cheese', 'bread', 'food', 'tray', 'bin', 'pepper', 'salt', 'colander', 'jar', 'carrot', 'top', 'tomato', 'kettle', 'pasta', 'oven', 'sauce', 'skin', 'paper', 'maker:coffee', 'garlic', 'towel', 'egg', 'rubbish', 'rice', 'mushroom', 'chicken', 'cutlery', 'coffee', 'glove', 'can', 'leaf', 'sink', 'milk', 'heat', 'jug', 'aubergine', 'salad', 'chilli', 'dishwasher', 'mixture', 'cucumber', 'clothes', 'peach', 'flour', 'courgette', 'filter', 'butter', 'scissors', 'chopstick', 'tofu', 'blender', 'olive', 'mat', 'spice', 'sausage', 'peeler:potato', 'napkin', 'cover', 'microwave', 'pizza', 'button', 'towel:kitchen', 'vegetable', 'stock', 'grater', 'ladle', 'yoghurt', 'cereal', 'wrap:plastic', 'broccoli', 'sugar', 'brush', 'biscuit', 'lemon', 'juicer', 'wrap', 'scale', 'rest', 'rack:drying', 'alarm', 'salmon', 'freezer', 'light', 'spreads', 'squash', 'leek', 'cap', 'fish', 'lettuce', 'curry', 'seed', 'foil', 'machine:washing', 'corn', 'soup', 'oatmeal', 'onion:spring', 'clip', 'lighter', 'ginger', 'tea', 'nut', 'vinegar', 'holder', 'pin:rolling', 'pie', 'powder', 'burger', 'book', 'shell:egg', 'tongs', 'cream', 'pork', 'oregano', 'banana', 'processor:food', 'paste', 'recipe', 'liquid', 'choi:pak', 'cooker:slow', 'plug', 'utensil', 'noodle', 'salami', 'kitchen', 'teapot', 'floor', 'tuna', 'lime', 'omelette', 'bacon', 'sandwich', 'phone', 'thermometer', 'orange', 'basket', 'parsley', 'spinner:salad', 'tablet', 'presser', 'coriander', 'opener:bottle', 'cake', 'avocado', 'lentil', 'blueberry', 'fan:extractor', 'cellar:salt', 'hummus', 'chair', 'juice', 'pancake', 'bean:green', 'toaster', 'apple', 'chocolate', 'ice', 'knob', 'handle', 'wine', 'pea', 'pith', 'yeast', 'coconut', 'fishcakes', 'spinach', 'apron', 'raisin', 'basil', 'grape', 'kale', 'wire', 'asparagus', 'paprika', 'mango', 'caper', 'drink', 'stalk', 'turmeric', 'whetstone', 'kiwi', 'bean', 'thyme', 'finger:lady', 'beef', 'whisk', 'blackberry', 'slicer', 'control:remote', 'label', 'celery', 'cabbage', 'hoover', 'breadstick', 'roll', 'cocktail', 'crisp', 'ladder', 'beer', 'pan:dust', 'battery', 'powder:washing', 'backpack', 'cumin', 'cutter:pizza', 'air', 'pear', 'quorn', 'funnel', 'wall', 'strawberry', 'almond', 'tv', 'scotch:egg', 'shelf', 'straw', 'stand', 'machine:sous:vide', 'masher', 'guard:hand', 'shrimp', 'fruit', 'artichoke', 'cork', 'cherry', 'sprout', 'mat:sushi', 'stick:crab', 'ring:onion', 'pestle', 'window', 'gin', 'bar', 'mint', 'heater', 'grass:lemon', 'rubber', 'gherkin', 'breadcrumb', 'watch', 'melon', 'cinnamon', 'popcorn', 'dumpling', 'rosemary', 'power', 'syrup', 'candle', 'pineapple', 'sheets', 'soda', 'raspberry', 'airer', 'balloon', 'turkey', 'computer', 'key', 'pillow', 'pen', 'face', 'plum', 'whiskey', 'door:kitchen', 'tape', 'camera', 'cd', 'extract:vanilla'),\n  token_to_index={'tap': 0, 'spoon': 1, 'plate': 2, 'cupboard': 3, 'knife': 4, 'pan': 5, 'lid': 6, 'bowl': 7, 'drawer': 8, 'sponge': 9, 'glass': 10, 'hand': 11, 'fridge': 12, 'cup': 13, 'fork': 14, 'bottle': 15, 'onion': 16, 'cloth': 17, 'board:chopping': 18, 'bag': 19, 'spatula': 20, 'container': 21, 'liquid:washing': 22, 'box': 23, 'hob': 24, 'dough': 25, 'package': 26, 'water': 27, 'meat': 28, 'pot': 29, 'potato': 30, 'oil': 31, 'cheese': 32, 'bread': 33, 'food': 34, 'tray': 35, 'bin': 36, 'pepper': 37, 'salt': 38, 'colander': 39, 'jar': 40, 'carrot': 41, 'top': 42, 'tomato': 43, 'kettle': 44, 'pasta': 45, 'oven': 46, 'sauce': 47, 'skin': 48, 'paper': 49, 'maker:coffee': 50, 'garlic': 51, 'towel': 52, 'egg': 53, 'rubbish': 54, 'rice': 55, 'mushroom': 56, 'chicken': 57, 'cutlery': 58, 'coffee': 59, 'glove': 60, 'can': 61, 'leaf': 62, 'sink': 63, 'milk': 64, 'heat': 65, 'jug': 66, 'aubergine': 67, 'salad': 68, 'chilli': 69, 'dishwasher': 70, 'mixture': 71, 'cucumber': 72, 'clothes': 73, 'peach': 74, 'flour': 75, 'courgette': 76, 'filter': 77, 'butter': 78, 'scissors': 79, 'chopstick': 80, 'tofu': 81, 'blender': 82, 'olive': 83, 'mat': 84, 'spice': 85, 'sausage': 86, 'peeler:potato': 87, 'napkin': 88, 'cover': 89, 'microwave': 90, 'pizza': 91, 'button': 92, 'towel:kitchen': 93, 'vegetable': 94, 'stock': 95, 'grater': 96, 'ladle': 97, 'yoghurt': 98, 'cereal': 99, 'wrap:plastic': 100, 'broccoli': 101, 'sugar': 102, 'brush': 103, 'biscuit': 104, 'lemon': 105, 'juicer': 106, 'wrap': 107, 'scale': 108, 'rest': 109, 'rack:drying': 110, 'alarm': 111, 'salmon': 112, 'freezer': 113, 'light': 114, 'spreads': 115, 'squash': 116, 'leek': 117, 'cap': 118, 'fish': 119, 'lettuce': 120, 'curry': 121, 'seed': 122, 'foil': 123, 'machine:washing': 124, 'corn': 125, 'soup': 126, 'oatmeal': 127, 'onion:spring': 128, 'clip': 129, 'lighter': 130, 'ginger': 131, 'tea': 132, 'nut': 133, 'vinegar': 134, 'holder': 135, 'pin:rolling': 136, 'pie': 137, 'powder': 138, 'burger': 139, 'book': 140, 'shell:egg': 141, 'tongs': 142, 'cream': 143, 'pork': 144, 'oregano': 145, 'banana': 146, 'processor:food': 147, 'paste': 148, 'recipe': 149, 'liquid': 150, 'choi:pak': 151, 'cooker:slow': 152, 'plug': 153, 'utensil': 154, 'noodle': 155, 'salami': 156, 'kitchen': 157, 'teapot': 158, 'floor': 159, 'tuna': 160, 'lime': 161, 'omelette': 162, 'bacon': 163, 'sandwich': 164, 'phone': 165, 'thermometer': 166, 'orange': 167, 'basket': 168, 'parsley': 169, 'spinner:salad': 170, 'tablet': 171, 'presser': 172, 'coriander': 173, 'opener:bottle': 174, 'cake': 175, 'avocado': 176, 'lentil': 177, 'blueberry': 178, 'fan:extractor': 179, 'cellar:salt': 180, 'hummus': 181, 'chair': 182, 'juice': 183, 'pancake': 184, 'bean:green': 185, 'toaster': 186, 'apple': 187, 'chocolate': 188, 'ice': 189, 'knob': 190, 'handle': 191, 'wine': 192, 'pea': 193, 'pith': 194, 'yeast': 195, 'coconut': 196, 'fishcakes': 197, 'spinach': 198, 'apron': 199, 'raisin': 200, 'basil': 201, 'grape': 202, 'kale': 203, 'wire': 204, 'asparagus': 205, 'paprika': 206, 'mango': 207, 'caper': 208, 'drink': 209, 'stalk': 210, 'turmeric': 211, 'whetstone': 212, 'kiwi': 213, 'bean': 214, 'thyme': 215, 'finger:lady': 216, 'beef': 217, 'whisk': 218, 'blackberry': 219, 'slicer': 220, 'control:remote': 221, 'label': 222, 'celery': 223, 'cabbage': 224, 'hoover': 225, 'breadstick': 226, 'roll': 227, 'cocktail': 228, 'crisp': 229, 'ladder': 230, 'beer': 231, 'pan:dust': 232, 'battery': 233, 'powder:washing': 234, 'backpack': 235, 'cumin': 236, 'cutter:pizza': 237, 'air': 238, 'pear': 239, 'quorn': 240, 'funnel': 241, 'wall': 242, 'strawberry': 243, 'almond': 244, 'tv': 245, 'scotch:egg': 246, 'shelf': 247, 'straw': 248, 'stand': 249, 'machine:sous:vide': 250, 'masher': 251, 'guard:hand': 252, 'shrimp': 253, 'fruit': 254, 'artichoke': 255, 'cork': 256, 'cherry': 257, 'sprout': 258, 'mat:sushi': 259, 'stick:crab': 260, 'ring:onion': 261, 'pestle': 262, 'window': 263, 'gin': 264, 'bar': 265, 'mint': 266, 'heater': 267, 'grass:lemon': 268, 'rubber': 269, 'gherkin': 270, 'breadcrumb': 271, 'watch': 272, 'melon': 273, 'cinnamon': 274, 'popcorn': 275, 'dumpling': 276, 'rosemary': 277, 'power': 278, 'syrup': 279, 'candle': 280, 'pineapple': 281, 'sheets': 282, 'soda': 283, 'raspberry': 284, 'airer': 285, 'balloon': 286, 'turkey': 287, 'computer': 288, 'key': 289, 'pillow': 290, 'pen': 291, 'face': 292, 'plum': 293, 'whiskey': 294, 'door:kitchen': 295, 'tape': 296, 'camera': 297, 'cd': 298, 'extract:vanilla': 299},\n),\n'vocab_verb': Vocabulary(\n  counter=Counter({'take': 1, 'put': 1, 'wash': 1, 'open': 1, 'close': 1, 'insert': 1, 'turn-on': 1, 'cut': 1, 'turn-off': 1, 'pour': 1, 'mix': 1, 'move': 1, 'remove': 1, 'throw': 1, 'dry': 1, 'shake': 1, 'scoop': 1, 'adjust': 1, 'squeeze': 1, 'peel': 1, 'empty': 1, 'press': 1, 'flip': 1, 'turn': 1, 'check': 1, 'scrape': 1, 'fill': 1, 'apply': 1, 'fold': 1, 'scrub': 1, 'break': 1, 'pull': 1, 'pat': 1, 'lift': 1, 'hold': 1, 'eat': 1, 'wrap': 1, 'filter': 1, 'look': 1, 'unroll': 1, 'sort': 1, 'hang': 1, 'sprinkle': 1, 'rip': 1, 'spray': 1, 'cook': 1, 'add': 1, 'roll': 1, 'search': 1, 'crush': 1, 'stretch': 1, 'knead': 1, 'divide': 1, 'set': 1, 'feel': 1, 'rub': 1, 'soak': 1, 'brush': 1, 'sharpen': 1, 'drop': 1, 'drink': 1, 'slide': 1, 'water': 1, 'gather': 1, 'attach': 1, 'turn-down': 1, 'coat': 1, 'transition': 1, 'wear': 1, 'measure': 1, 'increase': 1, 'unscrew': 1, 'wait': 1, 'lower': 1, 'form': 1, 'smell': 1, 'use': 1, 'grate': 1, 'screw': 1, 'let-go': 1, 'finish': 1, 'stab': 1, 'serve': 1, 'uncover': 1, 'unwrap': 1, 'choose': 1, 'lock': 1, 'flatten': 1, 'switch': 1, 'carry': 1, 'season': 1, 'unlock': 1, 'prepare': 1, 'bake': 1, 'mark': 1, 'bend': 1, 'unfreeze': 1}),\n  index_to_token=('take', 'put', 'wash', 'open', 'close', 'insert', 'turn-on', 'cut', 'turn-off', 'pour', 'mix', 'move', 'remove', 'throw', 'dry', 'shake', 'scoop', 'adjust', 'squeeze', 'peel', 'empty', 'press', 'flip', 'turn', 'check', 'scrape', 'fill', 'apply', 'fold', 'scrub', 'break', 'pull', 'pat', 'lift', 'hold', 'eat', 'wrap', 'filter', 'look', 'unroll', 'sort', 'hang', 'sprinkle', 'rip', 'spray', 'cook', 'add', 'roll', 'search', 'crush', 'stretch', 'knead', 'divide', 'set', 'feel', 'rub', 'soak', 'brush', 'sharpen', 'drop', 'drink', 'slide', 'water', 'gather', 'attach', 'turn-down', 'coat', 'transition', 'wear', 'measure', 'increase', 'unscrew', 'wait', 'lower', 'form', 'smell', 'use', 'grate', 'screw', 'let-go', 'finish', 'stab', 'serve', 'uncover', 'unwrap', 'choose', 'lock', 'flatten', 'switch', 'carry', 'season', 'unlock', 'prepare', 'bake', 'mark', 'bend', 'unfreeze'),\n  token_to_index={'take': 0, 'put': 1, 'wash': 2, 'open': 3, 'close': 4, 'insert': 5, 'turn-on': 6, 'cut': 7, 'turn-off': 8, 'pour': 9, 'mix': 10, 'move': 11, 'remove': 12, 'throw': 13, 'dry': 14, 'shake': 15, 'scoop': 16, 'adjust': 17, 'squeeze': 18, 'peel': 19, 'empty': 20, 'press': 21, 'flip': 22, 'turn': 23, 'check': 24, 'scrape': 25, 'fill': 26, 'apply': 27, 'fold': 28, 'scrub': 29, 'break': 30, 'pull': 31, 'pat': 32, 'lift': 33, 'hold': 34, 'eat': 35, 'wrap': 36, 'filter': 37, 'look': 38, 'unroll': 39, 'sort': 40, 'hang': 41, 'sprinkle': 42, 'rip': 43, 'spray': 44, 'cook': 45, 'add': 46, 'roll': 47, 'search': 48, 'crush': 49, 'stretch': 50, 'knead': 51, 'divide': 52, 'set': 53, 'feel': 54, 'rub': 55, 'soak': 56, 'brush': 57, 'sharpen': 58, 'drop': 59, 'drink': 60, 'slide': 61, 'water': 62, 'gather': 63, 'attach': 64, 'turn-down': 65, 'coat': 66, 'transition': 67, 'wear': 68, 'measure': 69, 'increase': 70, 'unscrew': 71, 'wait': 72, 'lower': 73, 'form': 74, 'smell': 75, 'use': 76, 'grate': 77, 'screw': 78, 'let-go': 79, 'finish': 80, 'stab': 81, 'serve': 82, 'uncover': 83, 'unwrap': 84, 'choose': 85, 'lock': 86, 'flatten': 87, 'switch': 88, 'carry': 89, 'season': 90, 'unlock': 91, 'prepare': 92, 'bake': 93, 'mark': 94, 'bend': 95, 'unfreeze': 96},\n)}\n</code></pre> <p><code>arctix</code> provides the function <code>arctix.dataset.epic_kitchen_100.to_array</code> to convert the <code>polars.DataFrame</code> to a dictionary of numpy arrays.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.epic_kitchen_100 import to_array\n&gt;&gt;&gt; arrays = to_array(data)  # doctest: +SKIP\n</code></pre> <p>The dictionary contains some regular arrays and masked arrays because sequences have variable lengths:</p> <pre><code>{'narration': masked_array(\n  data=[['open door', 'turn on light', 'close door', ..., --, --, --],\n        ['take plate', 'open bin', 'throw leftovers into bin', ..., --,\n         --, --],\n        ['open door', 'close door', 'switch on lights', ..., --, --, --],\n        ...,\n        ['open fridge', 'take plastic box', 'close fridge', ..., --, --,\n         --],\n        ['shake pot', 'take spatula', 'stir chicken thighs in pot', ...,\n         --, --, --],\n        ['take chicken thighs', 'debone chicken thighs',\n         'debone chicken thighs', ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U77'), 'narration_id': masked_array(\n  data=[['P01_01_0', 'P01_01_1', 'P01_01_2', ..., --, --, --],\n        ['P01_02_0', 'P01_02_1', 'P01_02_2', ..., --, --, --],\n        ['P01_03_0', 'P01_03_1', 'P01_03_2', ..., --, --, --],\n        ...,\n        ['P37_101_0', 'P37_101_1', 'P37_101_2', ..., --, --, --],\n        ['P37_102_0', 'P37_102_1', 'P37_102_2', ..., --, --, --],\n        ['P37_103_0', 'P37_103_1', 'P37_103_2', ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U11'), 'noun': masked_array(\n  data=[['door', 'light', 'door', ..., --, --, --],\n        ['plate', 'bin', 'leftover', ..., --, --, --],\n        ['door', 'door', 'light', ..., --, --, --],\n        ...,\n        ['fridge', 'box:plastic', 'fridge', ..., --, --, --],\n        ['pot', 'spatula', 'thigh:chicken', ..., --, --, --],\n        ['thigh:chicken', 'thigh:chicken', 'thigh:chicken', ..., --, --,\n         --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U29'), 'noun_class': masked_array(\n  data=[[3, 114, 3, ..., --, --, --],\n        [2, 36, 34, ..., --, --, --],\n        [3, 3, 114, ..., --, --, --],\n        ...,\n        [12, 23, 12, ..., --, --, --],\n        [29, 20, 57, ..., --, --, --],\n        [57, 57, 57, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'participant_id': array(['P01', 'P01', 'P01', ..., 'P37', 'P37', 'P37'],\n      dtype='&lt;U3'), 'sequence_length': array([329, 145,  42,  ..., 283, 378, 150,\n        74]), 'start_frame': masked_array(\n  data=[[8, 262, 418, ..., --, --, --],\n        [304, 516, 607, ..., --, --, --],\n        [16, 195, 292, ..., --, --, --],\n        ...,\n        [122, 282, 501, ..., --, --, --],\n        [215, 388, 472, ..., --, --, --],\n        [41, 85, 220, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'start_time_second': masked_array(\n  data=[[0.13999999999999999, 4.37, 6.9799999999999995, ..., --, --, --],\n        [5.069999999999999, 8.61, 10.129999999999999, ..., --, --, --],\n        [0.26999999999999996, 3.25, 4.88, ..., --, --, --],\n        ...,\n        [2.4499999999999997, 5.64, 10.02, ..., --, --, --],\n        [4.3, 7.76, 9.45, ..., --, --, --],\n        [0.82, 1.7, 4.41, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=1e+20), 'stop_frame': masked_array(\n  data=[[202, 370, 569, ..., --, --, --],\n        [410, 556, 1087, ..., --, --, --],\n        [126, 352, 362, ..., --, --, --],\n        ...,\n        [301, 500, 621, ..., --, --, --],\n        [312, 463, 1154, ..., --, --, --],\n        [79, 182, 483, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'stop_time_second': masked_array(\n  data=[[3.3699999999999997, 6.17, 9.49, ..., --, --, --],\n        [6.84, 9.28, 18.13, ..., --, --, --],\n        [2.11, 5.88, 6.04, ..., --, --, --],\n        ...,\n        [6.02, 10.01, 12.43, ..., --, --, --],\n        [6.25, 9.26, 23.09, ..., --, --, --],\n        [1.5899999999999999, 3.6399999999999997, 9.66, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=1e+20), 'verb': masked_array(\n  data=[['open', 'turn-on', 'close', ..., --, --, --],\n        ['take', 'open', 'throw-into', ..., --, --, --],\n        ['open', 'close', 'switch-on', ..., --, --, --],\n        ...,\n        ['open', 'take', 'close', ..., --, --, --],\n        ['shake', 'take', 'stir-in', ..., --, --, --],\n        ['take', 'debone', 'debone', ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U15'), 'verb_class': masked_array(\n  data=[[3, 6, 4, ..., --, --, --],\n        [0, 3, 13, ..., --, --, --],\n        [3, 4, 6, ..., --, --, --],\n        ...,\n        [3, 0, 4, ..., --, --, --],\n        [15, 0, 10, ..., --, --, --],\n        [0, 30, 30, ..., --, --, --]],\n  mask=[[False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        ...,\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True],\n        [False, False, False, ...,  True,  True,  True]],\n  fill_value=999999), 'video_id': array(['P01_01', 'P01_02', 'P01_03', ..., 'P37_101', 'P37_102', 'P37_103'], dtype='&lt;U7')}\n</code></pre>"},{"location":"datasets/multithumos/","title":"MultiTHUMOS","text":"<p>This page contains information about the MultiTHUMOS dataset, which was published with the following paper:</p> <pre><code>Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos.\nYeung S., Russakovsky O., Jin N., Andriluka M., Mori G., Fei-Fei L.\nIJCV 2017 (http://arxiv.org/pdf/1507.05738)\n</code></pre> <p>The data can be downloaded from the official project page.</p>"},{"location":"datasets/multithumos/#get-the-raw-data","title":"Get the raw data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.multithumos.fetch_data</code> to easily load the raw data in a <code>polars.DataFrame</code> format.</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.multithumos import fetch_data\n&gt;&gt;&gt; dataset_path = Path(\"/path/to/dataset/multithumos\")\n&gt;&gt;&gt; data_raw = fetch_data(dataset_path)  # doctest: +SKIP\nshape: (38_690, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 video                    \u2506 start_time \u2506 end_time \u2506 action              \u2502\n\u2502 ---                      \u2506 ---        \u2506 ---      \u2506 ---                 \u2502\n\u2502 str                      \u2506 f64        \u2506 f64      \u2506 str                 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 video_test_0000004       \u2506 0.03       \u2506 1.1      \u2506 Stand               \u2502\n\u2502 video_test_0000004       \u2506 0.2        \u2506 1.1      \u2506 CricketBowling      \u2502\n\u2502 video_test_0000004       \u2506 0.23       \u2506 0.93     \u2506 Jump                \u2502\n\u2502 video_test_0000004       \u2506 0.33       \u2506 1.13     \u2506 Throw               \u2502\n\u2502 video_test_0000004       \u2506 1.0        \u2506 1.5      \u2506 CricketShot         \u2502\n\u2502 \u2026                        \u2506 \u2026          \u2506 \u2026        \u2506 \u2026                   \u2502\n\u2502 video_validation_0000990 \u2506 103.6      \u2506 110.4    \u2506 VolleyballSpiking   \u2502\n\u2502 video_validation_0000990 \u2506 108.07     \u2506 111.57   \u2506 Jump                \u2502\n\u2502 video_validation_0000990 \u2506 109.03     \u2506 110.87   \u2506 BodyBend            \u2502\n\u2502 video_validation_0000990 \u2506 112.9      \u2506 122.47   \u2506 TalkToCamera        \u2502\n\u2502 video_validation_0000990 \u2506 112.9      \u2506 122.47   \u2506 CloseUpTalkToCamera \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>If the data is not downloaded in the dataset path, <code>fetch_data</code> automatically downloads the data. You can set <code>force_download=True</code> to force to re-download the data if the data is already downloaded.</p>"},{"location":"datasets/multithumos/#prepare-the-data","title":"Prepare the data","text":"<p><code>arctix</code> provides the function <code>arctix.dataset.multithumos.prepare_data</code> to preprocess the raw data. It returns two outputs: the prepared data and the generate metadata.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.multithumos import prepare_data\n&gt;&gt;&gt; data, metadata = prepare_data(data_raw)  # doctest: +SKIP\n</code></pre> <p><code>data</code> is a <code>polars.DataFrame</code> which contains the prepared data:</p> <pre><code>shape: (38_690, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 video                   \u2506 start_time \u2506 end_time   \u2506 action              \u2506 action_id \u2506 split      \u2502\n\u2502 ---                     \u2506 ---        \u2506 ---        \u2506 ---                 \u2506 ---       \u2506 ---        \u2502\n\u2502 str                     \u2506 f64        \u2506 f64        \u2506 str                 \u2506 i64       \u2506 str        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 video_test_0000004      \u2506 0.03       \u2506 1.1        \u2506 Stand               \u2506 3         \u2506 test       \u2502\n\u2502 video_test_0000004      \u2506 0.2        \u2506 1.1        \u2506 CricketBowling      \u2506 32        \u2506 test       \u2502\n\u2502 video_test_0000004      \u2506 0.23       \u2506 0.93       \u2506 Jump                \u2506 1         \u2506 test       \u2502\n\u2502 video_test_0000004      \u2506 0.33       \u2506 1.13       \u2506 Throw               \u2506 4         \u2506 test       \u2502\n\u2502 video_test_0000004      \u2506 1.0        \u2506 1.5        \u2506 CricketShot         \u2506 29        \u2506 test       \u2502\n\u2502 \u2026                       \u2506 \u2026          \u2506 \u2026          \u2506 \u2026                   \u2506 \u2026         \u2506 \u2026          \u2502\n\u2502 video_validation_000099 \u2506 103.599998 \u2506 110.400002 \u2506 VolleyballSpiking   \u2506 37        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 108.07     \u2506 111.57     \u2506 Jump                \u2506 1         \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 109.029999 \u2506 110.870003 \u2506 BodyBend            \u2506 23        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 112.900002 \u2506 122.470001 \u2506 TalkToCamera        \u2506 16        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 112.900002 \u2506 122.470001 \u2506 CloseUpTalkToCamera \u2506 20        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>You can note that new columns are added and the data types of some columns have changed. <code>metadata</code> contains a vocabulary that is used to generate the column <code>action_id</code>:</p> <pre><code>{'vocab_action': Vocabulary(\n  counter=Counter({'Run': 3693, 'Jump': 3496, 'Walk': 3059, 'Stand': 2808, 'Throw': 1971, 'Sit': 1798, 'BodyContract': 1660, 'NoHuman': 1176, 'Fall': 1105, 'BodyRoll': 1058, 'Diving': 887, 'StandUp': 810, 'BasketballShot': 802, 'BasketballDunk': 791, 'Squat': 780, 'ClapHands': 680, 'TalkToCamera': 540, 'PoleVault': 519, 'PoleVaultPlantPole': 486, 'TwoHandedCatch': 464, 'CloseUpTalkToCamera': 444, 'HammerThrow': 441, 'HammerThrowRelease': 428, 'BodyBend': 411, 'HighJump': 406, 'HammerThrowSpin': 404, 'JavelinThrow': 361, 'CliffDiving': 360, 'TwoRaisedArmCelebrate': 353, 'CricketShot': 351, 'HammerThrowWindUp': 340, 'PickUp': 326, 'CricketBowling': 316, 'LongJump': 305, 'BasketballGuard': 298, 'BasketballDribble': 287, 'OneHandedCatch': 272, 'VolleyballSpiking': 266, 'DiscusWindUp': 229, 'OneRaisedArmCelebrate': 220, 'DiscusRelease': 218, 'Shotput': 214, 'BasketballPass': 212, 'TennisSwing': 210, 'ThrowDiscus': 208, 'Drop': 195, 'Billiards': 187, 'FistPump': 168, 'ShotPutBend': 152, 'FrisbeeCatch': 151, 'CleanAndJerk': 140, 'BasketballBlock': 134, 'WeightliftingJerk': 121, 'VolleyballSet': 118, 'BodyTurn': 117, 'SoccerPenalty': 114, 'WeightliftingClean': 110, 'VolleyballBlock': 101, 'Hug': 96, 'HighFive': 94, 'BaseballPitch': 71, 'GolfSwing': 67, 'PatPerson': 46, 'VolleyballServe': 30, 'VolleyballBump': 15}),\n  index_to_token=('Run', 'Jump', 'Walk', 'Stand', 'Throw', 'Sit', 'BodyContract', 'NoHuman', 'Fall', 'BodyRoll', 'Diving', 'StandUp', 'BasketballShot', 'BasketballDunk', 'Squat', 'ClapHands', 'TalkToCamera', 'PoleVault', 'PoleVaultPlantPole', 'TwoHandedCatch', 'CloseUpTalkToCamera', 'HammerThrow', 'HammerThrowRelease', 'BodyBend', 'HighJump', 'HammerThrowSpin', 'JavelinThrow', 'CliffDiving', 'TwoRaisedArmCelebrate', 'CricketShot', 'HammerThrowWindUp', 'PickUp', 'CricketBowling', 'LongJump', 'BasketballGuard', 'BasketballDribble', 'OneHandedCatch', 'VolleyballSpiking', 'DiscusWindUp', 'OneRaisedArmCelebrate', 'DiscusRelease', 'Shotput', 'BasketballPass', 'TennisSwing', 'ThrowDiscus', 'Drop', 'Billiards', 'FistPump', 'ShotPutBend', 'FrisbeeCatch', 'CleanAndJerk', 'BasketballBlock', 'WeightliftingJerk', 'VolleyballSet', 'BodyTurn', 'SoccerPenalty', 'WeightliftingClean', 'VolleyballBlock', 'Hug', 'HighFive', 'BaseballPitch', 'GolfSwing', 'PatPerson', 'VolleyballServe', 'VolleyballBump'),\n  token_to_index={'Run': 0, 'Jump': 1, 'Walk': 2, 'Stand': 3, 'Throw': 4, 'Sit': 5, 'BodyContract': 6, 'NoHuman': 7, 'Fall': 8, 'BodyRoll': 9, 'Diving': 10, 'StandUp': 11, 'BasketballShot': 12, 'BasketballDunk': 13, 'Squat': 14, 'ClapHands': 15, 'TalkToCamera': 16, 'PoleVault': 17, 'PoleVaultPlantPole': 18, 'TwoHandedCatch': 19, 'CloseUpTalkToCamera': 20, 'HammerThrow': 21, 'HammerThrowRelease': 22, 'BodyBend': 23, 'HighJump': 24, 'HammerThrowSpin': 25, 'JavelinThrow': 26, 'CliffDiving': 27, 'TwoRaisedArmCelebrate': 28, 'CricketShot': 29, 'HammerThrowWindUp': 30, 'PickUp': 31, 'CricketBowling': 32, 'LongJump': 33, 'BasketballGuard': 34, 'BasketballDribble': 35, 'OneHandedCatch': 36, 'VolleyballSpiking': 37, 'DiscusWindUp': 38, 'OneRaisedArmCelebrate': 39, 'DiscusRelease': 40, 'Shotput': 41, 'BasketballPass': 42, 'TennisSwing': 43, 'ThrowDiscus': 44, 'Drop': 45, 'Billiards': 46, 'FistPump': 47, 'ShotPutBend': 48, 'FrisbeeCatch': 49, 'CleanAndJerk': 50, 'BasketballBlock': 51, 'WeightliftingJerk': 52, 'VolleyballSet': 53, 'BodyTurn': 54, 'SoccerPenalty': 55, 'WeightliftingClean': 56, 'VolleyballBlock': 57, 'Hug': 58, 'HighFive': 59, 'BaseballPitch': 60, 'GolfSwing': 61, 'PatPerson': 62, 'VolleyballServe': 63, 'VolleyballBump': 64},\n)}\n</code></pre> <p>It is possible to specify the dataset split to filter the data and keep only the data related to a given dataset split. The dataset has different can be decomposed in different splits. For example, the following line will filter the data to keep only the rows related to the first training dataset (a.k.a. <code>train1</code>):</p> <pre><code>&gt;&gt;&gt; data, metadata = prepare_data(data_raw, split=\"validation\")  # doctest: +SKIP\n</code></pre> <pre><code>shape: (18_482, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 video                   \u2506 start_time \u2506 end_time   \u2506 action              \u2506 action_id \u2506 split      \u2502\n\u2502 ---                     \u2506 ---        \u2506 ---        \u2506 ---                 \u2506 ---       \u2506 ---        \u2502\n\u2502 str                     \u2506 f64        \u2506 f64        \u2506 str                 \u2506 i64       \u2506 str        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 video_validation_000005 \u2506 0.03       \u2506 31.0       \u2506 Stand               \u2506 3         \u2506 validation \u2502\n\u2502 1                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000005 \u2506 0.03       \u2506 0.17       \u2506 NoHuman             \u2506 7         \u2506 validation \u2502\n\u2502 1                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000005 \u2506 0.2        \u2506 19.43      \u2506 TalkToCamera        \u2506 16        \u2506 validation \u2502\n\u2502 1                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000005 \u2506 0.2        \u2506 19.43      \u2506 CloseUpTalkToCamera \u2506 20        \u2506 validation \u2502\n\u2502 1                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000005 \u2506 37.299999  \u2506 47.93      \u2506 NoHuman             \u2506 7         \u2506 validation \u2502\n\u2502 1                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 \u2026                       \u2506 \u2026          \u2506 \u2026          \u2506 \u2026                   \u2506 \u2026         \u2506 \u2026          \u2502\n\u2502 video_validation_000099 \u2506 103.599998 \u2506 110.400002 \u2506 VolleyballSpiking   \u2506 37        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 108.07     \u2506 111.57     \u2506 Jump                \u2506 1         \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 109.029999 \u2506 110.870003 \u2506 BodyBend            \u2506 23        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 112.900002 \u2506 122.470001 \u2506 CloseUpTalkToCamera \u2506 20        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2502 video_validation_000099 \u2506 112.900002 \u2506 122.470001 \u2506 TalkToCamera        \u2506 16        \u2506 validation \u2502\n\u2502 0                       \u2506            \u2506            \u2506                     \u2506           \u2506            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p><code>arctix</code> provides the function <code>arctix.dataset.multithumos.to_array</code> to convert the <code>polars.DataFrame</code> to a dictionary of numpy arrays.</p> <pre><code>&gt;&gt;&gt; from arctix.dataset.multithumos import to_array\n&gt;&gt;&gt; arrays = to_array(data)  # doctest: +SKIP\n</code></pre> <p>The dictionary contains some regular arrays and masked arrays because sequences have variable lengths:</p> <pre><code>{'sequence_length': array([ 25,  23,  32, ...,  48,  23,  44]),\n 'split': array(['validation', 'validation', 'validation', ... 'validation', 'validation', 'validation'], dtype='&lt;U10'),\n 'action_id': masked_array(\n   data=[[3, 7, 20, ..., --, --, --],\n         [7, 7, 3, ..., --, --, --],\n         [7, 46, 7, ..., --, --, --],\n         ...,\n         [7, 53, 37, ..., --, --, --],\n         [7, 3, 4, ..., --, --, --],\n         [16, 3, 63, ..., --, --, --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=999999),\n 'start_time': masked_array(\n   data=[[0.029999999329447746, 0.029999999329447746, 0.20000000298023224,\n          ..., --, --, --],\n         [0.029999999329447746, 13.970000267028809, 22.170000076293945,\n          ..., --, --, --],\n         [0.029999999329447746, 9.100000381469727, 12.800000190734863,\n          ..., --, --, --],\n         ...,\n         [0.029999999329447746, 7.070000171661377, 7.199999809265137, ...,\n          --, --, --],\n         [0.029999999329447746, 8.0, 8.0, ..., --, --, --],\n         [0.029999999329447746, 0.029999999329447746, 51.0, ..., --, --,\n          --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=1e+20),\n 'end_time': masked_array(\n   data=[[31.0, 0.17000000178813934, 19.43000030517578, ..., --, --, --],\n         [13.600000381469727, 23.3700008392334, 23.0, ..., --, --, --],\n         [8.100000381469727, 13.800000190734863, 20.200000762939453, ...,\n          --, --, --],\n         ...,\n         [7.03000020980835, 8.100000381469727, 10.199999809265137, ...,\n          --, --, --],\n         [8.0, 12.0, 10.0, ..., --, --, --],\n         [49.06999969482422, 112.0, 53.0, ..., --, --, --]],\n   mask=[[False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         ...,\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True],\n         [False, False, False, ...,  True,  True,  True]],\n   fill_value=1e+20)}\n</code></pre>"},{"location":"refs/dataset/","title":"arctix.dataset","text":""},{"location":"refs/dataset/#arctix.dataset.breakfast","title":"arctix.dataset.breakfast","text":"<p>Contain code to download and prepare the Breakfast data.</p> <p>The following documentation assumes the data are downloaded in the directory <code>/path/to/data/breakfast/</code>.</p>"},{"location":"refs/dataset/#arctix.dataset.breakfast.fetch_data","title":"arctix.dataset.breakfast.fetch_data","text":"<pre><code>fetch_data(\n    path: Path,\n    name: str,\n    remove_duplicate: bool = True,\n    force_download: bool = False,\n) -&gt; DataFrame\n</code></pre> <p>Download and load the data for Breakfast dataset.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path where to store the downloaded data.</p> required <code>name</code> <code>str</code> <p>The name of the dataset. The valid names are <code>'segmentation_coarse'</code> and <code>'segmentation_fine'</code>.</p> required <code>remove_duplicate</code> <code>bool</code> <p>If <code>True</code>, the duplicate examples are removed.</p> <code>True</code> <code>force_download</code> <code>bool</code> <p>If <code>True</code>, the annotations are downloaded everytime this function is called. If <code>False</code>, the annotations are downloaded only if the given path does not contain the annotation data.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The data in a DataFrame</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the name is incorrect</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.breakfast import fetch_data\n&gt;&gt;&gt; data = fetch_data(\n...     Path(\"/path/to/data/breakfast/\"), \"segmentation_coarse\"\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.breakfast.prepare_data","title":"arctix.dataset.breakfast.prepare_data","text":"<pre><code>prepare_data(\n    frame: DataFrame, split: str = \"all\"\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Prepare the data.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The raw DataFrame.</p> required <code>split</code> <code>str</code> <p>The dataset split. By default, the union of all the dataset splits is used.</p> <code>'all'</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>A tuple containing the prepared data and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.breakfast import Column, group_by_sequence\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION: [\n...             \"SIL\",\n...             \"take_bowl\",\n...             \"pour_cereals\",\n...             \"pour_milk\",\n...             \"stir_cereals\",\n...             \"SIL\",\n...             \"SIL\",\n...             \"pour_milk\",\n...             \"spoon_powder\",\n...             \"SIL\",\n...         ],\n...         Column.COOKING_ACTIVITY: [\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...         ],\n...         Column.END_TIME: [\n...             30.0,\n...             150.0,\n...             428.0,\n...             575.0,\n...             705.0,\n...             836.0,\n...             47.0,\n...             215.0,\n...             565.0,\n...             747.0,\n...         ],\n...         Column.PERSON: [\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...         ],\n...         Column.START_TIME: [\n...             1.0,\n...             31.0,\n...             151.0,\n...             429.0,\n...             576.0,\n...             706.0,\n...             1.0,\n...             48.0,\n...             216.0,\n...             566.0,\n...         ],\n...     },\n... )\n&gt;&gt;&gt; data, metadata = prepare_data(frame)\n&gt;&gt;&gt; with pl.Config(tbl_cols=-1):\n...     data\n...\nshape: (10, 9)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action    \u2506 action_id \u2506 cooking_ \u2506 cooking_ \u2506 end_time \u2506 person \u2506 person_i \u2506 start_ti \u2506 start_ti \u2502\n\u2502 ---       \u2506 ---       \u2506 activity \u2506 activity \u2506 ---      \u2506 ---    \u2506 d        \u2506 me       \u2506 me_diff  \u2502\n\u2502 str       \u2506 i64       \u2506 ---      \u2506 _id      \u2506 f64      \u2506 str    \u2506 ---      \u2506 ---      \u2506 ---      \u2502\n\u2502           \u2506           \u2506 str      \u2506 ---      \u2506          \u2506        \u2506 i64      \u2506 f64      \u2506 f64      \u2502\n\u2502           \u2506           \u2506          \u2506 i64      \u2506          \u2506        \u2506          \u2506          \u2506          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 SIL       \u2506 0         \u2506 cereals  \u2506 0        \u2506 30.0     \u2506 P03    \u2506 0        \u2506 1.0      \u2506 0.0      \u2502\n\u2502 take_bowl \u2506 2         \u2506 cereals  \u2506 0        \u2506 150.0    \u2506 P03    \u2506 0        \u2506 31.0     \u2506 30.0     \u2502\n\u2502 pour_cere \u2506 5         \u2506 cereals  \u2506 0        \u2506 428.0    \u2506 P03    \u2506 0        \u2506 151.0    \u2506 120.0    \u2502\n\u2502 als       \u2506           \u2506          \u2506          \u2506          \u2506        \u2506          \u2506          \u2506          \u2502\n\u2502 pour_milk \u2506 1         \u2506 cereals  \u2506 0        \u2506 575.0    \u2506 P03    \u2506 0        \u2506 429.0    \u2506 278.0    \u2502\n\u2502 stir_cere \u2506 3         \u2506 cereals  \u2506 0        \u2506 705.0    \u2506 P03    \u2506 0        \u2506 576.0    \u2506 147.0    \u2502\n\u2502 als       \u2506           \u2506          \u2506          \u2506          \u2506        \u2506          \u2506          \u2506          \u2502\n\u2502 SIL       \u2506 0         \u2506 cereals  \u2506 0        \u2506 836.0    \u2506 P03    \u2506 0        \u2506 706.0    \u2506 130.0    \u2502\n\u2502 SIL       \u2506 0         \u2506 milk     \u2506 1        \u2506 47.0     \u2506 P54    \u2506 1        \u2506 1.0      \u2506 0.0      \u2502\n\u2502 pour_milk \u2506 1         \u2506 milk     \u2506 1        \u2506 215.0    \u2506 P54    \u2506 1        \u2506 48.0     \u2506 47.0     \u2502\n\u2502 spoon_pow \u2506 4         \u2506 milk     \u2506 1        \u2506 565.0    \u2506 P54    \u2506 1        \u2506 216.0    \u2506 168.0    \u2502\n\u2502 der       \u2506           \u2506          \u2506          \u2506          \u2506        \u2506          \u2506          \u2506          \u2502\n\u2502 SIL       \u2506 0         \u2506 milk     \u2506 1        \u2506 747.0    \u2506 P54    \u2506 1        \u2506 566.0    \u2506 350.0    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; metadata\n{'vocab_action': Vocabulary(\n  counter=Counter({'SIL': 4, 'pour_milk': 2, 'take_bowl': 1, 'stir_cereals': 1, 'spoon_powder': 1, 'pour_cereals': 1}),\n  index_to_token=('SIL', 'pour_milk', 'take_bowl', 'stir_cereals', 'spoon_powder', 'pour_cereals'),\n  token_to_index={'SIL': 0, 'pour_milk': 1, 'take_bowl': 2, 'stir_cereals': 3, 'spoon_powder': 4, 'pour_cereals': 5},\n), 'vocab_activity': Vocabulary(\n  counter=Counter({'cereals': 6, 'milk': 4}),\n  index_to_token=('cereals', 'milk'),\n  token_to_index={'cereals': 0, 'milk': 1},\n), 'vocab_person': Vocabulary(\n  counter=Counter({'P03': 6, 'P54': 4}),\n  index_to_token=('P03', 'P54'),\n  token_to_index={'P03': 0, 'P54': 1},\n)}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.breakfast.to_array","title":"arctix.dataset.breakfast.to_array","text":"<pre><code>to_array(frame: DataFrame) -&gt; dict[str, ndarray]\n</code></pre> <p>Convert a DataFrame to a dictionary of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The dictionary of arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.breakfast import Column, to_array\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION: [\n...             \"SIL\",\n...             \"take_bowl\",\n...             \"pour_cereals\",\n...             \"pour_milk\",\n...             \"stir_cereals\",\n...             \"SIL\",\n...             \"SIL\",\n...             \"pour_milk\",\n...             \"spoon_powder\",\n...             \"SIL\",\n...         ],\n...         Column.ACTION_ID: [0, 2, 5, 1, 3, 0, 0, 1, 4, 0],\n...         Column.COOKING_ACTIVITY: [\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...         ],\n...         Column.COOKING_ACTIVITY_ID: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n...         Column.END_TIME: [\n...             30.0,\n...             150.0,\n...             428.0,\n...             575.0,\n...             705.0,\n...             836.0,\n...             47.0,\n...             215.0,\n...             565.0,\n...             747.0,\n...         ],\n...         Column.PERSON: [\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...         ],\n...         Column.PERSON_ID: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n...         Column.START_TIME: [\n...             1.0,\n...             31.0,\n...             151.0,\n...             429.0,\n...             576.0,\n...             706.0,\n...             1.0,\n...             48.0,\n...             216.0,\n...             566.0,\n...         ],\n...         Column.START_TIME_DIFF: [\n...             0.0,\n...             30.0,\n...             120.0,\n...             278.0,\n...             147.0,\n...             130.0,\n...             0.0,\n...             47.0,\n...             168.0,\n...             350.0,\n...         ],\n...     }\n... )\n&gt;&gt;&gt; arrays = to_array(frame)\n&gt;&gt;&gt; arrays\n{'action': masked_array(\n  data=[['SIL', 'take_bowl', 'pour_cereals', 'pour_milk', 'stir_cereals',\n         'SIL'],\n        ['SIL', 'pour_milk', 'spoon_powder', 'SIL', --, --]],\n  mask=[[False, False, False, False, False, False],\n        [False, False, False, False,  True,  True]],\n  fill_value='N/A',\n  dtype='&lt;U12'),\n  'action_id': masked_array(\n  data=[[0, 2, 5, 1, 3, 0],\n        [0, 1, 4, 0, --, --]],\n  mask=[[False, False, False, False, False, False],\n        [False, False, False, False,  True,  True]],\n  fill_value=999999),\n  'cooking_activity': array(['cereals', 'milk'], dtype='&lt;U7'),\n  'cooking_activity_id': array([0, 1]), 'person': array(['P03', 'P54'], dtype='&lt;U3'),\n  'person_id': array([0, 1]),\n  'sequence_length': array([6, 4]),\n  'start_time': masked_array(\n  data=[[1.0, 31.0, 151.0, 429.0, 576.0, 706.0],\n        [1.0, 48.0, 216.0, 566.0, --, --]],\n  mask=[[False, False, False, False, False, False],\n        [False, False, False, False,  True,  True]],\n  fill_value=1e+20), 'start_time_diff': masked_array(\n  data=[[0.0, 30.0, 120.0, 278.0, 147.0, 130.0],\n        [0.0, 47.0, 168.0, 350.0, --, --]],\n  mask=[[False, False, False, False, False, False],\n        [False, False, False, False,  True,  True]],\n  fill_value=1e+20), 'end_time': masked_array(\n  data=[[30.0, 150.0, 428.0, 575.0, 705.0, 836.0],\n        [47.0, 215.0, 565.0, 747.0, --, --]],\n  mask=[[False, False, False, False, False, False],\n        [False, False, False, False,  True,  True]],\n  fill_value=1e+20)}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.breakfast.to_list","title":"arctix.dataset.breakfast.to_list","text":"<pre><code>to_list(frame: DataFrame) -&gt; dict[str, list]\n</code></pre> <p>Convert a DataFrame to a dictionary of lists.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>The dictionary of lists.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.breakfast import Column, to_list\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION: [\n...             \"SIL\",\n...             \"take_bowl\",\n...             \"pour_cereals\",\n...             \"pour_milk\",\n...             \"stir_cereals\",\n...             \"SIL\",\n...             \"SIL\",\n...             \"pour_milk\",\n...             \"spoon_powder\",\n...             \"SIL\",\n...         ],\n...         Column.ACTION_ID: [0, 2, 5, 1, 3, 0, 0, 1, 4, 0],\n...         Column.COOKING_ACTIVITY: [\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"cereals\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...             \"milk\",\n...         ],\n...         Column.COOKING_ACTIVITY_ID: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n...         Column.END_TIME: [\n...             30.0,\n...             150.0,\n...             428.0,\n...             575.0,\n...             705.0,\n...             836.0,\n...             47.0,\n...             215.0,\n...             565.0,\n...             747.0,\n...         ],\n...         Column.PERSON: [\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P03\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...             \"P54\",\n...         ],\n...         Column.PERSON_ID: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n...         Column.START_TIME: [\n...             1.0,\n...             31.0,\n...             151.0,\n...             429.0,\n...             576.0,\n...             706.0,\n...             1.0,\n...             48.0,\n...             216.0,\n...             566.0,\n...         ],\n...         Column.START_TIME_DIFF: [\n...             0.0,\n...             30.0,\n...             120.0,\n...             278.0,\n...             147.0,\n...             130.0,\n...             0.0,\n...             47.0,\n...             168.0,\n...             350.0,\n...         ],\n...     }\n... )\n&gt;&gt;&gt; data_list = to_list(frame)\n&gt;&gt;&gt; data_list\n{'action': [['SIL', 'take_bowl', 'pour_cereals', 'pour_milk', 'stir_cereals', 'SIL'], ['SIL', 'pour_milk', 'spoon_powder', 'SIL']],\n 'action_id': [[0, 2, 5, 1, 3, 0], [0, 1, 4, 0]],\n 'cooking_activity': ['cereals', 'milk'],\n 'cooking_activity_id': [0, 1],\n 'end_time': [[30.0, 150.0, 428.0, 575.0, 705.0, 836.0], [47.0, 215.0, 565.0, 747.0]],\n 'person': ['P03', 'P54'],\n 'person_id': [0, 1],\n 'sequence_length': [6, 4],\n 'start_time': [[1.0, 31.0, 151.0, 429.0, 576.0, 706.0], [1.0, 48.0, 216.0, 566.0]],\n 'start_time_diff': [[0.0, 30.0, 120.0, 278.0, 147.0, 130.0], [0.0, 47.0, 168.0, 350.0]]}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.ego4d","title":"arctix.dataset.ego4d","text":"<p>Contain code to prepare the Ego4D data.</p> <p>The following documentation assumes the data are downloaded in the directory <code>/path/to/data/ego4d/</code>.</p>"},{"location":"refs/dataset/#arctix.dataset.ego4d.fetch_data","title":"arctix.dataset.ego4d.fetch_data","text":"<pre><code>fetch_data(\n    path: Path, split: str\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Download and load the data and the metadata.</p> Notes <p>This function does not implement the data downloading because it is necessary to get credentials to access the data.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The directory where the dataset annotations are stored.</p> required <code>split</code> <code>str</code> <p>The dataset split.</p> required <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>The annotations in a DataFrame and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.ego4d import fetch_data\n&gt;&gt;&gt; data, metadata = fetch_data(\n...     Path(\"/path/to/data/ego4d/\"), split=\"train\"\n... )  # doctest: +SKIP\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.ego4d.prepare_data","title":"arctix.dataset.ego4d.prepare_data","text":"<pre><code>prepare_data(\n    frame: DataFrame,\n    metadata: dict,\n    group_col: str = Column.CLIP_ID,\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Prepare the data.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The raw DataFrame.</p> required <code>metadata</code> <code>dict</code> <p>The metadata wich contains the vocabularies to convert verbs and nouns to index.</p> required <code>group_col</code> <code>str</code> <p>The column used to generate the sequences.</p> <code>CLIP_ID</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>A tuple containing the prepared data and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.ego4d import Column, prepare_data\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION_END_FRAME: [47, 82, 102, 74, 142],\n...         Column.ACTION_END_SEC: [4.7, 8.2, 10.2, 7.4, 14.2],\n...         Column.ACTION_START_FRAME: [23, 39, 74, 12, 82],\n...         Column.ACTION_START_SEC: [2.3, 3.9, 7.4, 1.2, 8.2],\n...         Column.ACTION_INDEX: [0, 1, 2, 0, 1],\n...         Column.CLIP_ID: [\"clip1\", \"clip1\", \"clip1\", \"clip2\", \"clip2\"],\n...         Column.NOUN: [\"noun2\", \"noun3\", \"noun1\", \"noun1\", \"noun2\"],\n...         Column.NOUN_ID: [2, 3, 1, 1, 2],\n...         Column.SPLIT: [\"train\", \"train\", \"train\", \"train\", \"train\"],\n...         Column.VERB: [\"verb4\", \"verb2\", \"verb1\", \"verb1\", \"verb2\"],\n...         Column.VERB_ID: [4, 2, 1, 1, 2],\n...         Column.VIDEO_ID: [\"video1\", \"video1\", \"video1\", \"video2\", \"video2\"],\n...     }\n... )\n&gt;&gt;&gt; data, metadata = prepare_data(frame, metadata={})\n&gt;&gt;&gt; with pl.Config(tbl_cols=-1):\n...     data\n...\nshape: (5, 13)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 act \u2506 act \u2506 act \u2506 action \u2506 actio \u2506 actio \u2506 clip_ \u2506 noun  \u2506 noun_ \u2506 split \u2506 verb  \u2506 verb_ \u2506 video \u2502\n\u2502 ion \u2506 ion \u2506 ion \u2506 _clip_ \u2506 n_cli \u2506 n_idx \u2506 uid   \u2506 ---   \u2506 label \u2506 ---   \u2506 ---   \u2506 label \u2506 _uid  \u2502\n\u2502 _cl \u2506 _cl \u2506 _cl \u2506 start_ \u2506 p_sta \u2506 ---   \u2506 ---   \u2506 str   \u2506 ---   \u2506 str   \u2506 str   \u2506 ---   \u2506 ---   \u2502\n\u2502 ip_ \u2506 ip_ \u2506 ip_ \u2506 sec    \u2506 rt_se \u2506 i64   \u2506 str   \u2506       \u2506 i64   \u2506       \u2506       \u2506 i64   \u2506 str   \u2502\n\u2502 end \u2506 end \u2506 sta \u2506 ---    \u2506 c_dif \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u2502 _fr \u2506 _se \u2506 rt_ \u2506 f64    \u2506 f     \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u2502 ame \u2506 c   \u2506 fra \u2506        \u2506 ---   \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u2502 --- \u2506 --- \u2506 me  \u2506        \u2506 f64   \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u2502 i64 \u2506 f64 \u2506 --- \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u2502     \u2506     \u2506 i64 \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 47  \u2506 4.7 \u2506 23  \u2506 2.3    \u2506 0.0   \u2506 0     \u2506 clip1 \u2506 noun2 \u2506 2     \u2506 train \u2506 verb4 \u2506 4     \u2506 video \u2502\n\u2502     \u2506     \u2506     \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506 1     \u2502\n\u2502 82  \u2506 8.2 \u2506 39  \u2506 3.9    \u2506 1.6   \u2506 1     \u2506 clip1 \u2506 noun3 \u2506 3     \u2506 train \u2506 verb2 \u2506 2     \u2506 video \u2502\n\u2502     \u2506     \u2506     \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506 1     \u2502\n\u2502 102 \u2506 10. \u2506 74  \u2506 7.4    \u2506 3.5   \u2506 2     \u2506 clip1 \u2506 noun1 \u2506 1     \u2506 train \u2506 verb1 \u2506 1     \u2506 video \u2502\n\u2502     \u2506 2   \u2506     \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506 1     \u2502\n\u2502 74  \u2506 7.4 \u2506 12  \u2506 1.2    \u2506 0.0   \u2506 0     \u2506 clip2 \u2506 noun1 \u2506 1     \u2506 train \u2506 verb1 \u2506 1     \u2506 video \u2502\n\u2502     \u2506     \u2506     \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506 2     \u2502\n\u2502 142 \u2506 14. \u2506 82  \u2506 8.2    \u2506 7.0   \u2506 1     \u2506 clip2 \u2506 noun2 \u2506 2     \u2506 train \u2506 verb2 \u2506 2     \u2506 video \u2502\n\u2502     \u2506 2   \u2506     \u2506        \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506       \u2506 2     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; metadata\n{}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.ego4d.to_array","title":"arctix.dataset.ego4d.to_array","text":"<pre><code>to_array(\n    frame: DataFrame, group_col: str = Column.CLIP_ID\n) -&gt; dict[str, ndarray]\n</code></pre> <p>Convert a DataFrame to a dictionary of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>group_col</code> <code>str</code> <p>The column used to generate the sequences.</p> <code>CLIP_ID</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The dictionary of arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.ego4d import Column, to_array\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION_END_FRAME: [47, 82, 102, 74, 142],\n...         Column.ACTION_END_SEC: [4.7, 8.2, 10.2, 7.4, 14.2],\n...         Column.ACTION_START_FRAME: [23, 39, 74, 12, 82],\n...         Column.ACTION_START_SEC: [2.3, 3.9, 7.4, 1.2, 8.2],\n...         Column.ACTION_START_SEC_DIFF: [0.0, 1.6, 3.5, 0.0, 7.0],\n...         Column.ACTION_INDEX: [0, 1, 2, 0, 1],\n...         Column.CLIP_ID: [\"clip1\", \"clip1\", \"clip1\", \"clip2\", \"clip2\"],\n...         Column.NOUN: [\"noun2\", \"noun3\", \"noun1\", \"noun1\", \"noun2\"],\n...         Column.NOUN_ID: [2, 3, 1, 1, 2],\n...         Column.SPLIT: [\"train\", \"train\", \"train\", \"train\", \"train\"],\n...         Column.VERB: [\"verb4\", \"verb2\", \"verb1\", \"verb1\", \"verb2\"],\n...         Column.VERB_ID: [4, 2, 1, 1, 2],\n...         Column.VIDEO_ID: [\"video1\", \"video1\", \"video1\", \"video2\", \"video2\"],\n...     }\n... )\n&gt;&gt;&gt; arrays = to_array(frame)\n&gt;&gt;&gt; arrays\n{'noun': masked_array(\n  data=[['noun2', 'noun3', 'noun1'],\n        ['noun1', 'noun2', --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value='N/A',\n  dtype='&lt;U5'),\n  'noun_label': masked_array(\n  data=[[2, 3, 1],\n        [1, 2, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=999999),\n  'split': array(['train', 'train'], dtype='&lt;U5'),\n  'sequence_length': array([3, 2]),\n  'action_clip_start_frame': masked_array(\n  data=[[23, 39, 74],\n        [12, 82, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=999999),\n  'action_clip_start_sec': masked_array(\n  data=[[2.3, 3.9, 7.4],\n        [1.2, 8.2, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=1e+20),\n  'action_clip_start_sec_diff': masked_array(\n  data=[[0.0, 1.6, 3.5],\n        [0.0, 7.0, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=1e+20),\n  'action_clip_end_frame': masked_array(\n  data=[[47, 82, 102],\n        [74, 142, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=999999),\n  'action_clip_end_sec': masked_array(\n  data=[[4.7, 8.2, 10.2],\n        [7.4, 14.2, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=1e+20),\n  'verb': masked_array(\n  data=[['verb4', 'verb2', 'verb1'],\n        ['verb1', 'verb2', --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value='N/A',\n  dtype='&lt;U5'),\n  'verb_label': masked_array(\n  data=[[4, 2, 1],\n        [1, 2, --]],\n  mask=[[False, False, False],\n        [False, False,  True]],\n  fill_value=999999),\n  'clip_uid': array(['clip1', 'clip2'], dtype='&lt;U5')}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.ego4d.to_list","title":"arctix.dataset.ego4d.to_list","text":"<pre><code>to_list(\n    frame: DataFrame, group_col: str = Column.CLIP_ID\n) -&gt; dict[str, list]\n</code></pre> <p>Convert a DataFrame to a dictionary of lists.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <code>group_col</code> <code>str</code> <p>The column used to generate the sequences.</p> <code>CLIP_ID</code> <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>The dictionary of lists.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.ego4d import Column, to_list\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ACTION_END_FRAME: [47, 82, 102, 74, 142],\n...         Column.ACTION_END_SEC: [4.7, 8.2, 10.2, 7.4, 14.2],\n...         Column.ACTION_START_FRAME: [23, 39, 74, 12, 82],\n...         Column.ACTION_START_SEC: [2.3, 3.9, 7.4, 1.2, 8.2],\n...         Column.ACTION_START_SEC_DIFF: [0.0, 1.6, 3.5, 0.0, 7.0],\n...         Column.ACTION_INDEX: [0, 1, 2, 0, 1],\n...         Column.CLIP_ID: [\"clip1\", \"clip1\", \"clip1\", \"clip2\", \"clip2\"],\n...         Column.NOUN: [\"noun2\", \"noun3\", \"noun1\", \"noun1\", \"noun2\"],\n...         Column.NOUN_ID: [2, 3, 1, 1, 2],\n...         Column.SPLIT: [\"train\", \"train\", \"train\", \"train\", \"train\"],\n...         Column.VERB: [\"verb4\", \"verb2\", \"verb1\", \"verb1\", \"verb2\"],\n...         Column.VERB_ID: [4, 2, 1, 1, 2],\n...         Column.VIDEO_ID: [\"video1\", \"video1\", \"video1\", \"video2\", \"video2\"],\n...     }\n... )\n&gt;&gt;&gt; data_list = to_list(frame)\n&gt;&gt;&gt; data_list\n{'action_clip_end_frame': [[47, 82, 102], [74, 142]],\n 'action_clip_end_sec': [[4.7, 8.2, 10.2], [7.4, 14.2]],\n 'action_clip_start_frame': [[23, 39, 74], [12, 82]],\n 'action_clip_start_sec': [[2.3, 3.9, 7.4], [1.2, 8.2]],\n 'action_clip_start_sec_diff': [[0.0, 1.6, 3.5], [0.0, 7.0]],\n 'clip_uid': ['clip1', 'clip2'],\n 'noun': [['noun2', 'noun3', 'noun1'], ['noun1', 'noun2']],\n 'noun_label': [[2, 3, 1], [1, 2]],\n 'sequence_length': [3, 2],\n 'split': ['train', 'train'],\n 'verb': [['verb4', 'verb2', 'verb1'], ['verb1', 'verb2']],\n 'verb_label': [[4, 2, 1], [1, 2]]}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.epic_kitchen_100","title":"arctix.dataset.epic_kitchen_100","text":"<p>Contain code to download and prepare the EPIC-KITCHENS-100 data.</p> <p>The following documentation assumes the data are downloaded in the directory <code>/path/to/data/epic_kitchen_100/</code>.</p>"},{"location":"refs/dataset/#arctix.dataset.epic_kitchen_100.fetch_data","title":"arctix.dataset.epic_kitchen_100.fetch_data","text":"<pre><code>fetch_data(\n    path: Path, split: str, force_download: bool = False\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Download and load the data for EPIC-KITCHENS-100 dataset.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path where to store the downloaded data.</p> required <code>split</code> <code>str</code> <p>The dataset split.</p> required <code>force_download</code> <code>bool</code> <p>If <code>True</code>, the annotations are downloaded everytime this function is called. If <code>False</code>, the annotations are downloaded only if the given path does not contain the annotation data.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>The annotations in a DataFrame and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.multithumos import fetch_data\n&gt;&gt;&gt; data, metadata = fetch_data(Path(\"/path/to/data/epic_kitchen_100/\"))  # doctest: +SKIP\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.epic_kitchen_100.prepare_data","title":"arctix.dataset.epic_kitchen_100.prepare_data","text":"<pre><code>prepare_data(\n    frame: DataFrame, metadata: dict\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Prepare the data.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The raw DataFrame.</p> required <code>metadata</code> <code>dict</code> <p>The metadata wich contains the vocabularies to convert verbs and nouns to index.</p> required <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>A tuple containing the prepared data and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.epic_kitchen_100 import Column, prepare_data\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.ALL_NOUN_IDS: [[3], [114], [3]],\n...         Column.ALL_NOUNS: [[\"door\"], [\"light\"], [\"door\"]],\n...         Column.NARRATION: [\"open door\", \"turn on light\", \"close door\"],\n...         Column.NARRATION_ID: [\"P01_01_0\", \"P01_01_1\", \"P01_01_2\"],\n...         Column.NARRATION_TIMESTAMP: [\n...             datetime.time(0, 0, 1, 89000),\n...             datetime.time(0, 0, 2, 629000),\n...             datetime.time(0, 0, 5, 349000),\n...         ],\n...         Column.NOUN: [\"door\", \"light\", \"door\"],\n...         Column.NOUN_ID: [3, 114, 3],\n...         Column.PARTICIPANT_ID: [\"P01\", \"P01\", \"P01\"],\n...         Column.START_FRAME: [8, 262, 418],\n...         Column.START_TIMESTAMP: [\n...             datetime.time(0, 0, 0, 140000),\n...             datetime.time(0, 0, 4, 370000),\n...             datetime.time(0, 0, 6, 980000),\n...         ],\n...         Column.STOP_FRAME: [202, 370, 569],\n...         Column.STOP_TIMESTAMP: [\n...             datetime.time(0, 0, 3, 370000),\n...             datetime.time(0, 0, 6, 170000),\n...             datetime.time(0, 0, 9, 490000),\n...         ],\n...         Column.VERB: [\"open\", \"turn-on\", \"close\"],\n...         Column.VERB_ID: [3, 6, 4],\n...         Column.VIDEO_ID: [\"P01_01\", \"P01_01\", \"P01_01\"],\n...     },\n...     schema={\n...         Column.ALL_NOUN_IDS: pl.List(pl.Int64),\n...         Column.ALL_NOUNS: pl.List(pl.String),\n...         Column.NARRATION: pl.String,\n...         Column.NARRATION_ID: pl.String,\n...         Column.NARRATION_TIMESTAMP: pl.Time,\n...         Column.NOUN: pl.String,\n...         Column.NOUN_ID: pl.Int64,\n...         Column.PARTICIPANT_ID: pl.String,\n...         Column.START_FRAME: pl.Int64,\n...         Column.START_TIMESTAMP: pl.Time,\n...         Column.STOP_FRAME: pl.Int64,\n...         Column.STOP_TIMESTAMP: pl.Time,\n...         Column.VERB: pl.String,\n...         Column.VERB_ID: pl.Int64,\n...         Column.VIDEO_ID: pl.String,\n...     },\n... )\n&gt;&gt;&gt; data, metadata = prepare_data(frame, metadata={})\n&gt;&gt;&gt; with pl.Config(tbl_cols=-1):\n...     data\n...\nshape: (3, 18)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 all \u2506 all \u2506 nar \u2506 nar \u2506 nar \u2506 nou \u2506 nou \u2506 par \u2506 sta \u2506 sta \u2506 sta \u2506 sta \u2506 sto \u2506 sto \u2506 sto \u2506 ver \u2506 ver \u2506 vid \u2502\n\u2502 _no \u2506 _no \u2506 rat \u2506 rat \u2506 rat \u2506 n   \u2506 n_c \u2506 tic \u2506 rt_ \u2506 rt_ \u2506 rt_ \u2506 rt_ \u2506 p_f \u2506 p_t \u2506 p_t \u2506 b   \u2506 b_c \u2506 eo_ \u2502\n\u2502 un_ \u2506 uns \u2506 ion \u2506 ion \u2506 ion \u2506 --- \u2506 las \u2506 ipa \u2506 fra \u2506 tim \u2506 tim \u2506 tim \u2506 ram \u2506 ime \u2506 ime \u2506 --- \u2506 las \u2506 id  \u2502\n\u2502 cla \u2506 --- \u2506 --- \u2506 _id \u2506 _ti \u2506 str \u2506 s   \u2506 nt_ \u2506 me  \u2506 e_s \u2506 e_s \u2506 est \u2506 e   \u2506 _se \u2506 sta \u2506 str \u2506 s   \u2506 --- \u2502\n\u2502 sse \u2506 lis \u2506 str \u2506 --- \u2506 mes \u2506     \u2506 --- \u2506 id  \u2506 --- \u2506 eco \u2506 eco \u2506 amp \u2506 --- \u2506 con \u2506 mp  \u2506     \u2506 --- \u2506 str \u2502\n\u2502 s   \u2506 t[s \u2506     \u2506 str \u2506 tam \u2506     \u2506 i64 \u2506 --- \u2506 i64 \u2506 nd  \u2506 nd_ \u2506 --- \u2506 i64 \u2506 d   \u2506 --- \u2506     \u2506 i64 \u2506     \u2502\n\u2502 --- \u2506 tr] \u2506     \u2506     \u2506 p   \u2506     \u2506     \u2506 str \u2506     \u2506 --- \u2506 dif \u2506 tim \u2506     \u2506 --- \u2506 tim \u2506     \u2506     \u2506     \u2502\n\u2502 lis \u2506     \u2506     \u2506     \u2506 --- \u2506     \u2506     \u2506     \u2506     \u2506 f64 \u2506 f   \u2506 e   \u2506     \u2506 f64 \u2506 e   \u2506     \u2506     \u2506     \u2502\n\u2502 t[i \u2506     \u2506     \u2506     \u2506 tim \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 --- \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2502\n\u2502 64] \u2506     \u2506     \u2506     \u2506 e   \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 f64 \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [3] \u2506 [\"d \u2506 ope \u2506 P01 \u2506 00: \u2506 doo \u2506 3   \u2506 P01 \u2506 8   \u2506 0.1 \u2506 0.0 \u2506 00: \u2506 202 \u2506 3.3 \u2506 00: \u2506 ope \u2506 3   \u2506 P01 \u2502\n\u2502     \u2506 oor \u2506 n   \u2506 _01 \u2506 00: \u2506 r   \u2506     \u2506     \u2506     \u2506 4   \u2506     \u2506 00: \u2506     \u2506 7   \u2506 00: \u2506 n   \u2506     \u2506 _01 \u2502\n\u2502     \u2506 \"]  \u2506 doo \u2506 _0  \u2506 01. \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 00. \u2506     \u2506     \u2506 03. \u2506     \u2506     \u2506     \u2502\n\u2502     \u2506     \u2506 r   \u2506     \u2506 089 \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 140 \u2506     \u2506     \u2506 370 \u2506     \u2506     \u2506     \u2502\n\u2502 [11 \u2506 [\"l \u2506 tur \u2506 P01 \u2506 00: \u2506 lig \u2506 114 \u2506 P01 \u2506 262 \u2506 4.3 \u2506 4.2 \u2506 00: \u2506 370 \u2506 6.1 \u2506 00: \u2506 tur \u2506 6   \u2506 P01 \u2502\n\u2502 4]  \u2506 igh \u2506 n   \u2506 _01 \u2506 00: \u2506 ht  \u2506     \u2506     \u2506     \u2506 7   \u2506 3   \u2506 00: \u2506     \u2506 7   \u2506 00: \u2506 n-o \u2506     \u2506 _01 \u2502\n\u2502     \u2506 t\"] \u2506 on  \u2506 _1  \u2506 02. \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 04. \u2506     \u2506     \u2506 06. \u2506 n   \u2506     \u2506     \u2502\n\u2502     \u2506     \u2506 lig \u2506     \u2506 629 \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 370 \u2506     \u2506     \u2506 170 \u2506     \u2506     \u2506     \u2502\n\u2502     \u2506     \u2506 ht  \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2502\n\u2502 [3] \u2506 [\"d \u2506 clo \u2506 P01 \u2506 00: \u2506 doo \u2506 3   \u2506 P01 \u2506 418 \u2506 6.9 \u2506 2.6 \u2506 00: \u2506 569 \u2506 9.4 \u2506 00: \u2506 clo \u2506 4   \u2506 P01 \u2502\n\u2502     \u2506 oor \u2506 se  \u2506 _01 \u2506 00: \u2506 r   \u2506     \u2506     \u2506     \u2506 8   \u2506 1   \u2506 00: \u2506     \u2506 9   \u2506 00: \u2506 se  \u2506     \u2506 _01 \u2502\n\u2502     \u2506 \"]  \u2506 doo \u2506 _2  \u2506 05. \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 06. \u2506     \u2506     \u2506 09. \u2506     \u2506     \u2506     \u2502\n\u2502     \u2506     \u2506 r   \u2506     \u2506 349 \u2506     \u2506     \u2506     \u2506     \u2506     \u2506     \u2506 980 \u2506     \u2506     \u2506 490 \u2506     \u2506     \u2506     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; metadata\n{}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.epic_kitchen_100.to_array","title":"arctix.dataset.epic_kitchen_100.to_array","text":"<pre><code>to_array(frame: DataFrame) -&gt; dict[str, ndarray]\n</code></pre> <p>Convert a DataFrame to a dictionary of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The dictionary of arrays.</p>"},{"location":"refs/dataset/#arctix.dataset.epic_kitchen_100.to_list","title":"arctix.dataset.epic_kitchen_100.to_list","text":"<pre><code>to_list(frame: DataFrame) -&gt; dict[str, list]\n</code></pre> <p>Convert a DataFrame to a dictionary of lists.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>The dictionary of lists.</p>"},{"location":"refs/dataset/#arctix.dataset.multithumos","title":"arctix.dataset.multithumos","text":"<p>Contain code to prepare/preprocess the MultiTHUMOS data.</p> <p>The following documentation assumes the data are downloaded in the directory <code>/path/to/data/multithumos/</code>.</p>"},{"location":"refs/dataset/#arctix.dataset.multithumos.fetch_data","title":"arctix.dataset.multithumos.fetch_data","text":"<pre><code>fetch_data(\n    path: Path, force_download: bool = False\n) -&gt; DataFrame\n</code></pre> <p>Download and load the data for Breakfast dataset.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>The path where to store the downloaded data.</p> required <code>force_download</code> <code>bool</code> <p>If <code>True</code>, the annotations are downloaded everytime this function is called. If <code>False</code>, the annotations are downloaded only if the given path does not contain the annotation data.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The data in a DataFrame</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from arctix.dataset.multithumos import fetch_data\n&gt;&gt;&gt; data = fetch_data(Path(\"/path/to/data/multithumos/\"))  # doctest: +SKIP\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.multithumos.prepare_data","title":"arctix.dataset.multithumos.prepare_data","text":"<pre><code>prepare_data(\n    frame: DataFrame, split: str = \"all\"\n) -&gt; tuple[DataFrame, dict]\n</code></pre> <p>Prepare the data.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The raw DataFrame.</p> required <code>split</code> <code>str</code> <p>The dataset split. By default, the union of all the dataset splits is used.</p> <code>'all'</code> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict]</code> <p>A tuple containing the prepared data and the metadata.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.multithumos import Column, prepare_data\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.VIDEO: [\n...             \"video_validation_1\",\n...             \"video_test_2\",\n...             \"video_validation_1\",\n...             \"video_test_2\",\n...         ],\n...         Column.START_TIME: [72.80, 44.00, 1.50, 17.57],\n...         Column.END_TIME: [76.40, 50.90, 5.40, 18.33],\n...         Column.ACTION: [\"dribble\", \"dribble\", \"dribble\", \"guard\"],\n...     }\n... )\n&gt;&gt;&gt; data, metadata = prepare_data(frame)\n&gt;&gt;&gt; data\nshape: (4, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 action  \u2506 action_id \u2506 end_time \u2506 split      \u2506 start_time \u2506 start_time_diff \u2506 video              \u2502\n\u2502 ---     \u2506 ---       \u2506 ---      \u2506 ---        \u2506 ---        \u2506 ---             \u2506 ---                \u2502\n\u2502 str     \u2506 i64       \u2506 f64      \u2506 str        \u2506 f64        \u2506 f64             \u2506 str                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 guard   \u2506 1         \u2506 18.33    \u2506 test       \u2506 17.57      \u2506 0.0             \u2506 video_test_2       \u2502\n\u2502 dribble \u2506 0         \u2506 50.9     \u2506 test       \u2506 44.0       \u2506 26.43           \u2506 video_test_2       \u2502\n\u2502 dribble \u2506 0         \u2506 5.4      \u2506 validation \u2506 1.5        \u2506 0.0             \u2506 video_validation_1 \u2502\n\u2502 dribble \u2506 0         \u2506 76.4     \u2506 validation \u2506 72.8       \u2506 71.3            \u2506 video_validation_1 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; metadata\n{'vocab_action': Vocabulary(\n  counter=Counter({'dribble': 3, 'guard': 1}),\n  index_to_token=('dribble', 'guard'),\n  token_to_index={'dribble': 0, 'guard': 1},\n)}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.multithumos.to_array","title":"arctix.dataset.multithumos.to_array","text":"<pre><code>to_array(frame: DataFrame) -&gt; dict[str, ndarray]\n</code></pre> <p>Convert a DataFrame to a dictionary of arrays.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The dictionary of arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.multithumos import Column, to_array\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.VIDEO: [\n...             \"video_validation_1\",\n...             \"video_validation_1\",\n...             \"video_validation_1\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...         ],\n...         Column.START_TIME: [1.0, 17.0, 79.0, 2.0, 4.0, 20.0, 27.0],\n...         Column.START_TIME_DIFF: [0.0, 16.07, 61.73, 0.0, 1.57, 15.68, 7.20],\n...         Column.END_TIME: [5.0, 18.0, 83.0, 3.0, 5.0, 20.0, 30.0],\n...         Column.ACTION: [\n...             \"dribble\",\n...             \"guard\",\n...             \"dribble\",\n...             \"guard\",\n...             \"guard\",\n...             \"guard\",\n...             \"shoot\",\n...         ],\n...         Column.ACTION_ID: [1, 0, 1, 0, 0, 0, 2],\n...         Column.SPLIT: [\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...         ],\n...     },\n... )\n&gt;&gt;&gt; arrays = to_array(frame)\n&gt;&gt;&gt; arrays\n{'action': masked_array(\n  data=[['dribble', 'guard', 'dribble', --],\n        ['guard', 'guard', 'guard', 'shoot']],\n  mask=[[False, False, False,  True],\n        [False, False, False, False]],\n  fill_value='N/A',\n  dtype='&lt;U7'),\n  'action_id': masked_array(\n  data=[[1, 0, 1, --],\n        [0, 0, 0, 2]],\n  mask=[[False, False, False,  True],\n        [False, False, False, False]],\n  fill_value=999999),\n  'end_time': masked_array(\n  data=[[5.0, 18.0, 83.0, --],\n        [3.0, 5.0, 20.0, 30.0]],\n  mask=[[False, False, False,  True],\n        [False, False, False, False]],\n  fill_value=1e+20),\n  'sequence_length': array([3, 4]),\n  'split': array(['validation', 'validation'], dtype='&lt;U10'),\n  'start_time': masked_array(\n  data=[[1.0, 17.0, 79.0, --],\n        [2.0, 4.0, 20.0, 27.0]],\n  mask=[[False, False, False,  True],\n        [False, False, False, False]],\n  fill_value=1e+20),\n  'start_time_diff': masked_array(\n  data=[[0.0, 16.07, 61.73, --],\n        [0.0, 1.57, 15.68, 7.2]],\n  mask=[[False, False, False,  True],\n        [False, False, False, False]],\n  fill_value=1e+20)}\n</code></pre>"},{"location":"refs/dataset/#arctix.dataset.multithumos.to_list","title":"arctix.dataset.multithumos.to_list","text":"<pre><code>to_list(frame: DataFrame) -&gt; dict[str, list]\n</code></pre> <p>Convert a DataFrame to a dictionary of lists.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame.</p> required <p>Returns:</p> Type Description <code>dict[str, list]</code> <p>The dictionary of lists.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.dataset.multithumos import Column, to_list\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         Column.VIDEO: [\n...             \"video_validation_1\",\n...             \"video_validation_1\",\n...             \"video_validation_1\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...             \"video_validation_2\",\n...         ],\n...         Column.START_TIME: [1.0, 17.0, 79.0, 2.0, 4.0, 20.0, 27.0],\n...         Column.START_TIME_DIFF: [0.0, 16.07, 61.73, 0.0, 1.57, 15.68, 7.20],\n...         Column.END_TIME: [5.0, 18.0, 83.0, 3.0, 5.0, 20.0, 30.0],\n...         Column.ACTION: [\n...             \"dribble\",\n...             \"guard\",\n...             \"dribble\",\n...             \"guard\",\n...             \"guard\",\n...             \"guard\",\n...             \"shoot\",\n...         ],\n...         Column.ACTION_ID: [1, 0, 1, 0, 0, 0, 2],\n...         Column.SPLIT: [\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...             \"validation\",\n...         ],\n...     },\n... )\n&gt;&gt;&gt; data_list = to_list(frame)\n&gt;&gt;&gt; data_list\n{'action': [['dribble', 'guard', 'dribble'], ['guard', 'guard', 'guard', 'shoot']],\n 'action_id': [[1, 0, 1], [0, 0, 0, 2]],\n 'end_time': [[5.0, 18.0, 83.0], [3.0, 5.0, 20.0, 30.0]],\n 'sequence_length': [3, 4],\n 'split': ['validation', 'validation'],\n 'start_time': [[1.0, 17.0, 79.0], [2.0, 4.0, 20.0, 27.0]],\n 'start_time_diff': [[0.0, 16.07, 61.73], [0.0, 1.57, 15.68, 7.2]],\n 'video': ['video_validation_1', 'video_validation_2']}\n</code></pre>"},{"location":"refs/transformer/","title":"arctix.transformer","text":""},{"location":"refs/transformer/#arctix.transformer.dataframe","title":"arctix.transformer.dataframe","text":"<p>Contain DataFrame transformers.</p>"},{"location":"refs/transformer/#arctix.transformer.dataframe.BaseDataFrameTransformer","title":"arctix.transformer.dataframe.BaseDataFrameTransformer","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to transform a <code>polars.DataFrame</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Cast\n&gt;&gt;&gt; transformer = Cast(columns=[\"col1\", \"col3\"], dtype=pl.Int32)\n&gt;&gt;&gt; transformer\nCastDataFrameTransformer(columns=('col1', 'col3'), dtype=Int32)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i32  \u2506 str  \u2506 i32  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.BaseDataFrameTransformer.transform","title":"arctix.transformer.dataframe.BaseDataFrameTransformer.transform","text":"<pre><code>transform(frame: DataFrame) -&gt; DataFrame\n</code></pre> <p>Transform the data in the <code>polars.DataFrame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>Specifies the <code>polars.DataFrame</code> to transform.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The transformed DataFrame.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Cast\n&gt;&gt;&gt; transformer = Cast(columns=[\"col1\", \"col3\"], dtype=pl.Int32)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i32  \u2506 str  \u2506 i32  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Cast","title":"arctix.transformer.dataframe.Cast","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert some columns to a new data type.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>dtype</code> <code>type[DataType]</code> <p>The target data type.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Cast\n&gt;&gt;&gt; transformer = Cast(columns=[\"col1\", \"col3\"], dtype=pl.Int32)\n&gt;&gt;&gt; transformer\nCastDataFrameTransformer(columns=('col1', 'col3'), dtype=Int32)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i32  \u2506 str  \u2506 i32  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.CastDataFrameTransformer","title":"arctix.transformer.dataframe.CastDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert some columns to a new data type.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>dtype</code> <code>type[DataType]</code> <p>The target data type.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Cast\n&gt;&gt;&gt; transformer = Cast(columns=[\"col1\", \"col3\"], dtype=pl.Int32)\n&gt;&gt;&gt; transformer\nCastDataFrameTransformer(columns=('col1', 'col3'), dtype=Int32)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i32  \u2506 str  \u2506 i32  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 1    \u2506 a    \u2502\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 3    \u2506 3    \u2506 3    \u2506 c    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2502 5    \u2506 5    \u2506 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Diff","title":"arctix.transformer.dataframe.Diff","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to compute the first discrete difference between shifted items.</p> <p>Parameters:</p> Name Type Description Default <code>in_col</code> <code>str</code> <p>The input column name.</p> required <code>out_col</code> <code>str</code> <p>The output column name.</p> required <code>shift</code> <code>int</code> <p>The number of slots to shift.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Diff\n&gt;&gt;&gt; transformer = Diff(in_col=\"col1\", out_col=\"diff\")\n&gt;&gt;&gt; transformer\nDiffDataFrameTransformer(in_col=col1, out_col=diff, shift=1)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col1\": [1, 2, 3, 4, 5], \"col2\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 a    \u2502\n\u2502 2    \u2506 b    \u2502\n\u2502 3    \u2506 c    \u2502\n\u2502 4    \u2506 d    \u2502\n\u2502 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 diff \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 a    \u2506 null \u2502\n\u2502 2    \u2506 b    \u2506 1    \u2502\n\u2502 3    \u2506 c    \u2506 1    \u2502\n\u2502 4    \u2506 d    \u2506 1    \u2502\n\u2502 5    \u2506 e    \u2506 1    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.DiffDataFrameTransformer","title":"arctix.transformer.dataframe.DiffDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to compute the first discrete difference between shifted items.</p> <p>Parameters:</p> Name Type Description Default <code>in_col</code> <code>str</code> <p>The input column name.</p> required <code>out_col</code> <code>str</code> <p>The output column name.</p> required <code>shift</code> <code>int</code> <p>The number of slots to shift.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Diff\n&gt;&gt;&gt; transformer = Diff(in_col=\"col1\", out_col=\"diff\")\n&gt;&gt;&gt; transformer\nDiffDataFrameTransformer(in_col=col1, out_col=diff, shift=1)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col1\": [1, 2, 3, 4, 5], \"col2\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 a    \u2502\n\u2502 2    \u2506 b    \u2502\n\u2502 3    \u2506 c    \u2502\n\u2502 4    \u2506 d    \u2502\n\u2502 5    \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 diff \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 a    \u2506 null \u2502\n\u2502 2    \u2506 b    \u2506 1    \u2502\n\u2502 3    \u2506 c    \u2506 1    \u2502\n\u2502 4    \u2506 d    \u2506 1    \u2502\n\u2502 5    \u2506 e    \u2506 1    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Function","title":"arctix.transformer.dataframe.Function","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer that is a wrapper around a function to transform the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[DataFrame], DataFrame]</code> <p>The function to transform the DataFrame.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import FunctionDataFrameTransformer\n&gt;&gt;&gt; transformer = FunctionDataFrameTransformer(\n...     func=lambda frame: frame.filter(pl.col(\"col1\").is_in({2, 4}))\n... )\n&gt;&gt;&gt; transformer\nFunctionDataFrameTransformer(func=&lt;function &lt;lambda&gt; at 0x...&gt;)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.FunctionDataFrameTransformer","title":"arctix.transformer.dataframe.FunctionDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer that is a wrapper around a function to transform the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[[DataFrame], DataFrame]</code> <p>The function to transform the DataFrame.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import FunctionDataFrameTransformer\n&gt;&gt;&gt; transformer = FunctionDataFrameTransformer(\n...     func=lambda frame: frame.filter(pl.col(\"col1\").is_in({2, 4}))\n... )\n&gt;&gt;&gt; transformer\nFunctionDataFrameTransformer(func=&lt;function &lt;lambda&gt; at 0x...&gt;)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2    \u2506 2    \u2506 2    \u2506 b    \u2502\n\u2502 4    \u2506 4    \u2506 4    \u2506 d    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.IndexToToken","title":"arctix.transformer.dataframe.IndexToToken","text":"<p>               Bases: <code>ReplaceStrictDataFrameTransformer</code></p> <p>Replace.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocabulary</code> <p>The vocabulary which contains the index to token mapping.</p> required <code>index_column</code> <code>str</code> <p>The column name which contains the input indices.</p> required <code>token_column</code> <code>str</code> <p>The column name which contains the output tokens.</p> required <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from collections import Counter\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import IndexToToken\n&gt;&gt;&gt; from arctix.utils.vocab import Vocabulary\n&gt;&gt;&gt; vocab = Vocabulary(Counter({\"b\": 3, \"a\": 1, \"c\": 2, \"d\": 4}))\n&gt;&gt;&gt; vocab.get_index_to_token()\n('b', 'a', 'c', 'd')\n&gt;&gt;&gt; transformer = IndexToToken(\n...     vocab=vocab,\n...     index_column=\"col\",\n...     token_column=\"token\",\n... )\n&gt;&gt;&gt; transformer\nIndexToTokenDataFrameTransformer(orig_column=col, final_column=token)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [1, 0, 2, 3, 1]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 0   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2502 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 token \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 a     \u2502\n\u2502 0   \u2506 b     \u2502\n\u2502 2   \u2506 c     \u2502\n\u2502 3   \u2506 d     \u2502\n\u2502 1   \u2506 a     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.IndexToTokenDataFrameTransformer","title":"arctix.transformer.dataframe.IndexToTokenDataFrameTransformer","text":"<p>               Bases: <code>ReplaceStrictDataFrameTransformer</code></p> <p>Replace.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocabulary</code> <p>The vocabulary which contains the index to token mapping.</p> required <code>index_column</code> <code>str</code> <p>The column name which contains the input indices.</p> required <code>token_column</code> <code>str</code> <p>The column name which contains the output tokens.</p> required <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from collections import Counter\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import IndexToToken\n&gt;&gt;&gt; from arctix.utils.vocab import Vocabulary\n&gt;&gt;&gt; vocab = Vocabulary(Counter({\"b\": 3, \"a\": 1, \"c\": 2, \"d\": 4}))\n&gt;&gt;&gt; vocab.get_index_to_token()\n('b', 'a', 'c', 'd')\n&gt;&gt;&gt; transformer = IndexToToken(\n...     vocab=vocab,\n...     index_column=\"col\",\n...     token_column=\"token\",\n... )\n&gt;&gt;&gt; transformer\nIndexToTokenDataFrameTransformer(orig_column=col, final_column=token)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [1, 0, 2, 3, 1]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 0   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2502 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 token \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 a     \u2502\n\u2502 0   \u2506 b     \u2502\n\u2502 2   \u2506 c     \u2502\n\u2502 3   \u2506 d     \u2502\n\u2502 1   \u2506 a     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.JsonDecode","title":"arctix.transformer.dataframe.JsonDecode","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to parse string values as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to parse.</p> required <code>dtype</code> <code>PolarsDataType | PythonDataType | None</code> <p>The dtype to cast the extracted value to. If <code>None</code>, the dtype will be inferred from the JSON value.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import JsonDecode\n&gt;&gt;&gt; transformer = JsonDecode(columns=[\"col1\", \"col3\"])\n&gt;&gt;&gt; transformer\nJsonDecodeDataFrameTransformer(columns=('col1', 'col3'), dtype=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [\"[1, 2]\", \"[2]\", \"[1, 2, 3]\", \"[4, 5]\", \"[5, 4]\"],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"['1', '2']\", \"['2']\", \"['1', '2', '3']\", \"['4', '5']\", \"['5', '4']\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1      \u2506 col2 \u2506 col3            \u2506 col4 \u2502\n\u2502 ---       \u2506 ---  \u2506 ---             \u2506 ---  \u2502\n\u2502 str       \u2506 str  \u2506 str             \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 2]    \u2506 1    \u2506 ['1', '2']      \u2506 a    \u2502\n\u2502 [2]       \u2506 2    \u2506 ['2']           \u2506 b    \u2502\n\u2502 [1, 2, 3] \u2506 3    \u2506 ['1', '2', '3'] \u2506 c    \u2502\n\u2502 [4, 5]    \u2506 4    \u2506 ['4', '5']      \u2506 d    \u2502\n\u2502 [5, 4]    \u2506 5    \u2506 ['5', '4']      \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1      \u2506 col2 \u2506 col3            \u2506 col4 \u2502\n\u2502 ---       \u2506 ---  \u2506 ---             \u2506 ---  \u2502\n\u2502 list[i64] \u2506 str  \u2506 list[str]       \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 2]    \u2506 1    \u2506 [\"1\", \"2\"]      \u2506 a    \u2502\n\u2502 [2]       \u2506 2    \u2506 [\"2\"]           \u2506 b    \u2502\n\u2502 [1, 2, 3] \u2506 3    \u2506 [\"1\", \"2\", \"3\"] \u2506 c    \u2502\n\u2502 [4, 5]    \u2506 4    \u2506 [\"4\", \"5\"]      \u2506 d    \u2502\n\u2502 [5, 4]    \u2506 5    \u2506 [\"5\", \"4\"]      \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.JsonDecodeDataFrameTransformer","title":"arctix.transformer.dataframe.JsonDecodeDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to parse string values as JSON.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to parse.</p> required <code>dtype</code> <code>PolarsDataType | PythonDataType | None</code> <p>The dtype to cast the extracted value to. If <code>None</code>, the dtype will be inferred from the JSON value.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import JsonDecode\n&gt;&gt;&gt; transformer = JsonDecode(columns=[\"col1\", \"col3\"])\n&gt;&gt;&gt; transformer\nJsonDecodeDataFrameTransformer(columns=('col1', 'col3'), dtype=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [\"[1, 2]\", \"[2]\", \"[1, 2, 3]\", \"[4, 5]\", \"[5, 4]\"],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"['1', '2']\", \"['2']\", \"['1', '2', '3']\", \"['4', '5']\", \"['5', '4']\"],\n...         \"col4\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1      \u2506 col2 \u2506 col3            \u2506 col4 \u2502\n\u2502 ---       \u2506 ---  \u2506 ---             \u2506 ---  \u2502\n\u2502 str       \u2506 str  \u2506 str             \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 2]    \u2506 1    \u2506 ['1', '2']      \u2506 a    \u2502\n\u2502 [2]       \u2506 2    \u2506 ['2']           \u2506 b    \u2502\n\u2502 [1, 2, 3] \u2506 3    \u2506 ['1', '2', '3'] \u2506 c    \u2502\n\u2502 [4, 5]    \u2506 4    \u2506 ['4', '5']      \u2506 d    \u2502\n\u2502 [5, 4]    \u2506 5    \u2506 ['5', '4']      \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1      \u2506 col2 \u2506 col3            \u2506 col4 \u2502\n\u2502 ---       \u2506 ---  \u2506 ---             \u2506 ---  \u2502\n\u2502 list[i64] \u2506 str  \u2506 list[str]       \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 2]    \u2506 1    \u2506 [\"1\", \"2\"]      \u2506 a    \u2502\n\u2502 [2]       \u2506 2    \u2506 [\"2\"]           \u2506 b    \u2502\n\u2502 [1, 2, 3] \u2506 3    \u2506 [\"1\", \"2\", \"3\"] \u2506 c    \u2502\n\u2502 [4, 5]    \u2506 4    \u2506 [\"4\", \"5\"]      \u2506 d    \u2502\n\u2502 [5, 4]    \u2506 5    \u2506 [\"5\", \"4\"]      \u2506 e    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Replace","title":"arctix.transformer.dataframe.Replace","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>orig_column</code> <code>str</code> <p>The original column name.</p> required <code>final_column</code> <code>str</code> <p>The final column name.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>replace</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Replace\n&gt;&gt;&gt; transformer = Replace(\n...     orig_column=\"old\", final_column=\"new\", old={\"a\": 1, \"b\": 2, \"c\": 3}\n... )\n&gt;&gt;&gt; transformer\nReplaceDataFrameTransformer(orig_column=old, final_column=new)\n&gt;&gt;&gt; frame = pl.DataFrame({\"old\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2502\n\u2502 b   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2502 d   \u2506 d   \u2502\n\u2502 e   \u2506 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; transformer = Replace(\n...     orig_column=\"old\",\n...     final_column=\"new\",\n...     old={\"a\": 1, \"b\": 2, \"c\": 3},\n...     default=None,\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new  \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 c   \u2506 3    \u2502\n\u2502 d   \u2506 null \u2502\n\u2502 e   \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.ReplaceDataFrameTransformer","title":"arctix.transformer.dataframe.ReplaceDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>orig_column</code> <code>str</code> <p>The original column name.</p> required <code>final_column</code> <code>str</code> <p>The final column name.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>replace</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Replace\n&gt;&gt;&gt; transformer = Replace(\n...     orig_column=\"old\", final_column=\"new\", old={\"a\": 1, \"b\": 2, \"c\": 3}\n... )\n&gt;&gt;&gt; transformer\nReplaceDataFrameTransformer(orig_column=old, final_column=new)\n&gt;&gt;&gt; frame = pl.DataFrame({\"old\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2502\n\u2502 b   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2502 d   \u2506 d   \u2502\n\u2502 e   \u2506 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; transformer = Replace(\n...     orig_column=\"old\",\n...     final_column=\"new\",\n...     old={\"a\": 1, \"b\": 2, \"c\": 3},\n...     default=None,\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new  \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 c   \u2506 3    \u2502\n\u2502 d   \u2506 null \u2502\n\u2502 e   \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.ReplaceStrict","title":"arctix.transformer.dataframe.ReplaceStrict","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>orig_column</code> <code>str</code> <p>The original column name.</p> required <code>final_column</code> <code>str</code> <p>The final column name.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>replace</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import ReplaceStrict\n&gt;&gt;&gt; transformer = ReplaceStrict(\n...     orig_column=\"old\", final_column=\"new\", old={\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5}\n... )\n&gt;&gt;&gt; transformer\nReplaceStrictDataFrameTransformer(orig_column=old, final_column=new)\n&gt;&gt;&gt; frame = pl.DataFrame({\"old\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2502\n\u2502 b   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2502 d   \u2506 4   \u2502\n\u2502 e   \u2506 5   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; transformer = ReplaceStrict(\n...     orig_column=\"old\",\n...     final_column=\"new\",\n...     old={\"a\": 1, \"b\": 2, \"c\": 3},\n...     default=None,\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new  \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 c   \u2506 3    \u2502\n\u2502 d   \u2506 null \u2502\n\u2502 e   \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.ReplaceStrictDataFrameTransformer","title":"arctix.transformer.dataframe.ReplaceStrictDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>orig_column</code> <code>str</code> <p>The original column name.</p> required <code>final_column</code> <code>str</code> <p>The final column name.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>replace</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import ReplaceStrict\n&gt;&gt;&gt; transformer = ReplaceStrict(\n...     orig_column=\"old\", final_column=\"new\", old={\"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5}\n... )\n&gt;&gt;&gt; transformer\nReplaceStrictDataFrameTransformer(orig_column=old, final_column=new)\n&gt;&gt;&gt; frame = pl.DataFrame({\"old\": [\"a\", \"b\", \"c\", \"d\", \"e\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2502\n\u2502 b   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2502 d   \u2506 4   \u2502\n\u2502 e   \u2506 5   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; transformer = ReplaceStrict(\n...     orig_column=\"old\",\n...     final_column=\"new\",\n...     old={\"a\": 1, \"b\": 2, \"c\": 3},\n...     default=None,\n... )\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 old \u2506 new  \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 c   \u2506 3    \u2502\n\u2502 d   \u2506 null \u2502\n\u2502 e   \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Sequential","title":"arctix.transformer.dataframe.Sequential","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a <code>polars.DataFrame</code> transformer to apply sequentially several transformers.</p> <p>Parameters:</p> Name Type Description Default <code>transformers</code> <code>Sequence[BaseDataFrameTransformer | dict]</code> <p>The transformers or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import (\n...     Sequential,\n...     Cast,\n... )\n&gt;&gt;&gt; transformer = Sequential(\n...     [\n...         Cast(columns=[\"col1\"], dtype=pl.Float32),\n...         Cast(columns=[\"col2\"], dtype=pl.Int64),\n...     ]\n... )\n&gt;&gt;&gt; transformer\nSequentialDataFrameTransformer(\n  (0): CastDataFrameTransformer(columns=('col1',), dtype=Float32)\n  (1): CastDataFrameTransformer(columns=('col2',), dtype=Int64)\n)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...         \"col4\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 f32  \u2506 i64  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2.0  \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3.0  \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4.0  \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5.0  \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.SequentialDataFrameTransformer","title":"arctix.transformer.dataframe.SequentialDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a <code>polars.DataFrame</code> transformer to apply sequentially several transformers.</p> <p>Parameters:</p> Name Type Description Default <code>transformers</code> <code>Sequence[BaseDataFrameTransformer | dict]</code> <p>The transformers or their configurations.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import (\n...     Sequential,\n...     Cast,\n... )\n&gt;&gt;&gt; transformer = Sequential(\n...     [\n...         Cast(columns=[\"col1\"], dtype=pl.Float32),\n...         Cast(columns=[\"col2\"], dtype=pl.Int64),\n...     ]\n... )\n&gt;&gt;&gt; transformer\nSequentialDataFrameTransformer(\n  (0): CastDataFrameTransformer(columns=('col1',), dtype=Float32)\n  (1): CastDataFrameTransformer(columns=('col2',), dtype=Int64)\n)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...         \"col4\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 f32  \u2506 i64  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2.0  \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3.0  \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4.0  \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5.0  \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.Sort","title":"arctix.transformer.dataframe.Sort","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to sort the DataFrame by the given columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>sort</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>sort</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Sort\n&gt;&gt;&gt; transformer = Sort(columns=[\"col3\", \"col1\"])\n&gt;&gt;&gt; transformer\nSortDataFrameTransformer(columns=('col3', 'col1'))\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\"col1\": [1, 2, None], \"col2\": [6.0, 5.0, 4.0], \"col3\": [\"a\", \"c\", \"b\"]}\n... )\n&gt;&gt;&gt; frame\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.SortColumns","title":"arctix.transformer.dataframe.SortColumns","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to sort the DataFrame columns by name.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>If set to <code>False</code>, then the columns are sorted by alphabetical order.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import SortColumns\n&gt;&gt;&gt; transformer = SortColumns()\n&gt;&gt;&gt; transformer\nSortColumnsDataFrameTransformer(reverse=False)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\"col2\": [1, 2, None], \"col3\": [6.0, 5.0, 4.0], \"col1\": [\"a\", \"c\", \"b\"]}\n... )\n&gt;&gt;&gt; frame\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col2 \u2506 col3 \u2506 col1 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 str  \u2506 i64  \u2506 f64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a    \u2506 1    \u2506 6.0  \u2502\n\u2502 c    \u2506 2    \u2506 5.0  \u2502\n\u2502 b    \u2506 null \u2506 4.0  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.SortColumnsDataFrameTransformer","title":"arctix.transformer.dataframe.SortColumnsDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to sort the DataFrame columns by name.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>If set to <code>False</code>, then the columns are sorted by alphabetical order.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import SortColumns\n&gt;&gt;&gt; transformer = SortColumns()\n&gt;&gt;&gt; transformer\nSortColumnsDataFrameTransformer(reverse=False)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\"col2\": [1, 2, None], \"col3\": [6.0, 5.0, 4.0], \"col1\": [\"a\", \"c\", \"b\"]}\n... )\n&gt;&gt;&gt; frame\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col2 \u2506 col3 \u2506 col1 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 str  \u2506 i64  \u2506 f64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a    \u2506 1    \u2506 6.0  \u2502\n\u2502 c    \u2506 2    \u2506 5.0  \u2502\n\u2502 b    \u2506 null \u2506 4.0  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.SortDataFrameTransformer","title":"arctix.transformer.dataframe.SortDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to sort the DataFrame by the given columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>*args</code> <code>Any</code> <p>The positional arguments to pass to <code>sort</code>.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>sort</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import Sort\n&gt;&gt;&gt; transformer = Sort(columns=[\"col3\", \"col1\"])\n&gt;&gt;&gt; transformer\nSortDataFrameTransformer(columns=('col3', 'col1'))\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\"col1\": [1, 2, None], \"col2\": [6.0, 5.0, 4.0], \"col3\": [\"a\", \"c\", \"b\"]}\n... )\n&gt;&gt;&gt; frame\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2502\n\u2502 i64  \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0  \u2506 a    \u2502\n\u2502 null \u2506 4.0  \u2506 b    \u2502\n\u2502 2    \u2506 5.0  \u2506 c    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.StripChars","title":"arctix.transformer.dataframe.StripChars","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to remove leading and trailing characters.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to prepare.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import StripChars\n&gt;&gt;&gt; transformer = StripChars(columns=[\"col2\", \"col3\"])\n&gt;&gt;&gt; transformer\nStripCharsDataFrameTransformer(columns=('col2', 'col3'))\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...         \"col4\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a    \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506 b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506 c    \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d    \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e    \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.StripCharsDataFrameTransformer","title":"arctix.transformer.dataframe.StripCharsDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to remove leading and trailing characters.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to prepare.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import StripChars\n&gt;&gt;&gt; transformer = StripChars(columns=[\"col2\", \"col3\"])\n&gt;&gt;&gt; transformer\nStripCharsDataFrameTransformer(columns=('col2', 'col3'))\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1, 2, 3, 4, 5],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...         \"col4\": [\"a \", \" b\", \"  c  \", \"d\", \"e\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3  \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---   \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str   \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a     \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506  b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506   c   \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d     \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e     \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1 \u2506 col2 \u2506 col3 \u2506 col4  \u2502\n\u2502 ---  \u2506 ---  \u2506 ---  \u2506 ---   \u2502\n\u2502 i64  \u2506 str  \u2506 str  \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1    \u2506 a    \u2506 a     \u2502\n\u2502 2    \u2506 2    \u2506 b    \u2506  b    \u2502\n\u2502 3    \u2506 3    \u2506 c    \u2506   c   \u2502\n\u2502 4    \u2506 4    \u2506 d    \u2506 d     \u2502\n\u2502 5    \u2506 5    \u2506 e    \u2506 e     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TimeDiff","title":"arctix.transformer.dataframe.TimeDiff","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to compute the time difference between consecutive time steps.</p> <p>Parameters:</p> Name Type Description Default <code>group_cols</code> <code>Sequence[str]</code> <p>The columns used to generate the group for each sequence.</p> required <code>time_col</code> <code>str</code> <p>The input time column name.</p> required <code>time_diff_col</code> <code>str</code> <p>The output time difference column name.</p> required <code>shift</code> <code>int</code> <p>The number of slots to shift.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TimeDiff\n&gt;&gt;&gt; transformer = TimeDiff(group_cols=[\"col\"], time_col=\"time\", time_diff_col=\"diff\")\n&gt;&gt;&gt; transformer\nTimeDiffDataFrameTransformer(group_cols=['col'], time_col=time, time_diff_col=diff, shift=1)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [\"a\", \"b\", \"a\", \"a\", \"b\"], \"time\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 time \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 a   \u2506 3    \u2502\n\u2502 a   \u2506 4    \u2502\n\u2502 b   \u2506 5    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 time \u2506 diff \u2502\n\u2502 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2506 0    \u2502\n\u2502 a   \u2506 3    \u2506 2    \u2502\n\u2502 a   \u2506 4    \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2506 0    \u2502\n\u2502 b   \u2506 5    \u2506 3    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TimeDiffDataFrameTransformer","title":"arctix.transformer.dataframe.TimeDiffDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to compute the time difference between consecutive time steps.</p> <p>Parameters:</p> Name Type Description Default <code>group_cols</code> <code>Sequence[str]</code> <p>The columns used to generate the group for each sequence.</p> required <code>time_col</code> <code>str</code> <p>The input time column name.</p> required <code>time_diff_col</code> <code>str</code> <p>The output time difference column name.</p> required <code>shift</code> <code>int</code> <p>The number of slots to shift.</p> <code>1</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TimeDiff\n&gt;&gt;&gt; transformer = TimeDiff(group_cols=[\"col\"], time_col=\"time\", time_diff_col=\"diff\")\n&gt;&gt;&gt; transformer\nTimeDiffDataFrameTransformer(group_cols=['col'], time_col=time, time_diff_col=diff, shift=1)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [\"a\", \"b\", \"a\", \"a\", \"b\"], \"time\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 time \u2502\n\u2502 --- \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2502\n\u2502 a   \u2506 3    \u2502\n\u2502 a   \u2506 4    \u2502\n\u2502 b   \u2506 5    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 time \u2506 diff \u2502\n\u2502 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 str \u2506 i64  \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1    \u2506 0    \u2502\n\u2502 a   \u2506 3    \u2506 2    \u2502\n\u2502 a   \u2506 4    \u2506 1    \u2502\n\u2502 b   \u2506 2    \u2506 0    \u2502\n\u2502 b   \u2506 5    \u2506 3    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TimeToSecond","title":"arctix.transformer.dataframe.TimeToSecond","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert a column with time values to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>in_col</code> <code>str</code> <p>The input column with the time value to convert.</p> required <code>out_col</code> <code>str</code> <p>The output column with the time in seconds.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TimeToSecond\n&gt;&gt;&gt; transformer = TimeToSecond(in_col=\"time\", out_col=\"second\")\n&gt;&gt;&gt; transformer\nTimeToSecondDataFrameTransformer(in_col=time, out_col=second)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"time\": [\n...             datetime.time(0, 0, 1, 890000),\n...             datetime.time(0, 1, 1, 890000),\n...             datetime.time(1, 1, 1, 890000),\n...             datetime.time(0, 19, 19, 890000),\n...             datetime.time(19, 19, 19, 890000),\n...         ],\n...         \"col\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     },\n...     schema={\"time\": pl.Time, \"col\": pl.String},\n... )\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 time         \u2506 col \u2502\n\u2502 ---          \u2506 --- \u2502\n\u2502 time         \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 00:00:01.890 \u2506 a   \u2502\n\u2502 00:01:01.890 \u2506 b   \u2502\n\u2502 01:01:01.890 \u2506 c   \u2502\n\u2502 00:19:19.890 \u2506 d   \u2502\n\u2502 19:19:19.890 \u2506 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 time         \u2506 col \u2506 second   \u2502\n\u2502 ---          \u2506 --- \u2506 ---      \u2502\n\u2502 time         \u2506 str \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 00:00:01.890 \u2506 a   \u2506 1.89     \u2502\n\u2502 00:01:01.890 \u2506 b   \u2506 61.89    \u2502\n\u2502 01:01:01.890 \u2506 c   \u2506 3661.89  \u2502\n\u2502 00:19:19.890 \u2506 d   \u2506 1159.89  \u2502\n\u2502 19:19:19.890 \u2506 e   \u2506 69559.89 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TimeToSecondDataFrameTransformer","title":"arctix.transformer.dataframe.TimeToSecondDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert a column with time values to seconds.</p> <p>Parameters:</p> Name Type Description Default <code>in_col</code> <code>str</code> <p>The input column with the time value to convert.</p> required <code>out_col</code> <code>str</code> <p>The output column with the time in seconds.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import datetime\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TimeToSecond\n&gt;&gt;&gt; transformer = TimeToSecond(in_col=\"time\", out_col=\"second\")\n&gt;&gt;&gt; transformer\nTimeToSecondDataFrameTransformer(in_col=time, out_col=second)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"time\": [\n...             datetime.time(0, 0, 1, 890000),\n...             datetime.time(0, 1, 1, 890000),\n...             datetime.time(1, 1, 1, 890000),\n...             datetime.time(0, 19, 19, 890000),\n...             datetime.time(19, 19, 19, 890000),\n...         ],\n...         \"col\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n...     },\n...     schema={\"time\": pl.Time, \"col\": pl.String},\n... )\n&gt;&gt;&gt; frame\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 time         \u2506 col \u2502\n\u2502 ---          \u2506 --- \u2502\n\u2502 time         \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 00:00:01.890 \u2506 a   \u2502\n\u2502 00:01:01.890 \u2506 b   \u2502\n\u2502 01:01:01.890 \u2506 c   \u2502\n\u2502 00:19:19.890 \u2506 d   \u2502\n\u2502 19:19:19.890 \u2506 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 time         \u2506 col \u2506 second   \u2502\n\u2502 ---          \u2506 --- \u2506 ---      \u2502\n\u2502 time         \u2506 str \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 00:00:01.890 \u2506 a   \u2506 1.89     \u2502\n\u2502 00:01:01.890 \u2506 b   \u2506 61.89    \u2502\n\u2502 01:01:01.890 \u2506 c   \u2506 3661.89  \u2502\n\u2502 00:19:19.890 \u2506 d   \u2506 1159.89  \u2502\n\u2502 19:19:19.890 \u2506 e   \u2506 69559.89 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.ToTime","title":"arctix.transformer.dataframe.ToTime","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert some columns to a <code>polars.Time</code> type.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>format</code> <code>str | None</code> <p>Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: <code>\"%H:%M:%S\"</code>. If set to <code>None</code> (default), the format is inferred from the data.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import ToTime\n&gt;&gt;&gt; transformer = ToTime(columns=[\"col1\"], format=\"%H:%M:%S\")\n&gt;&gt;&gt; transformer\nToTimeDataFrameTransformer(columns=('col1',), format=%H:%M:%S)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [\"01:01:01\", \"02:02:02\", \"12:00:01\", \"18:18:18\", \"23:59:59\"],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"01:01:01\", \"02:02:02\", \"12:00:01\", \"18:18:18\", \"23:59:59\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1     \u2506 col2 \u2506 col3     \u2502\n\u2502 ---      \u2506 ---  \u2506 ---      \u2502\n\u2502 str      \u2506 str  \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 01:01:01 \u2506 1    \u2506 01:01:01 \u2502\n\u2502 02:02:02 \u2506 2    \u2506 02:02:02 \u2502\n\u2502 12:00:01 \u2506 3    \u2506 12:00:01 \u2502\n\u2502 18:18:18 \u2506 4    \u2506 18:18:18 \u2502\n\u2502 23:59:59 \u2506 5    \u2506 23:59:59 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1     \u2506 col2 \u2506 col3     \u2502\n\u2502 ---      \u2506 ---  \u2506 ---      \u2502\n\u2502 time     \u2506 str  \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 01:01:01 \u2506 1    \u2506 01:01:01 \u2502\n\u2502 02:02:02 \u2506 2    \u2506 02:02:02 \u2502\n\u2502 12:00:01 \u2506 3    \u2506 12:00:01 \u2502\n\u2502 18:18:18 \u2506 4    \u2506 18:18:18 \u2502\n\u2502 23:59:59 \u2506 5    \u2506 23:59:59 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.ToTimeDataFrameTransformer","title":"arctix.transformer.dataframe.ToTimeDataFrameTransformer","text":"<p>               Bases: <code>BaseDataFrameTransformer</code></p> <p>Implement a transformer to convert some columns to a <code>polars.Time</code> type.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str]</code> <p>The columns to convert.</p> required <code>format</code> <code>str | None</code> <p>Format to use for conversion. Refer to the chrono crate documentation for the full specification. Example: <code>\"%H:%M:%S\"</code>. If set to <code>None</code> (default), the format is inferred from the data.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import ToTime\n&gt;&gt;&gt; transformer = ToTime(columns=[\"col1\"], format=\"%H:%M:%S\")\n&gt;&gt;&gt; transformer\nToTimeDataFrameTransformer(columns=('col1',), format=%H:%M:%S)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [\"01:01:01\", \"02:02:02\", \"12:00:01\", \"18:18:18\", \"23:59:59\"],\n...         \"col2\": [\"1\", \"2\", \"3\", \"4\", \"5\"],\n...         \"col3\": [\"01:01:01\", \"02:02:02\", \"12:00:01\", \"18:18:18\", \"23:59:59\"],\n...     }\n... )\n&gt;&gt;&gt; frame\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1     \u2506 col2 \u2506 col3     \u2502\n\u2502 ---      \u2506 ---  \u2506 ---      \u2502\n\u2502 str      \u2506 str  \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 01:01:01 \u2506 1    \u2506 01:01:01 \u2502\n\u2502 02:02:02 \u2506 2    \u2506 02:02:02 \u2502\n\u2502 12:00:01 \u2506 3    \u2506 12:00:01 \u2502\n\u2502 18:18:18 \u2506 4    \u2506 18:18:18 \u2502\n\u2502 23:59:59 \u2506 5    \u2506 23:59:59 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col1     \u2506 col2 \u2506 col3     \u2502\n\u2502 ---      \u2506 ---  \u2506 ---      \u2502\n\u2502 time     \u2506 str  \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 01:01:01 \u2506 1    \u2506 01:01:01 \u2502\n\u2502 02:02:02 \u2506 2    \u2506 02:02:02 \u2502\n\u2502 12:00:01 \u2506 3    \u2506 12:00:01 \u2502\n\u2502 18:18:18 \u2506 4    \u2506 18:18:18 \u2502\n\u2502 23:59:59 \u2506 5    \u2506 23:59:59 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TokenToIndex","title":"arctix.transformer.dataframe.TokenToIndex","text":"<p>               Bases: <code>ReplaceStrictDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocabulary</code> <p>The vocabulary which contains the token to index mapping.</p> required <code>token_column</code> <code>str</code> <p>The column name which contains the input tokens.</p> required <code>index_column</code> <code>str</code> <p>The column name which contains the output indices.</p> required <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from collections import Counter\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TokenToIndex\n&gt;&gt;&gt; from arctix.utils.vocab import Vocabulary\n&gt;&gt;&gt; vocab = Vocabulary(Counter({\"b\": 3, \"a\": 1, \"c\": 2, \"d\": 4}))\n&gt;&gt;&gt; vocab.get_token_to_index()\n{'b': 0, 'a': 1, 'c': 2, 'd': 3}\n&gt;&gt;&gt; transformer = TokenToIndex(vocab=vocab, token_column=\"col\", index_column=\"index\")\n&gt;&gt;&gt; transformer\nTokenToIndexDataFrameTransformer(orig_column=col, final_column=index)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [\"a\", \"b\", \"c\", \"d\", \"a\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 index \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 str \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1     \u2502\n\u2502 b   \u2506 0     \u2502\n\u2502 c   \u2506 2     \u2502\n\u2502 d   \u2506 3     \u2502\n\u2502 a   \u2506 1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.TokenToIndexDataFrameTransformer","title":"arctix.transformer.dataframe.TokenToIndexDataFrameTransformer","text":"<p>               Bases: <code>ReplaceStrictDataFrameTransformer</code></p> <p>Replace the values in a column by the values in a mapping.</p> <p>Parameters:</p> Name Type Description Default <code>vocab</code> <code>Vocabulary</code> <p>The vocabulary which contains the token to index mapping.</p> required <code>token_column</code> <code>str</code> <p>The column name which contains the input tokens.</p> required <code>index_column</code> <code>str</code> <p>The column name which contains the output indices.</p> required <code>**kwargs</code> <code>Any</code> <p>The keyword arguments to pass to <code>replace</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from collections import Counter\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import TokenToIndex\n&gt;&gt;&gt; from arctix.utils.vocab import Vocabulary\n&gt;&gt;&gt; vocab = Vocabulary(Counter({\"b\": 3, \"a\": 1, \"c\": 2, \"d\": 4}))\n&gt;&gt;&gt; vocab.get_token_to_index()\n{'b': 0, 'a': 1, 'c': 2, 'd': 3}\n&gt;&gt;&gt; transformer = TokenToIndex(vocab=vocab, token_column=\"col\", index_column=\"index\")\n&gt;&gt;&gt; transformer\nTokenToIndexDataFrameTransformer(orig_column=col, final_column=index)\n&gt;&gt;&gt; frame = pl.DataFrame({\"col\": [\"a\", \"b\", \"c\", \"d\", \"a\"]})\n&gt;&gt;&gt; frame\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2502\n\u2502 b   \u2502\n\u2502 c   \u2502\n\u2502 d   \u2502\n\u2502 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; out = transformer.transform(frame)\n&gt;&gt;&gt; out\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 col \u2506 index \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 str \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1     \u2502\n\u2502 b   \u2506 0     \u2502\n\u2502 c   \u2506 2     \u2502\n\u2502 d   \u2506 3     \u2502\n\u2502 a   \u2506 1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.is_dataframe_transformer_config","title":"arctix.transformer.dataframe.is_dataframe_transformer_config","text":"<pre><code>is_dataframe_transformer_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseDataFrameTransformer</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>Specifies the configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseDataFrameTransformer</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arctix.transformer.dataframe import is_dataframe_transformer_config\n&gt;&gt;&gt; is_dataframe_transformer_config(\n...     {\"_target_\": \"arctix.transformer.dataframe.Cast\", \"columns\": [\"col1\", \"col3\"]}\n... )\nTrue\n</code></pre>"},{"location":"refs/transformer/#arctix.transformer.dataframe.setup_dataframe_transformer","title":"arctix.transformer.dataframe.setup_dataframe_transformer","text":"<pre><code>setup_dataframe_transformer(\n    transformer: BaseDataFrameTransformer | dict,\n) -&gt; BaseDataFrameTransformer\n</code></pre> <p>Set up a <code>polars.DataFrame</code> transformer.</p> <p>The transformer is instantiated from its configuration by using the <code>BaseDataFrameTransformer</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>transformer</code> <code>BaseDataFrameTransformer | dict</code> <p>Specifies a <code>polars.DataFrame</code> transformer or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseDataFrameTransformer</code> <p>An instantiated transformer.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arctix.transformer.dataframe import setup_dataframe_transformer\n&gt;&gt;&gt; transformer = setup_dataframe_transformer(\n...     {\n...         \"_target_\": \"arctix.transformer.dataframe.Cast\",\n...         \"columns\": [\"col1\", \"col3\"],\n...         \"dtype\": pl.Int64,\n...     }\n... )\n&gt;&gt;&gt; transformer\nCastDataFrameTransformer(columns=('col1', 'col3'), dtype=Int64)\n</code></pre>"},{"location":"refs/utils/","title":"arctix.utils","text":""},{"location":"refs/utils/#arctix.utils","title":"arctix.utils","text":"<p>Contain utility functions.</p>"}]}